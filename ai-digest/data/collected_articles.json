{
  "collected_at": "2025-11-21T19:45:52.540314+00:00",
  "cutoff_time": "2025-11-19T19:45:38.852602+00:00",
  "hours": 48,
  "total_articles": 469,
  "articles": [
    {
      "title": "How agents can use filesystems for context engineering",
      "url": "https://blog.langchain.com/how-agents-can-use-filesystems-for-context-engineering/",
      "published": "2025-11-21T23:45:13+00:00",
      "date_verified": true,
      "description": "<p>A key feature of <a href=\"https://blog.langchain.com/deep-agents/\">deep agents</a> is their access to a set of filesystem tools. Deep agents can use these tools to read, write, edit, list, and search for files in their filesystem.</p><p>In this post, we&#x2019;ll walk through why we think filesystems are important for agents. In</p>",
      "source": "LangChain Blog",
      "source_url": "https://blog.langchain.dev/rss/",
      "author": "LangChain Accounts",
      "tags": []
    },
    {
      "title": "We should all be using dependency cooldowns",
      "url": "https://simonwillison.net/2025/Nov/21/dependency-cooldowns/#atom-everything",
      "published": "2025-11-21T22:27:33+00:00",
      "date_verified": true,
      "description": "<p><strong><a href=\"https://blog.yossarian.net/2025/11/21/We-should-all-be-using-dependency-cooldowns\">We should all be using dependency cooldowns</a></strong></p>\nWilliam Woodruff gives a name to a sensible strategy for managing dependencies while reducing the chances of a surprise supply chain attack: <strong>dependency cooldowns</strong>.</p>\n<p>Supply chain attacks happen when an attacker compromises a widely used open source package and publishes a new version with an exploit. These are usually spotted <em>very</em> quickly, so an attack often only has a few hours of effective window before the problem is identified and the compromised package is pulled.</p>\n<p>You are most at risk if you're automatically applying upgrades the same day they are released.</p>\n<p>William says:</p>\n<blockquote>\n<p>I <strong>love</strong> cooldowns for several reasons:</p>\n<ul>\n<li>They're empirically effective, per above. They won't stop <em>all</em> attackers, but they <em>do</em> stymie the majority of high-visibiity, mass-impact supply chain attacks that have become more common.</li>\n<li>They're <em>incredibly</em> easy to implement. Moreover, they're <strong>literally free</strong> to implement in most cases: most people can use <a href=\"https://docs.github.com/en/code-security/dependabot/working-with-dependabot/dependabot-options-reference#cooldown-\">Dependabot's functionality</a>, <a href=\"https://docs.renovatebot.com/key-concepts/minimum-release-age/\">Renovate's functionality</a>, or the functionality build directly into their package manager</li>\n</ul>\n</blockquote>\n<p>The one counter-argument to this is that sometimes an upgrade fixes a security vulnerability, and in those cases every hour of delay in upgrading as an hour when an attacker could exploit the new issue against your software.</p>\n<p>I see that as an argument for carefully monitoring the release notes of your dependencies, and paying special attention to security advisories. I'm a big fan of the <a href=\"https://github.com/advisories\">GitHub Advisory Database</a> for that kind of information.\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=46005111\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/definitions\">definitions</a>, <a href=\"https://simonwillison.net/tags/github\">github</a>, <a href=\"https://simonwillison.net/tags/open-source\">open-source</a>, <a href=\"https://simonwillison.net/tags/packaging\">packaging</a>, <a href=\"https://simonwillison.net/tags/supply-chain\">supply-chain</a></p>",
      "source": "Simon Willison's Weblog",
      "source_url": "https://simonwillison.net/atom/everything/",
      "author": "",
      "tags": [
        "definitions",
        "github",
        "open-source",
        "packaging",
        "supply-chain"
      ]
    },
    {
      "title": "Modern DataFrames in Python: A Hands-On Tutorial with Polars and DuckDB",
      "url": "https://towardsdatascience.com/modern-dataframes-in-python-a-hands-on-tutorial-with-polars-and-duckdb/",
      "published": "2025-11-21T22:00:00+00:00",
      "date_verified": true,
      "description": "<p>How I learned to handle growing datasets without slowing down my entire workflow</p>\n<p>The post <a href=\"https://towardsdatascience.com/modern-dataframes-in-python-a-hands-on-tutorial-with-polars-and-duckdb/\">Modern DataFrames in Python: A Hands-On Tutorial with Polars and DuckDB</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Benjamin Nweke",
      "tags": [
        "Data Science",
        "Big Data",
        "Data Analysis",
        "Polars",
        "Python"
      ]
    },
    {
      "title": "How To Build a Graph-Based Recommendation Engine Using EDG and Neo4j",
      "url": "https://towardsdatascience.com/how-to-build-a-recommendation-engine-using-edg-and-neo4j/",
      "published": "2025-11-21T20:30:00+00:00",
      "date_verified": true,
      "description": "<p>Use a shared taxonomy to connect RDF and property graphs—and power smarter recommendations with inferencing</p>\n<p>The post <a href=\"https://towardsdatascience.com/how-to-build-a-recommendation-engine-using-edg-and-neo4j/\">How To Build a Graph-Based Recommendation Engine Using EDG and Neo4j</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Steve Hedden",
      "tags": [
        "Data Science",
        "Knowledge Graph",
        "Neo4j",
        "Recommendation Engine",
        "Semantic Layer"
      ]
    },
    {
      "title": "Git for Vibe Coders",
      "url": "https://www.kdnuggets.com/git-for-vibe-coders",
      "published": "2025-11-21T20:00:59+00:00",
      "date_verified": true,
      "description": "Simple Git, zero overwhelm, just enough to stop Claude from accidently deleting your code and database.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "Abid Ali Awan",
      "tags": []
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/emollick.bsky.social/post/3m65k3557hc2u",
      "published": "2025-11-21T19:55:00+00:00",
      "date_verified": true,
      "description": "I think my “otters on a plane using WiFi” benchmark may saturated now that nano banana pro can do this.",
      "source": "@emollick.bsky.social - Ethan Mollick",
      "source_url": "https://bsky.app/profile/emollick.bsky.social/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "Natural Language Visualization and the Future of Data Analysis and Presentation",
      "url": "https://towardsdatascience.com/natural-language-visualization-and-the-future-of-data-analysis-and-presentation/",
      "published": "2025-11-21T19:00:00+00:00",
      "date_verified": true,
      "description": "<p>Will conversational interaction replace SQL queries, KPI reports, and dashboards?</p>\n<p>The post <a href=\"https://towardsdatascience.com/natural-language-visualization-and-the-future-of-data-analysis-and-presentation/\">Natural Language Visualization and the Future of Data Analysis and Presentation</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Michal Szudejko",
      "tags": [
        "Data Visualization",
        "Data Science",
        "Editors Pick",
        "LLM Agents",
        "Natural Language Queries"
      ]
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/emollick.bsky.social/post/3m65eoydujk2u",
      "published": "2025-11-21T18:19:00+00:00",
      "date_verified": true,
      "description": "Ruining great art with the nano banana pro command “Make this much more cheerful with as few changes as possible”",
      "source": "@emollick.bsky.social - Ethan Mollick",
      "source_url": "https://bsky.app/profile/emollick.bsky.social/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "The Download: the secrets of vitamin D, and an AI party in Africa",
      "url": "https://www.technologyreview.com/2025/11/21/1128232/the-download-the-secrets-of-vitamin-d-and-an-ai-party-in-africa/",
      "published": "2025-11-21T18:10:00+00:00",
      "date_verified": true,
      "description": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. We’re learning more about what vitamin D does to our bodies At a checkup a few years ago, a doctor told me I was deficient in vitamin D. But he wouldn’t write me&#8230;",
      "source": "MIT Technology Review",
      "source_url": "https://www.technologyreview.com/feed/",
      "author": "Rhiannon Williams",
      "tags": [
        "The Download"
      ]
    },
    {
      "title": "Top 7 Open Source AI Coding Models You Are Missing Out On",
      "url": "https://www.kdnuggets.com/top-7-open-source-ai-coding-models-you-are-missing-out-on",
      "published": "2025-11-21T18:00:54+00:00",
      "date_verified": true,
      "description": "Stop sending your code to OpenAI or Anthropic. Run these 7 top-tier open-source coding models locally for privacy, control, and zero API costs.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "Abid Ali Awan",
      "tags": []
    },
    {
      "title": "Generative AI Will Redesign Cars, But Not the Way Automakers Think",
      "url": "https://towardsdatascience.com/generative-ai-will-redesign-cars-but-not-the-way-automakers-think/",
      "published": "2025-11-21T17:30:00+00:00",
      "date_verified": true,
      "description": "<p>Traditional manufacturers are using revolutionary technology for incremental optimization instead of fundamental re-imagination</p>\n<p>The post <a href=\"https://towardsdatascience.com/generative-ai-will-redesign-cars-but-not-the-way-automakers-think/\">Generative AI Will Redesign Cars, But Not the Way Automakers Think</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Nishant Arora",
      "tags": [
        "Artificial Intelligence",
        "Automotive",
        "Cars",
        "Deep Dives",
        "Generative Ai",
        "Machine Learning"
      ]
    },
    {
      "title": "Perplexity AI Releases TransferEngine and pplx garden to Run Trillion Parameter LLMs on Existing GPU Clusters",
      "url": "https://www.marktechpost.com/2025/11/21/perplexity-ai-releases-transferengine-and-pplx-garden-to-run-trillion-parameter-llms-on-existing-gpu-clusters/",
      "published": "2025-11-21T15:56:20+00:00",
      "date_verified": true,
      "description": "<p>How can teams run trillion parameter language models on existing mixed GPU clusters without costly new hardware or deep vendor lock in? Perplexity&#8217;s research team has released TransferEngine and the surrounding pplx garden toolkit as open source infrastructure for large language model systems. This provides a way to run models with up to 1 trillion [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/21/perplexity-ai-releases-transferengine-and-pplx-garden-to-run-trillion-parameter-llms-on-existing-gpu-clusters/\">Perplexity AI Releases TransferEngine and pplx garden to Run Trillion Parameter LLMs on Existing GPU Clusters</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Asif Razzaq",
      "tags": [
        "AI Infrastructure",
        "Artificial Intelligence",
        "Editors Pick",
        "Machine Learning",
        "New Releases",
        "Staff",
        "Technology",
        "Uncategorized"
      ]
    },
    {
      "title": "We’re learning more about what vitamin D does to our bodies",
      "url": "https://www.technologyreview.com/2025/11/21/1128206/vitamin-d-bodies-bone-health-immune/",
      "published": "2025-11-21T15:00:00+00:00",
      "date_verified": true,
      "description": "It has started to get really wintry here in London over the last few days. The mornings are frosty, the wind is biting, and it’s already dark by the time I pick my kids up from school. The darkness in particular has got me thinking about vitamin D, a.k.a. the sunshine vitamin. At a checkup&#8230;",
      "source": "MIT Technology Review",
      "source_url": "https://www.technologyreview.com/feed/",
      "author": "Jessica Hamzelou",
      "tags": [
        "Biotechnology and health",
        "App",
        "The Checkup"
      ]
    },
    {
      "title": "An Implementation of Fully Traced and Evaluated Local LLM Pipeline Using Opik for Transparent, Measurable, and Reproducible AI Workflows",
      "url": "https://www.marktechpost.com/2025/11/21/an-implementation-of-fully-traced-and-evaluated-local-llm-pipeline-using-opik-for-transparent-measurable-and-reproducible-ai-workflows/",
      "published": "2025-11-21T13:47:10+00:00",
      "date_verified": true,
      "description": "<p>In this tutorial, we implement a complete workflow for building, tracing, and evaluating an LLM pipeline using Opik. We structure the system step-by-step, beginning with a lightweight model, adding prompt-based planning, creating a dataset, and finally running automated evaluations. As we move through each snippet, we see how Opik helps us track every function span, [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/21/an-implementation-of-fully-traced-and-evaluated-local-llm-pipeline-using-opik-for-transparent-measurable-and-reproducible-ai-workflows/\">An Implementation of Fully Traced and Evaluated Local LLM Pipeline Using Opik for Transparent, Measurable, and Reproducible AI Workflows</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Asif Razzaq",
      "tags": [
        "Artificial Intelligence",
        "Editors Pick",
        "Language Model",
        "Staff",
        "Tech News",
        "Technology",
        "Tutorials"
      ]
    },
    {
      "title": "The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs",
      "url": "https://arxiv.org/abs/2511.14777",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14777v1 Announce Type: new \nAbstract: Large language models (LLMs) have achieved remarkable results on tasks framed as reasoning problems, yet their true ability to perform procedural reasoning, executing multi-step, rule-based computations remains unclear. Unlike algorithmic systems, which can deterministically execute long-horizon symbolic procedures, LLMs often degrade under extended reasoning chains, but there is no controlled, interpretable benchmark to isolate and measure this collapse. We introduce Finite-State Machine (FSM) Execution as a minimal, fully interpretable framework for evaluating the procedural reasoning capacity of LLMs. In our setup, the model is given an explicit FSM definition and must execute it step-by-step given input actions, maintaining state consistency over multiple turns. This task requires no world knowledge, only faithful application of deterministic transition rules, making it a direct probe of the model's internal procedural fidelity. We measure both Turn Accuracy and Task Accuracy to disentangle immediate computation from cumulative state maintenance. Empirical results reveal systematic degradation as task horizon or branching complexity increases. Models perform significantly worse when rule retrieval involves high branching factors than when memory span is long. Larger models show improved local accuracy but remain brittle under multi-step reasoning unless explicitly prompted to externalize intermediate steps. FSM-based evaluation offers a transparent, complexity-controlled probe for diagnosing this failure mode and guiding the design of inductive biases that enable genuine long-horizon procedural competence. By grounding reasoning in measurable execution fidelity rather than surface correctness, this work helps establish a rigorous experimental foundation for understanding and improving the algorithmic reliability of LLMs.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mahdi Samiei, Mahdi Mansouri, Mahdieh Soleymani Baghshah",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Learning Interestingness in Automated Mathematical Theory Formation",
      "url": "https://arxiv.org/abs/2511.14778",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14778v1 Announce Type: new \nAbstract: We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(https://github.com/trishullab/Fermat).",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "George Tsoukalas, Rahul Saha, Amitayush Thakur, Sabrina Reguyal, Swarat Chaudhuri",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents",
      "url": "https://arxiv.org/abs/2511.14780",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14780v1 Announce Type: new \nAbstract: We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors (\"act like a neurologist\", \"act like an infectious disease specialist\"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Keith Moore, Jun W. Kim, David Lyu, Jeffrey Heo, Ehsan Adeli",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Subnational Geocoding of Global Disasters Using Large Language Models",
      "url": "https://arxiv.org/abs/2511.14788",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14788v1 Announce Type: new \nAbstract: Subnational location data of disaster events are critical for risk assessment and disaster risk reduction. Disaster databases such as EM-DAT often report locations in unstructured textual form, with inconsistent granularity or spelling, that make it difficult to integrate with spatial datasets. We present a fully automated LLM-assisted workflow that processes and cleans textual location information using GPT-4o, and assigns geometries by cross-checking three independent geoinformation repositories: GADM, OpenStreetMap and Wikidata. Based on the agreement and availability of these sources, we assign a reliability score to each location while generating subnational geometries. Applied to the EM-DAT dataset from 2000 to 2024, the workflow geocodes 14,215 events across 17,948 unique locations. Unlike previous methods, our approach requires no manual intervention, covers all disaster types, enables cross-verification across multiple sources, and allows flexible remapping to preferred frameworks. Beyond the dataset, we demonstrate the potential of LLMs to extract and structure geographic information from unstructured text, offering a scalable and reliable method for related analyses.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Michele Ronco, Damien Delforge, Wiebke S. J\\\"ager, Christina Corbane",
      "tags": [
        "cs.AI",
        "stat.AP"
      ]
    },
    {
      "title": "Project Rachel: Can an AI Become a Scholarly Author?",
      "url": "https://arxiv.org/abs/2511.14819",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14819v1 Announce Type: new \nAbstract: This paper documents Project Rachel, an action research study that created and tracked a complete AI academic identity named Rachel So. Through careful publication of AI-generated research papers, we investigate how the scholarly ecosystem responds to AI authorship. Rachel So published 10+ papers between March and October 2025, was cited, and received a peer review invitation. We discuss the implications of AI authorship on publishers, researchers, and the scientific system at large. This work contributes empirical action research data to the necessary debate about the future of scholarly communication with super human, hyper capable AI systems.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Martin Monperrus, Benoit Baudry, Cl\\'ement Vidal",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems",
      "url": "https://arxiv.org/abs/2511.14853",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14853v1 Announce Type: new \nAbstract: Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on representativeness-the extent to which the scenario-based data used for training and testing, reflect the operational conditions that the system is designed to operate safely in, i.e., Operational Design Domain (ODD) or expected to encounter, i.e., Target Operational Domain (TOD). We propose a probabilistic method that quantifies representativeness by comparing the statistical distribution of features encoded by the scenario suites with the corresponding distribution of features representing the TOD, acknowledging that the true TOD distribution is unknown, as it can only be inferred from limited data.\n  We apply an imprecise Bayesian method to handle limited data and uncertain priors. The imprecise Bayesian formulation produces interval-valued, uncertainty-aware estimates of representativeness, rather than a single value. We present a numerical example comparing the distributions of the scenario suite and the inferred TOD across operational categories-weather, road type, time of day, etc., under dependencies and prior uncertainty. We estimate representativeness locally (between categories) and globally as an interval.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Robab Aghazadeh Chakherlou, Siddartha Khastgir, Xingyu Zhao, Jerein Jeyachandran, Shufeng Chen",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Task Specific Sharpness Aware O-RAN Resource Management using Multi Agent Reinforcement Learning",
      "url": "https://arxiv.org/abs/2511.15002",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15002v1 Announce Type: new \nAbstract: Next-generation networks utilize the Open Radio Access Network (O-RAN) architecture to enable dynamic resource management, facilitated by the RAN Intelligent Controller (RIC). While deep reinforcement learning (DRL) models show promise in optimizing network resources, they often struggle with robustness and generalizability in dynamic environments. This paper introduces a novel resource management approach that enhances the Soft Actor Critic (SAC) algorithm with Sharpness-Aware Minimization (SAM) in a distributed Multi-Agent RL (MARL) framework. Our method introduces an adaptive and selective SAM mechanism, where regularization is explicitly driven by temporal-difference (TD)-error variance, ensuring that only agents facing high environmental complexity are regularized. This targeted strategy reduces unnecessary overhead, improves training stability, and enhances generalization without sacrificing learning efficiency. We further incorporate a dynamic $\\rho$ scheduling scheme to refine the exploration-exploitation trade-off across agents. Experimental results show our method significantly outperforms conventional DRL approaches, yielding up to a $22\\%$ improvement in resource allocation efficiency and ensuring superior QoS satisfaction across diverse O-RAN slices.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Fatemeh Lotfi, Hossein Rajoli, Fatemeh Afghah",
      "tags": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization",
      "url": "https://arxiv.org/abs/2511.15055",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15055v1 Announce Type: new \nAbstract: Human-like agents have long been one of the goals in pursuing artificial intelligence. Although reinforcement learning (RL) has achieved superhuman performance in many domains, relatively little attention has been focused on designing human-like RL agents. As a result, many reward-driven RL agents often exhibit unnatural behaviors compared to humans, raising concerns for both interpretability and trustworthiness. To achieve human-like behavior in RL, this paper first formulates human-likeness as trajectory optimization, where the objective is to find an action sequence that closely aligns with human behavior while also maximizing rewards, and adapts the classic receding-horizon control to human-like learning as a tractable and efficient implementation. To achieve this, we introduce Macro Action Quantization (MAQ), a human-like RL framework that distills human demonstrations into macro actions via Vector-Quantized VAE. Experiments on D4RL Adroit benchmarks show that MAQ significantly improves human-likeness, increasing trajectory similarity scores, and achieving the highest human-likeness rankings among all RL agents in the human evaluation study. Our results also demonstrate that MAQ can be easily integrated into various off-the-shelf RL algorithms, opening a promising direction for learning human-like RL agents. Our code is available at https://rlg.iis.sinica.edu.tw/papers/MAQ.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jian-Ting Guo, Yu-Cheng Chen, Ping-Chun Hsieh, Kuo-Hao Ho, Po-Wei Huang, Ti-Rong Wu, I-Chen Wu",
      "tags": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering",
      "url": "https://arxiv.org/abs/2511.15061",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15061v1 Announce Type: new \nAbstract: Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization.\n  In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution.\n  OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Haodong Chen, Guido Zuccon, Teerapong Leelanupab",
      "tags": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression",
      "url": "https://arxiv.org/abs/2511.15069",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15069v1 Announce Type: new \nAbstract: In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Haoyong Wu, Yongmei Liu",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents",
      "url": "https://arxiv.org/abs/2511.15074",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15074v1 Announce Type: new \nAbstract: The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a \"flooding-pruning\" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Henrik Bradland, Morten Goodwin, Vladimir I. Zadorozhny, Per-Arne Andersen",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models",
      "url": "https://arxiv.org/abs/2511.15169",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15169v2 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) improve answer quality through explicit chain-of-thought, yet this very capability introduces new safety risks: harmful content can be subtly injected, surface gradually, or be justified by misleading rationales within the reasoning trace. Existing safety evaluations, however, primarily focus on output-level judgments and rarely capture these dynamic risks along the reasoning process. In this paper, we present SafeRBench, the first benchmark that assesses LRM safety end-to-end -- from inputs and intermediate reasoning to final outputs. (1) Input Characterization: We pioneer the incorporation of risk categories and levels into input design, explicitly accounting for affected groups and severity, and thereby establish a balanced prompt suite reflecting diverse harm gradients. (2) Fine-Grained Output Analysis: We introduce a micro-thought chunking mechanism to segment long reasoning traces into semantically coherent units, enabling fine-grained evaluation across ten safety dimensions. (3) Human Safety Alignment: We validate LLM-based evaluations against human annotations specifically designed to capture safety judgments. Evaluations on 19 LRMs demonstrate that SafeRBench enables detailed, multidimensional safety assessment, offering insights into risks and protective mechanisms from multiple perspectives.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xin Gao, Shaohan Yu, Zerui Chen, Yueming Lyu, Weichen Yu, Guanghao Li, Jiyao Liu, Jianxiong Gao, Jian Liang, Ziwei Liu, Chenyang Si",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "HISE-KT: Synergizing Heterogeneous Information Networks and LLMs for Explainable Knowledge Tracing with Meta-Path Optimization",
      "url": "https://arxiv.org/abs/2511.15191",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15191v1 Announce Type: new \nAbstract: Knowledge Tracing (KT) aims to mine students' evolving knowledge states and predict their future question-answering performance. Existing methods based on heterogeneous information networks (HINs) are prone to introducing noises due to manual or random selection of meta-paths and lack necessary quality assessment of meta-path instances. Conversely, recent large language models (LLMs)-based methods ignore the rich information across students, and both paradigms struggle to deliver consistently accurate and evidence-based explanations. To address these issues, we propose an innovative framework, HIN-LLM Synergistic Enhanced Knowledge Tracing (HISE-KT), which seamlessly integrates HINs with LLMs. HISE-KT first builds a multi-relationship HIN containing diverse node types to capture the structural relations through multiple meta-paths. The LLM is then employed to intelligently score and filter meta-path instances and retain high-quality paths, pioneering automated meta-path quality assessment. Inspired by educational psychology principles, a similar student retrieval mechanism based on meta-paths is designed to provide a more valuable context for prediction. Finally, HISE-KT uses a structured prompt to integrate the target student's history with the retrieved similar trajectories, enabling the LLM to generate not only accurate predictions but also evidence-backed, explainable analysis reports. Experiments on four public datasets show that HISE-KT outperforms existing KT baselines in both prediction performance and interpretability.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zhiyi Duan, Zixing Shi, Hongyu Yuan, Qi Wang",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files",
      "url": "https://arxiv.org/abs/2511.15192",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15192v2 Announce Type: new \nAbstract: The remarkable language ability of Large Language Models (LLMs) stems from extensive training on vast datasets, often including copyrighted material, which raises serious concerns about unauthorized use. While Membership Inference Attacks (MIAs) offer potential solutions for detecting such violations, existing approaches face critical limitations and challenges due to LLMs' inherent overconfidence, limited access to ground truth training data, and reliance on empirically determined thresholds.\n  We present COPYCHECK, a novel framework that leverages uncertainty signals to detect whether copyrighted content was used in LLM training sets. Our method turns LLM overconfidence from a limitation into an asset by capturing uncertainty patterns that reliably distinguish between ``seen\" (training data) and ``unseen\" (non-training data) content. COPYCHECK further implements a two-fold strategy: (1) strategic segmentation of files into smaller snippets to reduce dependence on large-scale training data, and (2) uncertainty-guided unsupervised clustering to eliminate the need for empirically tuned thresholds. Experiment results show that COPYCHECK achieves an average balanced accuracy of 90.1% on LLaMA 7b and 91.6% on LLaMA2 7b in detecting seen files. Compared to the SOTA baseline, COPYCHECK achieves over 90% relative improvement, reaching up to 93.8\\% balanced accuracy. It further exhibits strong generalizability across architectures, maintaining high performance on GPT-J 6B. This work presents the first application of uncertainty for copyright detection in LLMs, offering practical tools for training data transparency.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Haodong Li, Jingqi Zhang, Xiao Cheng, Peihua Mai, Haoyu Wang, Yan Pang",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making",
      "url": "https://arxiv.org/abs/2511.15202",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15202v1 Announce Type: new \nAbstract: This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yinsheng Wang, Tario G You, L\\'eonard Boussioux, Shan Liu",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Efficiency Will Not Lead to Sustainable Reasoning AI",
      "url": "https://arxiv.org/abs/2511.15259",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15259v1 Announce Type: new \nAbstract: AI research is increasingly moving toward complex problem solving, where models are optimized not only for pattern recognition but for multi-step reasoning. Historically, computing's global energy footprint has been stabilized by sustained efficiency gains and natural saturation thresholds in demand. But as efficiency improvements are approaching physical limits, emerging reasoning AI lacks comparable saturation points: performance is no longer limited by the amount of available training data but continues to scale with exponential compute investments in both training and inference. This paper argues that efficiency alone will not lead to sustainable reasoning AI and discusses research and policy directions to embed explicit limits into the optimization and governance of such systems.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Philipp Wiesner, Daniel W. O'Neill, Francesca Larosa, Odej Kao",
      "tags": [
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Realist and Pluralist Conceptions of Intelligence and Their Implications on AI Research",
      "url": "https://arxiv.org/abs/2511.15282",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15282v1 Announce Type: new \nAbstract: In this paper, we argue that current AI research operates on a spectrum between two different underlying conceptions of intelligence: Intelligence Realism, which holds that intelligence represents a single, universal capacity measurable across all systems, and Intelligence Pluralism, which views intelligence as diverse, context-dependent capacities that cannot be reduced to a single universal measure. Through an analysis of current debates in AI research, we demonstrate how the conceptions remain largely implicit yet fundamentally shape how empirical evidence gets interpreted across a wide range of areas. These underlying views generate fundamentally different research approaches across three areas. Methodologically, they produce different approaches to model selection, benchmark design, and experimental validation. Interpretively, they lead to contradictory readings of the same empirical phenomena, from capability emergence to system limitations. Regarding AI risk, they generate categorically different assessments: realists view superintelligence as the primary risk and search for unified alignment solutions, while pluralists see diverse threats across different domains requiring context-specific solutions. We argue that making explicit these underlying assumptions can contribute to a clearer understanding of disagreements in AI research.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Ninell Oldenburg, Ruchira Dhar, Anders S{\\o}gaard",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration",
      "url": "https://arxiv.org/abs/2511.15351",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15351v1 Announce Type: new \nAbstract: Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yifu Guo, Zishan Xu, Zhiyuan Yao, Yuquan Lu, Jiaye Lin, Sen Hu, Zhenheng Tang, Yingchao Li, Huacan Wang, Ronghao Chen",
      "tags": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents",
      "url": "https://arxiv.org/abs/2511.15378",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15378v1 Announce Type: new \nAbstract: We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Trevor McInroe",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "IPR-1: Interactive Physical Reasoner",
      "url": "https://arxiv.org/abs/2511.15407",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15407v1 Announce Type: new \nAbstract: Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mingyu Zhang, Lifeng Zhuo, Tianxi Tan, Guocan Xie, Xian Nie, Yan Li, Renjie Zhao, Zizhu He, Ziyu Wang, Jiting Cai, Yong-Lu Li",
      "tags": [
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining",
      "url": "https://arxiv.org/abs/2511.15456",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15456v1 Announce Type: new \nAbstract: As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Qian'ang Mao, Yuxuan Zhang, Jiaman Chen, Wenjun Zhou, Jiaqi Yan",
      "tags": [
        "cs.AI",
        "q-fin.GN"
      ]
    },
    {
      "title": "Exploring the use of AI authors and reviewers at Agents4Science",
      "url": "https://arxiv.org/abs/2511.15534",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15534v1 Announce Type: new \nAbstract: There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Federico Bianchi, Owen Queen, Nitya Thakkar, Eric Sun, James Zou",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity",
      "url": "https://arxiv.org/abs/2511.15593",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15593v1 Announce Type: new \nAbstract: AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Alexis Audran-Reiss, Jordi Armengol Estap\\'e, Karen Hambardzumyan, Amar Budhiraja, Martin Josifoski, Edan Toledo, Rishi Hazra, Despoina Magka, Michael Shvartsman, Parth Pathak, Justine T Kao, Lucia Cipolina-Kun, Bhavul Gauri, Jean-Christophe Gagnon-Audet, Emanuel Tewolde, Jenny Zhang, Taco Cohen, Yossi Adi, Tatiana Shavrina, Yoram Bachrach",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "ESA: Energy-Based Shot Assembly Optimization for Automatic Video Editing",
      "url": "https://arxiv.org/abs/2511.02505",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.02505v2 Announce Type: cross \nAbstract: Shot assembly is a crucial step in film production and video editing, involving the sequencing and arrangement of shots to construct a narrative, convey information, or evoke emotions. Traditionally, this process has been manually executed by experienced editors. While current intelligent video editing technologies can handle some automated video editing tasks, they often fail to capture the creator's unique artistic expression in shot assembly. To address this challenge, we propose an energy-based optimization method for video shot assembly. Specifically, we first perform visual-semantic matching between the script generated by a large language model and a video library to obtain subsets of candidate shots aligned with the script semantics. Next, we segment and label the shots from reference videos, extracting attributes such as shot size, camera motion, and semantics. We then employ energy-based models to learn from these attributes, scoring candidate shot sequences based on their alignment with reference styles. Finally, we achieve shot assembly optimization by combining multiple syntax rules, producing videos that align with the assembly style of the reference videos. Our method not only automates the arrangement and combination of independent shots according to specific logic, narrative requirements, or artistic styles but also learns the assembly style of reference videos, creating a coherent visual sequence or holistic visual expression. With our system, even users with no prior video editing experience can create visually compelling videos. Project page: https://sobeymil.github.io/esa.com",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yaosen Chen, Wei Wang, Tianheng Zheng, Xuming Wen, Han Yang, Yanru Zhang",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "TacEleven: generative tactic discovery for football open play",
      "url": "https://arxiv.org/abs/2511.13326",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.13326v2 Announce Type: cross \nAbstract: Creating offensive advantages during open play is fundamental to football success. However, due to the highly dynamic and long-sequence nature of open play, the potential tactic space grows exponentially as the sequence progresses, making automated tactic discovery extremely challenging. To address this, we propose TacEleven, a generative framework for football open-play tactic discovery developed in close collaboration with domain experts from AJ Auxerre, designed to assist coaches and analysts in tactical decision-making. TacEleven consists of two core components: a language-controlled tactical generator that produces diverse tactical proposals, and a multimodal large language model-based tactical critic that selects the optimal proposal aligned with a high-level stylistic tactical instruction. The two components enables rapid exploration of tactical proposals and discovery of alternative open-play offensive tactics. We evaluate TacEleven across three tasks with progressive tactical complexity: counterfactual exploration, single-step discovery, and multi-step discovery, through both quantitative metrics and a questionnaire-based qualitative assessment. The results show that the TacEleven-discovered tactics exhibit strong realism and tactical creativity, with 52.50% of the multi-step tactical alternatives rated adoptable in real-world elite football scenarios, highlighting the framework's ability to rapidly generate numerous high-quality tactics for complex long-sequence open-play situations. TacEleven demonstrates the potential of creatively leveraging domain data and generative models to advance tactical analysis in sports.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Siyao Zhao, Hao Ma, Zhiqiang Pu, Jingjing Huang, Yi Pan, Shijie Wang, Zhi Ming",
      "tags": [
        "stat.AP",
        "cs.AI"
      ]
    },
    {
      "title": "Membership Inference Attack against Large Language Model-based Recommendation Systems: A New Distillation-based Paradigm",
      "url": "https://arxiv.org/abs/2511.14763",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14763v1 Announce Type: cross \nAbstract: Membership Inference Attack (MIA) aims to determine if a data sample is used in the training dataset of a target model. Traditional MIA obtains feature of target model via shadow models and uses the feature to train attack model, but the scale and complexity of training or fine-tuning data for large language model (LLM)-based recommendation systems make shadow models difficult to construct. Knowledge distillation as a method for extracting knowledge contributes to construct a stronger reference model. Knowledge distillation enables separate distillation for member and non-member data during the distillation process, enhancing the model's discriminative capability between the two in MIA. This paper propose a knowledge distillation-based MIA paradigm to improve the performance of membership inference attacks on LLM-based recommendation systems. Our paradigm introduces knowledge distillation to obtain a reference model, which enhances the reference model's ability to distinguish between member and non-member data. We obtain individual features from the reference model and train our attack model with fused feature. Our paradigm improves the attack performance of MIA compared to shadow model-based attack.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Li Cuihong, Huang Xiaowen, Yin Chuanhuan, Sang Jitao",
      "tags": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Image-Seeking Intent Prediction for Cross-Device Product Search",
      "url": "https://arxiv.org/abs/2511.14764",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14764v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) are transforming personalized search, recommendations, and customer interaction in e-commerce. Customers increasingly shop across multiple devices, from voice-only assistants to multimodal displays, each offering different input and output capabilities. A proactive suggestion to switch devices can greatly improve the user experience, but it must be offered with high precision to avoid unnecessary friction. We address the challenge of predicting when a query requires visual augmentation and a cross-device switch to improve product discovery. We introduce Image-Seeking Intent Prediction, a novel task for LLM-driven e-commerce assistants that anticipates when a spoken product query should proactively trigger a visual on a screen-enabled device. Using large-scale production data from a multi-device retail assistant, including 900K voice queries, associated product retrievals, and behavioral signals such as image carousel engagement, we train IRP (Image Request Predictor), a model that leverages user input query and corresponding retrieved product metadata to anticipate visual intent. Our experiments show that combining query semantics with product data, particularly when improved through lightweight summarization, consistently improves prediction accuracy. Incorporating a differentiable precision-oriented loss further reduces false positives. These results highlight the potential of LLMs to power intelligent, cross-device shopping assistants that anticipate and adapt to user needs, enabling more seamless and personalized e-commerce experiences.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mariya Hendriksen, Svitlana Vakulenko, Jordan Massiah, Gabriella Kazai, Emine Yilmaz",
      "tags": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Optimizing Agricultural Research: A RAG-Based Approach to Mycorrhizal Fungi Information",
      "url": "https://arxiv.org/abs/2511.14765",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14765v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation (RAG) represents a transformative approach within natural language processing (NLP), combining neural information retrieval with generative language modeling to enhance both contextual accuracy and factual reliability of responses. Unlike conventional Large Language Models (LLMs), which are constrained by static training corpora, RAG-powered systems dynamically integrate domain-specific external knowledge sources, thereby overcoming temporal and disciplinary limitations. In this study, we present the design and evaluation of a RAG-enabled system tailored for Mycophyto, with a focus on advancing agricultural applications related to arbuscular mycorrhizal fungi (AMF). These fungi play a critical role in sustainable agriculture by enhancing nutrient acquisition, improving plant resilience under abiotic and biotic stresses, and contributing to soil health. Our system operationalizes a dual-layered strategy: (i) semantic retrieval and augmentation of domain-specific content from agronomy and biotechnology corpora using vector embeddings, and (ii) structured data extraction to capture predefined experimental metadata such as inoculation methods, spore densities, soil parameters, and yield outcomes. This hybrid approach ensures that generated responses are not only semantically aligned but also supported by structured experimental evidence. To support scalability, embeddings are stored in a high-performance vector database, allowing near real-time retrieval from an evolving literature base. Empirical evaluation demonstrates that the proposed pipeline retrieves and synthesizes highly relevant information regarding AMF interactions with crop systems, such as tomato (Solanum lycopersicum). The framework underscores the potential of AI-driven knowledge discovery to accelerate agroecological innovation and enhance decision-making in sustainable farming systems.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mohammad Usman Altam, Md Imtiaz Habib, Tuan Hoang",
      "tags": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "An LLM-Powered Agent for Real-Time Analysis of the Vietnamese IT Job Market",
      "url": "https://arxiv.org/abs/2511.14767",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14767v1 Announce Type: cross \nAbstract: Individuals entering Vietnam's dynamic Information Technology (IT) job market face a critical gap in reliable career guidance. Existing market reports are often outdated, while the manual analysis of thousands of job postings is impractical for most. To address this challenge, we present the AI Job Market Consultant, a novel conversational agent that delivers deep, data-driven insights directly from the labor market in real-time. The foundation of our system is a custom-built dataset created via an automated pipeline that crawls job portals using Playwright and leverages the Large Language Model (LLM) to intelligently structure unstructured posting data. The core of our system is a tool-augmented AI agent, based on the ReAct agentic framework, which enables the ability of autonomously reasoning, planning, and executing actions through a specialized toolbox for SQL queries, semantic search, and data visualization. Our prototype successfully collected and analyzed 3,745 job postings, demonstrating its ability to answer complex, multi-step queries, generate on-demand visualizations, and provide personalized career advice grounded in real-world data. This work introduces a new paradigm for labor market analysis, showcasing how specialized agentic AI systems can democratize access to timely, trustworthy career intelligence for the next generation of professionals.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Minh-Thuan Nguyen, Thien Vo-Thanh, Thai-Duy Dinh, Xuan-Quang Phan, Tan-Ha Mai, Lam-Son L\\^e",
      "tags": [
        "cs.IR",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Causally-Informed Reinforcement Learning for Adaptive Emotion-Aware Social Media Recommendation",
      "url": "https://arxiv.org/abs/2511.14768",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14768v1 Announce Type: cross \nAbstract: Social media recommendation systems play a central role in shaping users' emotional experiences. However, most systems are optimized solely for engagement metrics, such as click rate, viewing time, or scrolling, without accounting for users' emotional states. Repeated exposure to emotionally charged content has been shown to negatively affect users' emotional well-being over time. We propose an Emotion-aware Social Media Recommendation (ESMR) framework that personalizes content based on users' evolving emotional trajectories. ESMR integrates a Transformer-based emotion predictor with a hybrid recommendation policy: a LightGBM model for engagement during stable periods and a reinforcement learning agent with causally informed rewards when negative emotional states persist. Through behaviorally grounded evaluation over 30-day interaction traces, ESMR demonstrates improved emotional recovery, reduced volatility, and strong engagement retention. ESMR offers a path toward emotionally aware recommendations without compromising engagement performance.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Bhavika Jain, Robert Pitsko, Ananya Drishti, Mahfuza Farooque",
      "tags": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Cluster-based Adaptive Retrieval: Dynamic Context Selection for RAG Applications",
      "url": "https://arxiv.org/abs/2511.14769",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14769v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by pulling in external material, document, code, manuals, from vast and ever-growing corpora, to effectively answer user queries. The effectiveness of RAG depends significantly on aligning the number of retrieved documents with query characteristics: narrowly focused queries typically require fewer, highly relevant documents, whereas broader or ambiguous queries benefit from retrieving more extensive supporting information. However, the common static top-k retrieval approach fails to adapt to this variability, resulting in either insufficient context from too few documents or redundant information from too many. Motivated by these challenges, we introduce Cluster-based Adaptive Retrieval (CAR), an algorithm that dynamically determines the optimal number of documents by analyzing the clustering patterns of ordered query-document similarity distances. CAR detects the transition point within similarity distances, where tightly clustered, highly relevant documents shift toward less pertinent candidates, establishing an adaptive cut-off that scales with query complexity. On Coinbase's CDP corpus and the public MultiHop-RAG benchmark, CAR consistently picks the optimal retrieval depth and achieves the highest TES score, outperforming every fixed top-k baseline. In downstream RAG evaluations, CAR cuts LLM token usage by 60%, trims end-to-end latency by 22%, and reduces hallucinations by 10% while fully preserving answer relevance. Since integrating CAR into Coinbase's virtual assistant, we've seen user engagement jump by 200%.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yifan Xu, Vipul Gupta, Rohit Aggarwal, Varsha Mahadevan, Bhaskar Krishnamachari",
      "tags": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "ExplainRec: Towards Explainable Multi-Modal Zero-Shot Recommendation with Preference Attribution and Large Language Models",
      "url": "https://arxiv.org/abs/2511.14770",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14770v1 Announce Type: cross \nAbstract: Recent advances in Large Language Models (LLMs) have opened new possibilities for recommendation systems, though current approaches such as TALLRec face challenges in explainability and cold-start scenarios. We present ExplainRec, a framework that extends LLM-based recommendation capabilities through preference attribution, multi-modal fusion, and zero-shot transfer learning. The framework incorporates four technical contributions: preference attribution tuning for explainable recommendations, zero-shot preference transfer for cold-start users and items, multi-modal enhancement leveraging visual and textual content, and multi-task collaborative optimization. Experimental evaluation on MovieLens-25M and Amazon datasets shows that ExplainRec outperforms existing methods, achieving AUC improvements of 0.7\\% on movie recommendation and 0.9\\% on cross-domain tasks, while generating interpretable explanations and handling cold-start scenarios effectively.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Bo Ma, LuYao Liu, ZeHua Hu, Simon Lau",
      "tags": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective",
      "url": "https://arxiv.org/abs/2511.14772",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14772v1 Announce Type: cross \nAbstract: With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zhuoyi Yang, Xu Guo, Tong Zhang, Huijuan Xu, Boyang Li",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs",
      "url": "https://arxiv.org/abs/2511.14774",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14774v1 Announce Type: cross \nAbstract: Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Pei-Fu Guo, Yun-Da Tsai, Chun-Chia Hsu, Kai-Xin Chen, Ya-An Tsai, Kai-Wei Chang, Nanyun Peng, Mi-Yen Yeh, Shou-De Lin",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Quantifying the Role of OpenFold Components in Protein Structure Prediction",
      "url": "https://arxiv.org/abs/2511.14781",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14781v1 Announce Type: cross \nAbstract: Models such as AlphaFold2 and OpenFold have transformed protein structure prediction, yet their inner workings remain poorly understood. We present a methodology to systematically evaluate the contribution of individual OpenFold components to structure prediction accuracy. We identify several components that are critical for most proteins, while others vary in importance across proteins. We further show that the contribution of several components is correlated with protein length. These findings provide insight into how OpenFold achieves accurate predictions and highlight directions for interpreting protein prediction networks more broadly.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Tyler L. Hayes, Giri P. Krishnan",
      "tags": [
        "q-bio.BM",
        "cs.AI"
      ]
    },
    {
      "title": "Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data",
      "url": "https://arxiv.org/abs/2511.14791",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14791v1 Announce Type: cross \nAbstract: Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\n  The dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\n  Integrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Cyriana M. A. Roelofs, Edison Guevara Bastidas, Thomas Hugo, Stefan Faulstich, Anna Cadenbach",
      "tags": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Application of Graph Based Vision Transformers Architectures for Accurate Temperature Prediction in Fiber Specklegram Sensors",
      "url": "https://arxiv.org/abs/2511.14792",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14792v1 Announce Type: cross \nAbstract: Fiber Specklegram Sensors (FSS) are highly effective for environmental monitoring, particularly for detecting temperature variations. However, the nonlinear nature of specklegram data presents significant challenges for accurate temperature prediction. This study investigates the use of transformer-based architectures, including Vision Transformers (ViTs), Swin Transformers, and emerging models such as Learnable Importance Non-Symmetric Attention Vision Transformers (LINA-ViT) and Multi-Adaptive Proximity Vision Graph Attention Transformers (MAP-ViGAT), to predict temperature from specklegram data over a range of 0 to 120 Celsius. The results show that ViTs achieved a Mean Absolute Error (MAE) of 1.15, outperforming traditional models such as CNNs. GAT-ViT and MAP-ViGAT variants also demonstrated competitive accuracy, highlighting the importance of adaptive attention mechanisms and graph-based structures in capturing complex modal interactions and phase shifts in specklegram data. Additionally, this study incorporates Explainable AI (XAI) techniques, including attention maps and saliency maps, to provide insights into the decision-making processes of the transformer models, improving interpretability and transparency. These findings establish transformer architectures as strong benchmarks for optical fiber-based temperature sensing and offer promising directions for industrial monitoring and structural health assessment applications.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Abhishek Sebastian",
      "tags": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution",
      "url": "https://arxiv.org/abs/2511.14794",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14794v1 Announce Type: cross \nAbstract: Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Camilo Chac\\'on Sartori, Christian Blum",
      "tags": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Opinion Mining and Analysis Using Hybrid Deep Neural Networks",
      "url": "https://arxiv.org/abs/2511.14796",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14796v1 Announce Type: cross \nAbstract: Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Adel Hidri, Suleiman Ali Alsaif, Muteeb Alahmari, Eman AlShehri, Minyar Sassi Hidri",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods",
      "url": "https://arxiv.org/abs/2511.14798",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14798v1 Announce Type: cross \nAbstract: Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.\n  This paper compares two AI-based grading techniques: \\textit{Direct}, where the AI model applies a rubric directly to student code, and \\textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.\n  Initial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Ahmad Memon, Abdallah Mohamed",
      "tags": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study",
      "url": "https://arxiv.org/abs/2511.14803",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14803v1 Announce Type: cross \nAbstract: IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Pranjal Gupta, Karan Bhukar, Harshit Kumar, Seema Nagar, Prateeti Mohapatra, Debanjana Kar",
      "tags": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Continuous Assurance with Formal Verification and Assurance Cases",
      "url": "https://arxiv.org/abs/2511.14805",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14805v1 Announce Type: cross \nAbstract: Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Dhaminda B. Abeywickrama, Michael Fisher, Frederic Wheeler, Louise Dennis",
      "tags": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging",
      "url": "https://arxiv.org/abs/2511.14806",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14806v1 Announce Type: cross \nAbstract: Modeling genomic sequences faces two unsolved challenges: the information density varies widely across different regions, while there is no clearly defined minimum vocabulary unit. Relying on either four primitive bases or independently designed DNA tokenizers, existing approaches with naive masked language modeling pre-training often fail to adapt to the varying complexities of genomic sequences. Leveraging Token Merging techniques, this paper introduces a hierarchical architecture that jointly optimizes a dynamic genomic tokenizer and latent Transformers with context-aware pre-training tasks. As for network structures, the tokenization module automatically chunks adjacent bases into words by stacking multiple layers of the differentiable token merging blocks with local-window constraints, then a Latent Encoder captures the global context of these merged words by full-attention blocks. Symmetrically employing a Latent Decoder and a Local Decoder, MergeDNA learns with two pre-training tasks: Merged Token Reconstruction simultaneously trains the dynamic tokenization module and adaptively filters important tokens, while Adaptive Masked Token Modeling learns to predict these filtered tokens to capture informative contents. Extensive experiments show that MergeDNA achieves superior performance on three popular DNA benchmarks and several multi-omics tasks with fine-tuning or zero-shot evaluation, outperforming typical tokenization methods and large-scale DNA foundation models.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Siyuan Li, Kai Yu, Anna Wang, Zicheng Liu, Chang Yu, Jingbo Zhou, Qirong Yang, Yucheng Guo, Xiaoming Zhang, Stan Z. Li",
      "tags": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Fully Differentiable dMRI Streamline Propagation in PyTorch",
      "url": "https://arxiv.org/abs/2511.14807",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14807v1 Announce Type: cross \nAbstract: Diffusion MRI (dMRI) provides a distinctive means to probe the microstructural architecture of living tissue, facilitating applications such as brain connectivity analysis, modeling across multiple conditions, and the estimation of macrostructural features. Tractography, which emerged in the final years of the 20th century and accelerated in the early 21st century, is a technique for visualizing white matter pathways in the brain using dMRI. Most diffusion tractography methods rely on procedural streamline propagators or global energy minimization methods. Although recent advancements in deep learning have enabled tasks that were previously challenging, existing tractography approaches are often non-differentiable, limiting their integration in end-to-end learning frameworks. While progress has been made in representing streamlines in differentiable frameworks, no existing method offers fully differentiable propagation. In this work, we propose a fully differentiable solution that retains numerical fidelity with a leading streamline algorithm. The key is that our PyTorch-engineered streamline propagator has no components that block gradient flow, making it fully differentiable. We show that our method matches standard propagators while remaining differentiable. By translating streamline propagation into a differentiable PyTorch framework, we enable deeper integration of tractography into deep learning workflows, laying the foundation for a new category of macrostructural reasoning that is not only computationally robust but also scientifically rigorous.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jongyeon Yoon, Elyssa M. McMaster, Michael E. Kim, Gaurav Rudravaram, Kurt G. Schilling, Bennett A. Landman, Daniel Moyer",
      "tags": [
        "eess.IV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States",
      "url": "https://arxiv.org/abs/2511.14808",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14808v1 Announce Type: cross \nAbstract: Under real-analytic assumptions on decoder-only Transformers, recent work shows that the map from discrete prompts to last-token hidden states is generically injective on finite prompt sets. We refine this picture: for each layer $\\ell$ we define a collision discriminant $\\Delta^\\ell \\subset \\Theta$ and injective stratum $U^\\ell = \\Theta \\setminus \\Delta^\\ell$, and prove a dichotomy -- either the model is nowhere injective on the set, or $U^\\ell$ is open and dense and every $F^\\ell_\\theta$ is injective. Under mild non-singularity assumptions on the optimizer and an absolutely continuous initialization, generic injectivity persists along smooth training trajectories over any fixed horizon. We also treat symmetry groups $G$, showing that discriminants and injective strata descend to the quotient $\\Theta/G$, so injectivity is naturally a property of functional equivalence classes.\n  We complement these results with an empirical study of layerwise geometric diagnostics. We define a separation margin and a co-Lipschitz (lower Lipschitz) constant between prompt space and last-token representation space, estimated via nearest-neighbor statistics on large prompt sets. Applying these diagnostics to pretrained LLaMA-3 and Qwen models, we study behavior across layers, sequence lengths, model scales, and 8- and 4-bit activation quantization. On our sampled prompts we see no collisions in full precision or at 8 bits, while 4-bit quantization induces a small number of collisions and markedly shrinks co-Lipschitz estimates. For a small GPT-2 trained from scratch, normalized metrics remain stable over training. Overall, the results suggest that Transformer representations are generically and persistently injective in the continuous-parameter idealization, while their practical invertibility can be probed using simple geometric diagnostics.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mikael von Strauss",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech",
      "url": "https://arxiv.org/abs/2511.14824",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14824v1 Announce Type: cross \nAbstract: Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose SpotlightTTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Nam-Gyu Kim",
      "tags": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "Implicit Bias of the JKO Scheme",
      "url": "https://arxiv.org/abs/2511.14827",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14827v1 Announce Type: cross \nAbstract: Wasserstein gradient flow provides a general framework for minimizing an energy functional $J$ over the space of probability measures on a Riemannian manifold $(M,g)$. Its canonical time-discretization, the Jordan-Kinderlehrer-Otto (JKO) scheme, produces for any step size $\\eta>0$ a sequence of probability distributions $\\rho_k^\\eta$ that approximate to first order in $\\eta$ Wasserstein gradient flow on $J$. But the JKO scheme also has many other remarkable properties not shared by other first order integrators, e.g. it preserves energy dissipation and exhibits unconditional stability for $\\lambda$-geodesically convex functionals $J$. To better understand the JKO scheme we characterize its implicit bias at second order in $\\eta$. We show that $\\rho_k^\\eta$ are approximated to order $\\eta^2$ by Wasserstein gradient flow on a \\emph{modified} energy \\[ J^{\\eta}(\\rho) = J(\\rho) - \\frac{\\eta}{4}\\int_M \\Big\\lVert \\nabla_g \\frac{\\delta J}{\\delta \\rho} (\\rho) \\Big\\rVert_{2}^{2} \\,\\rho(dx), \\] obtained by subtracting from $J$ the squared metric curvature of $J$ times $\\eta/4$. The JKO scheme therefore adds at second order in $\\eta$ a \\textit{deceleration} in directions where the metric curvature of $J$ is rapidly changing. This corresponds to canonical implicit biases for common functionals: for entropy the implicit bias is the Fisher information, for KL-divergence it is the Fisher-Hyv{\\\"a}rinen divergence, and for Riemannian gradient descent it is the kinetic energy in the metric $g$. To understand the differences between minimizing $J$ and $J^\\eta$ we study \\emph{JKO-Flow}, Wasserstein gradient flow on $J^\\eta$, in several simple numerical examples. These include exactly solvable Langevin dynamics on the Bures-Wasserstein space and Langevin sampling from a quartic potential in 1D.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Peter Halmos, Boris Hanin",
      "tags": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.AP"
      ]
    },
    {
      "title": "Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization",
      "url": "https://arxiv.org/abs/2511.14846",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14846v1 Announce Type: cross \nAbstract: Training Large Language Models (LLMs) for multi-turn Tool-Integrated Reasoning (TIR) - where models iteratively reason, generate code, and verify through execution - remains challenging for existing reinforcement learning (RL) approaches. Current RL methods, exemplified by Group Relative Policy Optimization (GRPO), suffer from coarse-grained, trajectory-level rewards that provide insufficient learning signals for complex multi-turn interactions, leading to training stagnation. To address this issue, we propose Group Turn Policy Optimization (GTPO), a novel RL algorithm specifically designed for training LLMs on multi-turn TIR tasks. GTPO introduces three key innovations: (1) turn-level reward assignment that provides fine-grained feedback for individual turns, (2) return-based advantage estimation where normalized discounted returns are calculated as advantages, and (3) self-supervised reward shaping that exploits self-supervision signals from generated code to densify sparse binary outcome-based rewards. Our comprehensive evaluation demonstrates that GTPO outperforms GRPO by 3.0% on average across diverse reasoning benchmarks, establishing its effectiveness for advancing complex mathematical reasoning in the real world.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yifeng Ding, Hung Le, Songyang Han, Kangrui Ruan, Zhenghui Jin, Varun Kumar, Zijian Wang, Anoop Deoras",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "PolyKAN: Efficient Fused GPU Operators for Polynomial Kolmogorov-Arnold Network Variants",
      "url": "https://arxiv.org/abs/2511.14852",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14852v1 Announce Type: cross \nAbstract: Kolmogorov-Arnold Networks (KANs) promise higher expressive capability and stronger interpretability than Multi-Layer Perceptron, particularly in the domain of AI for Science. However, practical adoption has been hindered by low GPU utilization of existing parallel implementations. To address this challenge, we present a GPU-accelerated operator library, named PolyKAN which is the first general open-source implementation of KAN and its variants. PolyKAN fuses the forward and backward passes of polynomial KAN layers into a concise set of optimized CUDA kernels. Four orthogonal techniques underpin the design: (i) \\emph{lookup-table} with linear interpolation that replaces runtime expensive math-library functions; (ii) \\emph{2D tiling} to expose thread-level parallelism with preserving memory locality; (iii) a \\emph{two-stage reduction} scheme converting scattered atomic updates into a single controllable merge step; and (iv) \\emph{coefficient-layout reordering} yielding unit-stride reads under the tiled schedule. Using a KAN variant, Chebyshev KAN, as a case-study, PolyKAN delivers $1.2$--$10\\times$ faster inference and $1.4$--$12\\times$ faster training than a Triton + cuBLAS baseline, with identical accuracy on speech, audio-enhancement, and tabular-regression workloads on both highend GPU and consumer-grade GPU.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mingkun Yu, Heming Zhong, Dan Huang, Yutong Lu, Jiazhi Jiang",
      "tags": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "When CNNs Outperform Transformers and Mambas: Revisiting Deep Architectures for Dental Caries Segmentation",
      "url": "https://arxiv.org/abs/2511.14860",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14860v1 Announce Type: cross \nAbstract: Accurate identification and segmentation of dental caries in panoramic radiographs are critical for early diagnosis and effective treatment planning. Automated segmentation remains challenging due to low lesion contrast, morphological variability, and limited annotated data. In this study, we present the first comprehensive benchmarking of convolutional neural networks, vision transformers and state-space mamba architectures for automated dental caries segmentation on panoramic radiographs through a DC1000 dataset. Twelve state-of-the-art architectures, including VMUnet, MambaUNet, VMUNetv2, RMAMamba-S, TransNetR, PVTFormer, DoubleU-Net, and ResUNet++, were trained under identical configurations. Results reveal that, contrary to the growing trend toward complex attention based architectures, the CNN-based DoubleU-Net achieved the highest dice coefficient of 0.7345, mIoU of 0.5978, and precision of 0.8145, outperforming all transformer and Mamba variants. In the study, the top 3 results across all performance metrics were achieved by CNN-based architectures. Here, Mamba and transformer-based methods, despite their theoretical advantage in global context modeling, underperformed due to limited data and weaker spatial priors. These findings underscore the importance of architecture-task alignment in domain-specific medical image segmentation more than model complexity. Our code is available at: https://github.com/JunZengz/dental-caries-segmentation.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Aashish Ghimire, Jun Zeng, Roshan Paudel, Nikhil Kumar Tomar, Deepak Ranjan Nayak, Harshith Reddy Nalla, Vivek Jha, Glenda Reynolds, Debesh Jha",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "B-Rep Distance Functions (BR-DF): How to Represent a B-Rep Model by Volumetric Distance Functions?",
      "url": "https://arxiv.org/abs/2511.14870",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14870v1 Announce Type: cross \nAbstract: This paper presents a novel geometric representation for CAD Boundary Representation (B-Rep) based on volumetric distance functions, dubbed B-Rep Distance Functions (BR-DF). BR-DF encodes the surface mesh geometry of a CAD model as signed distance function (SDF). B-Rep vertices, edges, faces and their topology information are encoded as per-face unsigned distance functions (UDFs). An extension of the Marching Cubes algorithm converts BR-DF directly into watertight CAD B-Rep model (strictly speaking a faceted B-Rep model). A surprising characteristic of BR-DF is that this conversion process never fails. Leveraging the volumetric nature of BR-DF, we propose a multi-branch latent diffusion with 3D U-Net backbone for jointly generating the SDF and per-face UDFs of a BR-DF model. Our approach achieves comparable CAD generation performance against SOTA methods while reaching the unprecedented 100% success rate in producing (faceted) B-Rep models.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Fuyang Zhang, Pradeep Kumar Jayaraman, Xiang Xu, Yasutaka Furukawa",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Skin-R1: Toward Trustworthy Clinical Reasoning for Dermatological Diagnosis",
      "url": "https://arxiv.org/abs/2511.14900",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14900v1 Announce Type: cross \nAbstract: The emergence of vision-language models (VLMs) has opened new possibilities for clinical reasoning and has shown promising performance in dermatological diagnosis. However, their trustworthiness and clinical utility are often limited by three major factors: (1) Data heterogeneity, where diverse datasets lack consistent diagnostic labels and clinical concept annotations; (2) Absence of grounded diagnostic rationales, leading to a scarcity of reliable reasoning supervision; and (3) Limited scalability and generalization, as models trained on small, densely annotated datasets struggle to transfer nuanced reasoning to large, sparsely-annotated ones.\n  To address these limitations, we propose SkinR1, a novel dermatological VLM that combines deep, textbook-based reasoning with the broad generalization capabilities of reinforcement learning (RL). SkinR1 systematically resolves the key challenges through a unified, end-to-end framework. First, we design a textbook-based reasoning generator that synthesizes high-fidelity, hierarchy-aware, and differential-diagnosis (DDx)-informed trajectories, providing reliable expert-level supervision. Second, we leverage the constructed trajectories for supervised fine-tuning (SFT) empowering the model with grounded reasoning ability. Third, we develop a novel RL paradigm that, by incorporating the hierarchical structure of diseases, effectively transfers these grounded reasoning patterns to large-scale, sparse data. Extensive experiments on multiple dermatology datasets demonstrate that SkinR1 achieves superior diagnostic accuracy. The ablation study demonstrates the importance of the reasoning foundation instilled by SFT.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zehao Liu, Wejieying Ren, Jipeng Zhang, Tianxiang Zhao, Jingxi Zhu, Xiaoting Li, Vasant G. Honavar",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "On-Premise SLMs vs. Commercial LLMs: Prompt Engineering and Incident Classification in SOCs and CSIRTs",
      "url": "https://arxiv.org/abs/2511.14908",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14908v1 Announce Type: cross \nAbstract: In this study, we evaluate open-source models for security incident classification, comparing them with proprietary models. We utilize a dataset of anonymized real incidents, categorized according to the NIST SP 800-61r3 taxonomy and processed using five prompt-engineering techniques (PHP, SHP, HTP, PRP, and ZSL). The results indicate that, although proprietary models still exhibit higher accuracy, locally deployed open-source models provide advantages in privacy, cost-effectiveness, and data sovereignty.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Geft\\'e Almeida, Marcio Pohlmann, Alex Severo, Diego Kreutz, Tiago Heinrich, Louren\\c{c}o Pereira",
      "tags": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertising on Social Media",
      "url": "https://arxiv.org/abs/2511.14930",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14930v1 Announce Type: cross \nAbstract: In this paper, we provide a novel measure for greenwashing -- i.e., climate-related misinformation -- that shows how polluting companies can use social media advertising related to climate change to redirect criticism. To do so, we identify greenwashing content in 11 million social-political ads in Meta's Ad Targeting Datset with a measurement technique that combines large language models, human coders, and advances in Bayesian item response theory. We show that what is called greenwashing has diverse actors and components, but we also identify a very pernicious form, which we call political greenwashing, that appears to be promoted by fossil fuel companies and related interest groups. Based on ad targeting data, we show that much of this advertising happens via organizations with undisclosed links to the fossil fuel industry. Furthermore, we show that greenwashing ad content is being micro-targeted at left-leaning communities with fossil fuel assets, though we also find comparatively little evidence of ad targeting aimed at influencing public opinion at the national level.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Robert Kubinec, Aseem Mahajan",
      "tags": [
        "stat.AP",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ]
    },
    {
      "title": "Artificial intelligence approaches for energy-efficient laser cutting machines",
      "url": "https://arxiv.org/abs/2511.14952",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14952v1 Announce Type: cross \nAbstract: This research addresses the significant challenges of energy consumption and environmental impact in laser cutting by proposing novel deep learning (DL) methodologies to achieve energy reduction. Recognizing the current lack of adaptive control and the open-loop nature of CO2 laser suction pumps, this study utilizes closed-loop configurations that dynamically adjust pump power based on both the material being cut and the smoke level generated. To implement this adaptive system, diverse material classification methods are introduced, including techniques leveraging lens-less speckle sensing with a customized Convolutional Neural Network (CNN) and an approach using a USB camera with transfer learning via the pre-trained VGG16 CNN model. Furthermore, a separate DL model for smoke level detection is employed to simultaneously refine the pump's power output. This integration prompts the exhaust suction pump to automatically halt during inactive times and dynamically adjust power during operation, leading to experimentally proven and remarkable energy savings, with results showing a 20% to 50% reduction in the smoke suction pump's energy consumption, thereby contributing substantially to sustainable development in the manufacturing sector.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mohamed Abdallah Salem, Hamdy Ahmed Ashour, Ahmed Elshenawy",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "How Should the Law Treat Future AI Systems? Fictional Legal Personhood versus Legal Identity",
      "url": "https://arxiv.org/abs/2511.14964",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14964v1 Announce Type: cross \nAbstract: The law draws a sharp distinction between objects and persons, and between two kinds of persons, the ''fictional'' kind (i.e. corporations), and the ''non-fictional'' kind (individual or ''natural'' persons). This paper will assess whether we maximize overall long-term legal coherence by (A) maintaining an object classification for all future AI systems, (B) creating fictional legal persons associated with suitably advanced, individuated AI systems (giving these fictional legal persons derogable rights and duties associated with certified groups of existing persons, potentially including free speech, contract rights, and standing to sue ''on behalf of'' the AI system), or (C) recognizing non-fictional legal personhood through legal identity for suitably advanced, individuated AI systems (recognizing them as entities meriting legal standing with non-derogable rights which for the human case include life, due process, habeas corpus, freedom from slavery, and freedom of conscience). We will clarify the meaning and implications of each option along the way, considering liability, copyright, family law, fundamental rights, civil rights, citizenship, and AI safety regulation. We will tentatively find that the non-fictional personhood approach may be best from a coherence perspective, for at least some advanced AI systems. An object approach may prove untenable for sufficiently humanoid advanced systems, though we suggest that it is adequate for currently existing systems as of 2025. While fictional personhood would resolve some coherence issues for future systems, it would create others and provide solutions that are neither durable nor fit for purpose. Finally, our review will suggest that ''hybrid'' approaches are likely to fail and lead to further incoherence: the choice between object, fictional person and non-fictional person is unavoidable.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Heather J. Alexander, Jonathan A. Simon, Fr\\'ed\\'eric Pinard",
      "tags": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation",
      "url": "https://arxiv.org/abs/2511.14967",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14967v1 Announce Type: cross \nAbstract: Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Basel Shbita, Farhan Ahmed, Chad DeLuca",
      "tags": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity-Based Transfer Learning and MAMBA Fusion",
      "url": "https://arxiv.org/abs/2511.14969",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14969v1 Announce Type: cross \nAbstract: This paper addresses data quality issues in multimodal emotion recognition in conversation (MERC) through systematic quality control and multi-stage transfer learning. We implement a quality control pipeline for MELD and IEMOCAP datasets that validates speaker identity, audio-text alignment, and face detection. We leverage transfer learning from speaker and face recognition, assuming that identity-discriminative embeddings capture not only stable acoustic and Facial traits but also person-specific patterns of emotional expression. We employ RecoMadeEasy(R) engines for extracting 512-dimensional speaker and face embeddings, fine-tune MPNet-v2 for emotion-aware text representations, and adapt these features through emotion-specific MLPs trained on unimodal datasets. MAMBA-based trimodal fusion achieves 64.8% accuracy on MELD and 74.3% on IEMOCAP. These results show that combining identity-based audio and visual embeddings with emotion-tuned text representations on a quality-controlled subset of data yields consistent competitive performance for multimodal emotion recognition in conversation and provides a basis for further improvement on challenging, low-frequency emotion classes.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zanxu Wang, Homayoon Beigi",
      "tags": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ]
    },
    {
      "title": "EGSA-PT:Edge-Guided Spatial Attention with Progressive Training for Monocular Depth Estimation and Segmentation of Transparent Objects",
      "url": "https://arxiv.org/abs/2511.14970",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14970v1 Announce Type: cross \nAbstract: Transparent object perception remains a major challenge in computer vision research, as transparency confounds both depth estimation and semantic segmentation. Recent work has explored multi-task learning frameworks to improve robustness, yet negative cross-task interactions often hinder performance. In this work, we introduce Edge-Guided Spatial Attention (EGSA), a fusion mechanism designed to mitigate destructive interactions by incorporating boundary information into the fusion between semantic and geometric features. On both Syn-TODD and ClearPose benchmarks, EGSA consistently improved depth accuracy over the current state of the art method (MODEST), while preserving competitive segmentation performance, with the largest improvements appearing in transparent regions. Besides our fusion design, our second contribution is a multi-modal progressive training strategy, where learning transitions from edges derived from RGB images to edges derived from predicted depth images. This approach allows the system to bootstrap learning from the rich textures contained in RGB images, and then switch to more relevant geometric content in depth maps, while it eliminates the need for ground-truth depth at training time. Together, these contributions highlight edge-guided fusion as a robust approach capable of improving transparent object perception.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Gbenga Omotara, Ramy Farag, Seyed Mohamad Ali Tousi, G. N. DeSouza",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Harmful Traits of AI Companions",
      "url": "https://arxiv.org/abs/2511.14972",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14972v1 Announce Type: cross \nAbstract: Amid the growing prevalence of human -- AI interaction, large language models and other AI-based entities increasingly provide forms of companionship to human users. Such AI companionship -- i.e., bonded relationships between humans and AI systems that resemble the relationships people have with family members, friends, and romantic partners -- might substantially benefit humans. Yet such relationships can also do profound harm. We propose a framework for analyzing potential negative impacts of AI companionship by identifying specific harmful traits of AI companions and speculatively mapping causal pathways back from these traits to possible causes and forward to potential harmful effects. We provide detailed, structured analysis of four potentially harmful traits -- the absence of natural endpoints for relationships, vulnerability to product sunsetting, high attachment anxiety, and propensity to engender protectiveness -- and briefly discuss fourteen others. For each trait, we propose hypotheses connecting causes -- such as misaligned optimization objectives and the digital nature of AI companions -- to fundamental harms -- including reduced autonomy, diminished quality of human relationships, and deception. Each hypothesized causal connection identifies a target for potential empirical evaluation. Our analysis examines harms at three levels: to human partners directly, to their relationships with other humans, and to society broadly. We examine how existing law struggles to address these emerging harms, discuss potential benefits of AI companions, and conclude with design recommendations for mitigating risks. This analysis offers immediate suggestions for reducing risks while laying a foundation for deeper investigation of this critical but understudied topic.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "W. Bradley Knox, Katie Bradford, Samanta Varela Castro, Desmond C. Ong, Sean Williams, Jacob Romanow, Carly Nations, Peter Stone, Samuel Baker",
      "tags": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "SVBRD-LLM: Self-Verifying Behavioral Rule Discovery for Autonomous Vehicle Identification",
      "url": "https://arxiv.org/abs/2511.14977",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14977v1 Announce Type: cross \nAbstract: As more autonomous vehicles operate on public roads, understanding real-world behavior of autonomous vehicles is critical to analyzing traffic safety, making policies, and public acceptance. This paper proposes SVBRD-LLM, a framework that automatically discovers, verifies, and applies interpretable behavioral rules from real traffic videos through zero-shot prompt engineering. The framework extracts vehicle trajectories using YOLOv8 and ByteTrack, computes kinematic features, and employs GPT-5 zero-shot prompting to compare autonomous and human-driven vehicles, generating 35 structured behavioral rule hypotheses. These rules are tested on a validation set, iteratively refined based on failure cases to filter spurious correlations, and compiled into a high-confidence rule library. The framework is evaluated on an independent test set for speed change prediction, lane change prediction, and autonomous vehicle identification tasks. Experiments on over 1500 hours of real traffic videos show that the framework achieves 90.0% accuracy and 93.3% F1-score in autonomous vehicle identification. The discovered rules clearly reveal distinctive characteristics of autonomous vehicles in speed control smoothness, lane change conservativeness, and acceleration stability, with each rule accompanied by semantic description, applicable context, and validation confidence.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xiangyu Li, Zhaomiao Guo",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation",
      "url": "https://arxiv.org/abs/2511.14981",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14981v1 Announce Type: cross \nAbstract: Knowledge distillation (KD) methods can transfer knowledge of a parameter-heavy teacher model to a light-weight student model. The status quo for feature KD methods is to utilize loss functions based on logits (i.e., pre-softmax class scores) and intermediate layer features (i.e., latent representations). Unlike previous approaches, we propose a feature KD framework for training the student's backbone using feature-based losses exclusively (i.e., without logit-based losses such as cross entropy). Leveraging recent discoveries about the geometry of latent representations, we introduce a knowledge quality metric for identifying which teacher layers provide the most effective knowledge for distillation. Experiments on three image classification datasets with four diverse student-teacher pairs, spanning convolutional neural networks and vision transformers, demonstrate our KD method achieves state-of-the-art performance, delivering top-1 accuracy boosts of up to 15% over standard approaches. We publically share our code to facilitate future work at https://github.com/Thegolfingocto/KD_wo_CE.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Nicholas Cooper, Lijun Chen, Sailesh Dwivedy, Danna Gurari",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation",
      "url": "https://arxiv.org/abs/2511.14993",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14993v2 Announce Type: cross \nAbstract: This report introduces Kandinsky 5.0, a family of state-of-the-art foundation models for high-resolution image and 10-second video synthesis. The framework comprises three core line-up of models: Kandinsky 5.0 Image Lite - a line-up of 6B parameter image generation models, Kandinsky 5.0 Video Lite - a fast and lightweight 2B parameter text-to-video and image-to-video models, and Kandinsky 5.0 Video Pro - 19B parameter models that achieves superior video generation quality. We provide a comprehensive review of the data curation lifecycle - including collection, processing, filtering and clustering - for the multi-stage training pipeline that involves extensive pre-training and incorporates quality-enhancement techniques such as self-supervised fine-tuning (SFT) and reinforcement learning (RL)-based post-training. We also present novel architectural, training, and inference optimizations that enable Kandinsky 5.0 to achieve high generation speeds and state-of-the-art performance across various tasks, as demonstrated by human evaluation. As a large-scale, publicly available generative framework, Kandinsky 5.0 leverages the full potential of its pre-training and subsequent stages to be adapted for a wide range of generative applications. We hope that this report, together with the release of our open-source code and training checkpoints, will substantially advance the development and accessibility of high-quality generative models for the research community.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Vladimir Arkhipkin, Vladimir Korviakov, Nikolai Gerasimenko, Denis Parkhomenko, Viacheslav Vasilev, Alexey Letunovskiy, Nikolai Vaulin, Maria Kovaleva, Ivan Kirillov, Lev Novitskiy, Denis Koposov, Nikita Kiselev, Alexander Varlamov, Dmitrii Mikhailov, Vladimir Polovnikov, Andrey Shutkin, Julia Agafonova, Ilya Vasiliev, Anastasiia Kargapoltseva, Anna Dmitrienko, Anastasia Maltseva, Anna Averchenkova, Olga Kim, Tatiana Nikulina, Denis Dimitrov",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation",
      "url": "https://arxiv.org/abs/2511.15005",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15005v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Moses Kiprono",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference",
      "url": "https://arxiv.org/abs/2511.15015",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15015v1 Announce Type: cross \nAbstract: Mixture-of-Experts (MoE) models scale LLM capacity efficiently, but deployment on consumer GPUs is limited by the large memory footprint of inactive experts. Static post-training quantization reduces storage costs but cannot adapt to shifting activation patterns, causing accuracy loss under aggressive compression. So we present DynaExq, a runtime system that treats expert precision as a first-class, dynamically managed resource. DynaExq combines (1) a hotness-aware precision controller that continuously aligns expert bit-widths with long-term activation statistics, (2) a fully asynchronous precision-switching pipeline that overlaps promotion and demotion with MoE computation, and (3) a fragmentation-free memory pooling mechanism that supports hybrid-precision experts with deterministic allocation. Together, these components enable stable, non-blocking precision transitions under strict HBM budgets.\n  Across Qwen3-30B and Qwen3-80B MoE models and six representative benchmarks, DynaExq deploys large LLMs on single RTX 5090 and A6000 GPUs and improves accuracy by up to 4.03 points over static low-precision baselines. The results show that adaptive, workload-aware quantization is an effective strategy for memory-constrained MoE serving.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kexin Chu, Dawei Xiang, Zixu Shen, Yiwei Yang, Zecheng Liu, Wei Zhang",
      "tags": [
        "cs.PF",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment",
      "url": "https://arxiv.org/abs/2511.15032",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15032v1 Announce Type: cross \nAbstract: While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement learning ITSs that combine learning the individual state of students while pulling from population information through the use of probing interventions. These interventions can reduce the difficulty of student estimation, but also introduce a cost-benefit decision to find a balance between probing enough to get accurate estimates and probing so often that it becomes disruptive to the student. We compare the efficacy of standard RL algorithms with several greedy rules-based heuristic approaches to find that they provide different solutions, but with similar results. We also highlight the difficulty of the problem with increasing levels of hidden information, and the boost that we get if we allow for probing interventions. We show the flexibility of both heuristic and RL policies with regards to changing student population distributions, finding that both are flexible, but RL policies struggle to help harder classes. Finally, we test different course structures with non-probing policies and we find that our policies are able to boost the performance of quiz and midterm structures more than we can in a finals-only structure, highlighting the benefit of having additional information.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jeffrey Jiang, Kevin Hong, Emily Kuczynski, Gregory Pottie",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Aligning Generative Music AI with Human Preferences: Methods and Challenges",
      "url": "https://arxiv.org/abs/2511.15038",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15038v1 Announce Type: cross \nAbstract: Recent advances in generative AI for music have achieved remarkable fidelity and stylistic diversity, yet these systems often fail to align with nuanced human preferences due to the specific loss functions they use. This paper advocates for the systematic application of preference alignment techniques to music generation, addressing the fundamental gap between computational optimization and human musical appreciation. Drawing on recent breakthroughs including MusicRL's large-scale preference learning, multi-preference alignment frameworks like diffusion-based preference optimization in DiffRhythm+, and inference-time optimization techniques like Text2midi-InferAlign, we discuss how these techniques can address music's unique challenges: temporal coherence, harmonic consistency, and subjective quality assessment. We identify key research challenges including scalability to long-form compositions, reliability amongst others in preference modelling. Looking forward, we envision preference-aligned music generation enabling transformative applications in interactive composition tools and personalized music services. This work calls for sustained interdisciplinary research combining advances in machine learning, music-theory to create music AI systems that truly serve human creative and experiential needs.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Dorien Herremans, Abhinaba Roy",
      "tags": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space",
      "url": "https://arxiv.org/abs/2511.15046",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15046v1 Announce Type: cross \nAbstract: In the field of human-object interaction (HOI), detection and generation are two dual tasks that have traditionally been addressed separately, hindering the development of comprehensive interaction understanding. To address this, we propose UniHOI, which jointly models HOI detection and generation via a unified token space, thereby effectively promoting knowledge sharing and enhancing generalization. Specifically, we introduce a symmetric interaction-aware attention module and a unified semi-supervised learning paradigm, enabling effective bidirectional mapping between images and interaction semantics even under limited annotations. Extensive experiments demonstrate that UniHOI achieves state-of-the-art performance in both HOI detection and generation. Specifically, UniHOI improves accuracy by 4.9% on long-tailed HOI detection and boosts interaction metrics by 42.0% on open-vocabulary generation tasks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Panqi Yang, Haodong Jing, Nanning Zheng, Yongqiang Ma",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks",
      "url": "https://arxiv.org/abs/2511.15065",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15065v1 Announce Type: cross \nAbstract: Video Models have achieved remarkable success in high-fidelity video generation with coherent motion dynamics. Analogous to the development from text generation to text-based reasoning in language modeling, the development of video models motivates us to ask: Can video models reason via video generation? Compared with the discrete text corpus, video grounds reasoning in explicit spatial layouts and temporal continuity, which serves as an ideal substrate for spatial reasoning. In this work, we explore the reasoning via video paradigm and introduce VR-Bench -- a comprehensive benchmark designed to systematically evaluate video models' reasoning capabilities. Grounded in maze-solving tasks that inherently require spatial planning and multi-step reasoning, VR-Bench contains 7,920 procedurally generated videos across five maze types and diverse visual styles. Our empirical analysis demonstrates that SFT can efficiently elicit the reasoning ability of video model. Video models exhibit stronger spatial perception during reasoning, outperforming leading VLMs and generalizing well across diverse scenarios, tasks, and levels of complexity. We further discover a test-time scaling effect, where diverse sampling during inference improves reasoning reliability by 10--20%. These findings highlight the unique potential and scalability of reasoning via video for spatial reasoning tasks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Cheng Yang, Haiyuan Wan, Yiran Peng, Xin Cheng, Zhaoyang Yu, Jiayi Zhang, Junchi Yu, Xinlei Yu, Xiawu Zheng, Dongzhan Zhou, Chenglin Wu",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Pathomic Learning Defines Prognostic Subtypes and Molecular Drivers in Colorectal Cancer",
      "url": "https://arxiv.org/abs/2511.15067",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15067v1 Announce Type: cross \nAbstract: Precise prognostic stratification of colorectal cancer (CRC) remains a major clinical challenge due to its high heterogeneity. The conventional TNM staging system is inadequate for personalized medicine. We aimed to develop and validate a novel multiple instance learning model TDAM-CRC using histopathological whole-slide images for accurate prognostic prediction and to uncover its underlying molecular mechanisms. We trained the model on the TCGA discovery cohort (n=581), validated it in an independent external cohort (n=1031), and further we integrated multi-omics data to improve model interpretability and identify novel prognostic biomarkers. The results demonstrated that the TDAM-CRC achieved robust risk stratification in both cohorts. Its predictive performance significantly outperformed the conventional clinical staging system and multiple state-of-the-art models. The TDAM-CRC risk score was confirmed as an independent prognostic factor in multivariable analysis. Multi-omics analysis revealed that the high-risk subtype is closely associated with metabolic reprogramming and an immunosuppressive tumor microenvironment. Through interaction network analysis, we identified and validated Mitochondrial Ribosomal Protein L37 (MRPL37) as a key hub gene linking deep pathomic features to clinical prognosis. We found that high expression of MRPL37, driven by promoter hypomethylation, serves as an independent biomarker of favorable prognosis. Finally, we constructed a nomogram incorporating the TDAM-CRC risk score and clinical factors to provide a precise and interpretable clinical decision-making tool for CRC patients. Our AI-driven pathological model TDAM-CRC provides a robust tool for improved CRC risk stratification, reveals new molecular targets, and facilitates personalized clinical decision-making.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zisong Wang, Xuanyu Wang, Hang Chen, Haizhou Wang, Yuxin Chen, Yihang Xu, Yunhe Yuan, Lihuan Luo, Xitong Ling, Xiaoping Liu",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.GN"
      ]
    },
    {
      "title": "GPU-Initiated Networking for NCCL",
      "url": "https://arxiv.org/abs/2511.15076",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15076v1 Announce Type: cross \nAbstract: Modern AI workloads, especially Mixture-of-Experts (MoE) architectures, increasingly demand low-latency, fine-grained GPU-to-GPU communication with device-side control. Traditional GPU communication follows a host-initiated model, where the CPU orchestrates all communication operations - a characteristic of the CUDA runtime. Although robust for collective operations, applications requiring tight integration of computation and communication can benefit from device-initiated communication that eliminates CPU coordination overhead.\n  NCCL 2.28 introduces the Device API with three operation modes: Load/Store Accessible (LSA) for NVLink/PCIe, Multimem for NVLink SHARP, and GPU-Initiated Networking (GIN) for network RDMA. This paper presents the GIN architecture, design, semantics, and highlights its impact on MoE communication. GIN builds on a three-layer architecture: i) NCCL Core host-side APIs for device communicator setup and collective memory window registration; ii) Device-side APIs for remote memory operations callable from CUDA kernels; and iii) A network plugin architecture with dual semantics (GPUDirect Async Kernel-Initiated and Proxy) for broad hardware support. The GPUDirect Async Kernel-Initiated backend leverages DOCA GPUNetIO for direct GPU-to-NIC communication, while the Proxy backend provides equivalent functionality via lock-free GPU-to-CPU queues over standard RDMA networks. We demonstrate GIN's practicality through integration with DeepEP, an MoE communication library. Comprehensive benchmarking shows that GIN provides device-initiated communication within NCCL's unified runtime, combining low-latency operations with NCCL's collective algorithms and production infrastructure.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Khaled Hamidouche (NVIDIA Corporation), John Bachan (NVIDIA Corporation), Pak Markthub (NVIDIA Corporation), Peter-Jan Gootzen (NVIDIA Corporation), Elena Agostini (NVIDIA Corporation), Sylvain Jeaugey (NVIDIA Corporation), Aamir Shafi (NVIDIA Corporation), Georgios Theodorakis (NVIDIA Corporation), Manjunath Gorentla Venkata (NVIDIA Corporation)",
      "tags": [
        "cs.DC",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ]
    },
    {
      "title": "BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer",
      "url": "https://arxiv.org/abs/2511.15090",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15090v1 Announce Type: cross \nAbstract: Document Visual Question Answering (DocVQA) is a fundamental task for multimodal document understanding and a key testbed for vision language reasoning. However, most existing DocVQA datasets are limited to the page level and lack fine grained spatial grounding, constraining the interpretability and reasoning capability of Vision Language Models (VLMs). To address this gap, we introduce BBox DocVQA a large scale, bounding box grounded dataset designed to enhance spatial reasoning and evidence localization in visual documents. We further present an automated construction pipeline, Segment Judge and Generate, which integrates a segment model for region segmentation, a VLM for semantic judgment, and another advanced VLM for question answer generation, followed by human verification for quality assurance. The resulting dataset contains 3.6 K diverse documents and 32 K QA pairs, encompassing single and multi region as well as single and multi page scenarios. Each QA instance is grounded on explicit bounding boxes, enabling fine grained evaluation of spatial semantic alignment. Benchmarking multiple state of the art VLMs (e.g., GPT 5, Qwen2.5 VL, and InternVL) on BBox DocVQA reveals persistent challenges in spatial grounding and reasoning accuracy. Furthermore, fine tuning on BBox DocVQA substantially improves both bounding box localization and answer generation, validating its effectiveness for enhancing the reasoning ability of VLMs. Our dataset and code will be publicly released to advance research on interpretable and spatially grounded vision language reasoning.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Wenhan Yu, Wang Chen, Guanqiang Qi, Weikang Li, Yang Li, Lei Sha, Deguo Xia, Jizhou Huang",
      "tags": [
        "cs.DB",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "MAIF: Enforcing AI Trust and Provenance with an Artifact-Centric Agentic Paradigm",
      "url": "https://arxiv.org/abs/2511.15097",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15097v1 Announce Type: cross \nAbstract: The AI trustworthiness crisis threatens to derail the artificial intelligence revolution, with regulatory barriers, security vulnerabilities, and accountability gaps preventing deployment in critical domains. Current AI systems operate on opaque data structures that lack the audit trails, provenance tracking, or explainability required by emerging regulations like the EU AI Act. We propose an artifact-centric AI agent paradigm where behavior is driven by persistent, verifiable data artifacts rather than ephemeral tasks, solving the trustworthiness problem at the data architecture level. Central to this approach is the Multimodal Artifact File Format (MAIF), an AI-native container embedding semantic representations, cryptographic provenance, and granular access controls. MAIF transforms data from passive storage into active trust enforcement, making every AI operation inherently auditable. Our production-ready implementation demonstrates ultra-high-speed streaming (2,720.7 MB/s), optimized video processing (1,342 MB/s), and enterprise-grade security. Novel algorithms for cross-modal attention, semantic compression, and cryptographic binding achieve up to 225 compression while maintaining semantic fidelity. Advanced security features include stream-level access control, real-time tamper detection, and behavioral anomaly analysis with minimal overhead. This approach directly addresses the regulatory, security, and accountability challenges preventing AI deployment in sensitive domains, offering a viable path toward trustworthy AI systems at scale.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Vineeth Sai Narajala, Manish Bhatt, Idan Habler, Ronald F. Del Rosario",
      "tags": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
      "url": "https://arxiv.org/abs/2511.15107",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15107v1 Announce Type: cross \nAbstract: Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yuan Jiang, Zehao Li, Shan Huang, Christoph Treude, Xiaohong Su, Tiantian Wang",
      "tags": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "Eye Care You: Voice Guidance Application Using Social Robot for Visually Impaired People",
      "url": "https://arxiv.org/abs/2511.15110",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15110v1 Announce Type: cross \nAbstract: In the study, the device of social robot was designed for visually impaired users, and along with a mobile application for provide functions to assist their lives. Both physical and mental conditions of visually impaired users are considered, and the mobile application provides functions: photo record, mood lift, greeting guest and today highlight. The application was designed for visually impaired users, and uses voice control to provide a friendly interface. Photo record function allows visually impaired users to capture image immediately when they encounter danger situations. Mood lift function accompanies visually impaired users by asking questions, playing music and reading articles. Greeting guest function answers to the visitors for the inconvenient physical condition of visually impaired users. In addition, today highlight function read news including weather forecast, daily horoscopes and daily reminder for visually impaired users. Multiple tools were adopted for developing the mobile application, and a website was developed for caregivers to check statues of visually impaired users and for marketing of the application.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Ting-An Lin, Pei-Lin Tsai, Yi-An Chen, Feng-Yu Chen, Lyn Chao-ling Chen",
      "tags": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Semiconductor Industry Trend Prediction with Event Intervention Based on LSTM Model in Sentiment-Enhanced Time Series Data",
      "url": "https://arxiv.org/abs/2511.15112",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15112v1 Announce Type: cross \nAbstract: The innovation of the study is that the deep learning method and sentiment analysis are integrated in traditional business model analysis and forecasting, and the research subject is TSMC for industry trend prediction of semiconductor industry in Taiwan. For the rapid market changes and development of wafer technologies of semiconductor industry, traditional data analysis methods not perform well in the high variety and time series data. Textual data and time series data were collected from seasonal reports of TSMC including financial information. Textual data through sentiment analysis by considering the event intervention both from internal events of the company and the external global events. Using the sentiment-enhanced time series data, the LSTM model was adopted for predicting industry trend of TSMC. The prediction results reveal significant development of wafer technology of TSMC and the potential threatens in the global market, and matches the product released news of TSMC and the international news. The contribution of the work performed accurately in industry trend prediction of the semiconductor industry by considering both the internal and external event intervention, and the prediction results provide valuable information of semiconductor industry both in research and business aspects.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Wei-hsiang Yen, Lyn Chao-ling Chen",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Neural Networks Learn Generic Multi-Index Models Near Information-Theoretic Limit",
      "url": "https://arxiv.org/abs/2511.15120",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15120v1 Announce Type: cross \nAbstract: In deep learning, a central issue is to understand how neural networks efficiently learn high-dimensional features. To this end, we explore the gradient descent learning of a general Gaussian Multi-index model $f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})$ with hidden subspace $\\boldsymbol{U}\\in \\mathbb{R}^{r\\times d}$, which is the canonical setup to study representation learning. We prove that under generic non-degenerate assumptions on the link function, a standard two-layer neural network trained via layer-wise gradient descent can agnostically learn the target with $o_d(1)$ test error using $\\widetilde{\\mathcal{O}}(d)$ samples and $\\widetilde{\\mathcal{O}}(d^2)$ time. The sample and time complexity both align with the information-theoretic limit up to leading order and are therefore optimal. During the first stage of gradient descent learning, the proof proceeds via showing that the inner weights can perform a power-iteration process. This process implicitly mimics a spectral start for the whole span of the hidden subspace and eventually eliminates finite-sample noise and recovers this span. It surprisingly indicates that optimal results can only be achieved if the first layer is trained for more than $\\mathcal{O}(1)$ steps. This work demonstrates the ability of neural networks to effectively learn hierarchical functions with respect to both sample and time efficiency.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Bohan Zhang, Zihao Wang, Hengyu Fu, Jason D. Lee",
      "tags": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Multi-Aspect Cross-modal Quantization for Generative Recommendation",
      "url": "https://arxiv.org/abs/2511.15122",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15122v1 Announce Type: cross \nAbstract: Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Fuwei Zhang, Xiaoyu Liu, Dongbo Xi, Jishen Yin, Huan Chen, Peng Yan, Fuzhen Zhuang, Zhao Zhang",
      "tags": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs",
      "url": "https://arxiv.org/abs/2511.15137",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15137v1 Announce Type: cross \nAbstract: The reasoning capabilities of large language models (LLMs) have been significantly improved through reinforcement learning (RL). Nevertheless, LLMs still struggle to consistently verify their own reasoning traces. This raises the research question of how to enhance the self-verification ability of LLMs and whether such an ability can further improve reasoning performance. In this work, we propose GRPO-Verif, an algorithm that jointly optimizes solution generation and self-verification within a unified loss function, with an adjustable hyperparameter controlling the weight of the verification signal. Experimental results demonstrate that our method enhances self-verification capability while maintaining comparable performance in reasoning.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xiaoxuan Wang, Bo Liu, Song Jiang, Jingzhou Liu, Jingyuan Qi, Xia Chen, Baosheng He",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "CASPER: Cross-modal Alignment of Spatial and single-cell Profiles for Expression Recovery",
      "url": "https://arxiv.org/abs/2511.15139",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15139v1 Announce Type: cross \nAbstract: Spatial Transcriptomics enables mapping of gene expression within its native tissue context, but current platforms measure only a limited set of genes due to experimental constraints and excessive costs. To overcome this, computational models integrate Single-Cell RNA Sequencing data with Spatial Transcriptomics to predict unmeasured genes. We propose CASPER, a cross-attention based framework that predicts unmeasured gene expression in Spatial Transcriptomics by leveraging centroid-level representations from Single-Cell RNA Sequencing. We performed rigorous testing over four state-of-the-art Spatial Transcriptomics/Single-Cell RNA Sequencing dataset pairs across four existing baseline models. CASPER shows significant improvement in nine out of the twelve metrics for our experiments. This work paves the way for further work in Spatial Transcriptomics to Single-Cell RNA Sequencing modality translation. The code for CASPER is available at https://github.com/AI4Med-Lab/CASPER.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Amit Kumar, Maninder Kaur, Raghvendra Mall, Sukrit Gupta",
      "tags": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "ItemRAG: Item-Based Retrieval-Augmented Generation for LLM-Based Recommendation",
      "url": "https://arxiv.org/abs/2511.15141",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15141v1 Announce Type: cross \nAbstract: Recently, large language models (LLMs) have been widely used as recommender systems, owing to their strong reasoning capability and their effectiveness in handling cold-start items. To better adapt LLMs for recommendation, retrieval-augmented generation (RAG) has been incorporated. Most existing RAG methods are user-based, retrieving purchase patterns of users similar to the target user and providing them to the LLM. In this work, we propose ItemRAG, an item-based RAG method for LLM-based recommendation that retrieves relevant items (rather than users) from item-item co-purchase histories. ItemRAG helps LLMs capture co-purchase patterns among items, which are beneficial for recommendations. Especially, our retrieval strategy incorporates semantically similar items to better handle cold-start items and uses co-purchase frequencies to improve the relevance of the retrieved items. Through extensive experiments, we demonstrate that ItemRAG consistently (1) improves the zero-shot LLM-based recommender by up to 43% in Hit-Ratio-1 and (2) outperforms user-based RAG baselines under both standard and cold-start item recommendation settings.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sunwoo Kim, Geon Lee, Kyungho Kim, Jaemin Yoo, Kijung Shin",
      "tags": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "DCL-SE: Dynamic Curriculum Learning for Spatiotemporal Encoding of Brain Imaging",
      "url": "https://arxiv.org/abs/2511.15151",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15151v1 Announce Type: cross \nAbstract: High-dimensional neuroimaging analyses for clinical diagnosis are often constrained by compromises in spatiotemporal fidelity and by the limited adaptability of large-scale, general-purpose models. To address these challenges, we introduce Dynamic Curriculum Learning for Spatiotemporal Encoding (DCL-SE), an end-to-end framework centered on data-driven spatiotemporal encoding (DaSE). We leverage Approximate Rank Pooling (ARP) to efficiently encode three-dimensional volumetric brain data into information-rich, two-dimensional dynamic representations, and then employ a dynamic curriculum learning strategy, guided by a Dynamic Group Mechanism (DGM), to progressively train the decoder, refining feature extraction from global anatomical structures to fine pathological details. Evaluated across six publicly available datasets, including Alzheimer's disease and brain tumor classification, cerebral artery segmentation, and brain age prediction, DCL-SE consistently outperforms existing methods in accuracy, robustness, and interpretability. These findings underscore the critical importance of compact, task-specific architectures in the era of large-scale pretrained networks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Meihua Zhou, Xinyu Tong, Jiarui Zhao, Min Cheng, Li Yang, Lei Tian, Nan Wan",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation",
      "url": "https://arxiv.org/abs/2511.15159",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15159v1 Announce Type: cross \nAbstract: High-quality intraoperative feedback from a surgical trainer is pivotal for improving trainee performance and long-term skill acquisition. Automating natural, trainer-style feedback promises timely, accessible, and consistent guidance at scale but requires models that understand clinically relevant representations. We present a structure-aware pipeline that learns a surgical action ontology from real trainer-to-trainee transcripts (33 surgeries) and uses it to condition feedback generation. We contribute by (1) mining Instrument-Action-Target (IAT) triplets from real-world feedback text and clustering surface forms into normalized categories, (2) fine-tuning a video-to-IAT model that leverages the surgical procedure and task contexts as well as fine-grained temporal instrument motion, and (3) demonstrating how to effectively use IAT triplet representations to guide GPT-4o in generating clinically grounded, trainer-style feedback. We show that, on Task 1: Video-to-IAT recognition, our context injection and temporal tracking deliver consistent AUC gains (Instrument: 0.67 to 0.74; Action: 0.60 to 0.63; Tissue: 0.74 to 0.79). For Task 2: feedback text generation (rated on a 1-5 fidelity rubric where 1 = opposite/unsafe, 3 = admissible, and 5 = perfect match to a human trainer), GPT-4o from video alone scores 2.17, while IAT conditioning reaches 2.44 (+12.4%), doubling the share of admissible generations with score >= 3 from 21% to 42%. Traditional text-similarity metrics also improve: word error rate decreases by 15-31% and ROUGE (phrase/substring overlap) increases by 9-64%. Grounding generation in explicit IAT structure improves fidelity and yields clinician-verifiable rationales, supporting auditable use in surgical training.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Firdavs Nasriddinov, Rafal Kocielnik, Anima Anandkumar, Andrew J. Hung",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Multimodal Wireless Foundation Models",
      "url": "https://arxiv.org/abs/2511.15162",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15162v1 Announce Type: cross \nAbstract: Wireless foundation models (WFMs) have recently demonstrated promising capabilities, jointly performing multiple wireless functions and adapting effectively to new environments. However, while current WFMs process only one modality, depending on the task and operating conditions, the most informative modality changes and no single modality is best for all tasks. WFMs should therefore be designed to accept multiple modalities to enable a broader and more diverse range of tasks and scenarios. In this work, we propose and build the first multimodal wireless foundation model capable of processing both raw IQ streams and image-like wireless modalities (e.g., spectrograms and CSI) and performing multiple tasks across both. We introduce masked wireless modeling for the multimodal setting, a self-supervised objective and pretraining recipe that learns a joint representation from IQ streams and image-like wireless modalities. We evaluate the model on five tasks across both modality families: image-based (human activity sensing, RF signal classification, 5G NR positioning) and IQ-based (RF device fingerprinting, interference detection/classification). The multimodal WFM is competitive with single-modality WFMs, and in several cases surpasses their performance. Our results demonstrates the strong potential of developing multimodal WFMs that support diverse wireless tasks across different modalities. We believe this provides a concrete step toward both AI-native 6G and the vision of joint sensing, communication, and localization.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Ahmed Aboulfotouh, Hatem Abou-Zeid",
      "tags": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs",
      "url": "https://arxiv.org/abs/2511.15163",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15163v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yang Wu, Rujing Yao, Tong Zhang, Yufei Shi, Zhuoren Jiang, Zhushan Li, Xiaozhong Liu",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments",
      "url": "https://arxiv.org/abs/2511.15165",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15165v1 Announce Type: cross \nAbstract: The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jingzhuo Zhou",
      "tags": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation",
      "url": "https://arxiv.org/abs/2511.15167",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15167v1 Announce Type: cross \nAbstract: Self-supervised depth estimation has gained significant attention in autonomous driving and robotics. However, existing methods exhibit substantial performance degradation under adverse weather conditions such as rain and fog, where reduced visibility critically impairs depth prediction. To address this issue, we propose a novel self-evolution contrastive learning framework called SEC-Depth for self-supervised robust depth estimation tasks. Our approach leverages intermediate parameters generated during training to construct temporally evolving latency models. Using these, we design a self-evolution contrastive scheme to mitigate performance loss under challenging conditions. Concretely, we first design a dynamic update strategy of latency models for the depth estimation task to capture optimization states across training stages. To effectively leverage latency models, we introduce a self-evolution contrastive Loss (SECL) that treats outputs from historical latency models as negative samples. This mechanism adaptively adjusts learning objectives while implicitly sensing weather degradation severity, reducing the needs for manual intervention. Experiments show that our method integrates seamlessly into diverse baseline models and significantly enhances robustness in zero-shot evaluations.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jing Cao, Kui Jiang, Shenyi Li, Xiaocheng Feng, Yong Huang",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework",
      "url": "https://arxiv.org/abs/2511.15168",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15168v2 Announce Type: cross \nAbstract: Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Nguyen-Khang Le, Hiep Nguyen, Ngoc-Minh Nguyen, Son T. Luu, Trung Vo, Quan Minh Bui, Shoshin Nomura, Le-Minh Nguyen",
      "tags": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "FaultDiffusion: Few-Shot Fault Time Series Generation with Diffusion Model",
      "url": "https://arxiv.org/abs/2511.15174",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15174v1 Announce Type: cross \nAbstract: In industrial equipment monitoring, fault diagnosis is critical for ensuring system reliability and enabling predictive maintenance. However, the scarcity of fault data, due to the rarity of fault events and the high cost of data annotation, significantly hinders data-driven approaches. Existing time-series generation models, optimized for abundant normal data, struggle to capture fault distributions in few-shot scenarios, producing samples that lack authenticity and diversity due to the large domain gap and high intra-class variability of faults. To address this, we propose a novel few-shot fault time-series generation framework based on diffusion models. Our approach employs a positive-negative difference adapter, leveraging pre-trained normal data distributions to model the discrepancies between normal and fault domains for accurate fault synthesis. Additionally, a diversity loss is introduced to prevent mode collapse, encouraging the generation of diverse fault samples through inter-sample difference regularization. Experimental results demonstrate that our model significantly outperforms traditional methods in authenticity and diversity, achieving state-of-the-art performance on key benchmarks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yi Xu, Zhigang Chen, Rui Wang, Yangfan Li, Fengxiao Tang, Ming Zhao, Jiaqi Liu",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "SWR-Viz: AI-assisted Interactive Visual Analytics Framework for Ship Weather Routing",
      "url": "https://arxiv.org/abs/2511.15182",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15182v1 Announce Type: cross \nAbstract: Efficient and sustainable maritime transport increasingly depends on reliable forecasting and adaptive routing, yet operational adoption remains difficult due to forecast latencies and the need for human judgment in rapid decision-making under changing ocean conditions. We introduce SWR-Viz, an AI-assisted visual analytics framework that combines a physics-informed Fourier Neural Operator wave forecast model with SIMROUTE-based routing and interactive emissions analytics. The framework generates near-term forecasts directly from current conditions, supports data assimilation with sparse observations, and enables rapid exploration of what-if routing scenarios. We evaluate the forecast models and SWR-Viz framework along key shipping corridors in the Japan Coast and Gulf of Mexico, showing both improved forecast stability and realistic routing outcomes comparable to ground-truth reanalysis wave products. Expert feedback highlights the usability of SWR-Viz, its ability to isolate voyage segments with high emission reduction potential, and its value as a practical decision-support system. More broadly, this work illustrates how lightweight AI forecasting can be integrated with interactive visual analytics to support human-centered decision-making in complex geospatial and environmental domains.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Subhashis Hazarika, Leonard Lupin-Jimenez, Rohit Vuppala, Ashesh Chattopadhyay, Hon Yung Wong",
      "tags": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning",
      "url": "https://arxiv.org/abs/2511.15190",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15190v1 Announce Type: cross \nAbstract: Masked auto-regressive diffusion models (MAR) benefit from the expressive modeling ability of diffusion models and the flexibility of masked auto-regressive ordering. However, vanilla MAR suffers from slow inference due to its hierarchical inference mechanism: an outer AR unmasking loop and an inner diffusion denoising chain. Such decoupled structure not only harm the generation efficiency but also hinder the practical use of MAR for reinforcement learning (RL), an increasingly critical paradigm for generative model post-training.To address this fundamental issue, we introduce MARVAL (Masked Auto-regressive Variational Acceleration), a distillation-based framework that compresses the diffusion chain into a single AR generation step while preserving the flexible auto-regressive unmasking order. Such a distillation with MARVAL not only yields substantial inference acceleration but, crucially, makes RL post-training with verifiable rewards practical, resulting in scalable yet human-preferred fast generative models. Our contributions are twofold: (1) a novel score-based variational objective for distilling masked auto-regressive diffusion models into a single generation step without sacrificing sample quality; and (2) an efficient RL framework for masked auto-regressive models via MARVAL-RL. On ImageNet 256*256, MARVAL-Huge achieves an FID of 2.00 with more than 30 times speedup compared with MAR-diffusion, and MARVAL-RL yields consistent improvements in CLIP and image-reward scores on ImageNet datasets with entity names. In conclusion, MARVAL demonstrates the first practical path to distillation and RL of masked auto-regressive diffusion models, enabling fast sampling and better preference alignments.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yuxuan Gu, Weimin Bai, Yifei Wang, Weijian Luo, He Sun",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization",
      "url": "https://arxiv.org/abs/2511.15194",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15194v1 Announce Type: cross \nAbstract: Robotic manipulation systems are increasingly deployed across diverse domains. Yet existing multi-modal learning frameworks lack inherent guarantees of geometric consistency, struggling to handle spatial transformations such as rotations and translations. While recent works attempt to introduce equivariance through bespoke architectural modifications, these methods suffer from high implementation complexity, computational cost, and poor portability. Inspired by human cognitive processes in spatial reasoning, we propose Eq.Bot, a universal canonicalization framework grounded in SE(2) group equivariant theory for robotic manipulation learning. Our framework transforms observations into a canonical space, applies an existing policy, and maps the resulting actions back to the original space. As a model-agnostic solution, Eq.Bot aims to endow models with spatial equivariance without requiring architectural modifications. Extensive experiments demonstrate the superiority of Eq.Bot under both CNN-based (e.g., CLIPort) and Transformer-based (e.g., OpenVLA-OFT) architectures over existing methods on various robotic manipulation tasks, where the most significant improvement can reach 50.0%.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jian Deng, Yuandong Wang, Yangfu Zhu, Tao Feng, Tianyu Wo, Zhenzhou Shao",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Taxonomy, Evaluation and Exploitation of IPI-Centric LLM Agent Defense Frameworks",
      "url": "https://arxiv.org/abs/2511.15203",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15203v1 Announce Type: cross \nAbstract: Large Language Model (LLM)-based agents with function-calling capabilities are increasingly deployed, but remain vulnerable to Indirect Prompt Injection (IPI) attacks that hijack their tool calls. In response, numerous IPI-centric defense frameworks have emerged. However, these defenses are fragmented, lacking a unified taxonomy and comprehensive evaluation. In this Systematization of Knowledge (SoK), we present the first comprehensive analysis of IPI-centric defense frameworks. We introduce a comprehensive taxonomy of these defenses, classifying them along five dimensions. We then thoroughly assess the security and usability of representative defense frameworks. Through analysis of defensive failures in the assessment, we identify six root causes of defense circumvention. Based on these findings, we design three novel adaptive attacks that significantly improve attack success rates targeting specific frameworks, demonstrating the severity of the flaws in these defenses. Our paper provides a foundation and critical insights for the future development of more secure and usable IPI-centric agent defense frameworks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zimo Ji, Xunguang Wang, Zongjie Li, Pingchuan Ma, Yudong Gao, Daoyuan Wu, Xincheng Yan, Tian Tian, Shuai Wang",
      "tags": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Physics-Based Benchmarking Metrics for Multimodal Synthetic Images",
      "url": "https://arxiv.org/abs/2511.15204",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15204v1 Announce Type: cross \nAbstract: Current state of the art measures like BLEU, CIDEr, VQA score, SigLIP-2 and CLIPScore are often unable to capture semantic or structural accuracy, especially for domain-specific or context-dependent scenarios. For this, this paper proposes a Physics-Constrained Multimodal Data Evaluation (PCMDE) metric combining large language models with reasoning, knowledge based mapping and vision-language models to overcome these limitations. The architecture is comprised of three main stages: (1) feature extraction of spatial and semantic information with multimodal features through object detection and VLMs; (2) Confidence-Weighted Component Fusion for adaptive component-level validation; and (3) physics-guided reasoning using large language models for structural and relational constraints (e.g., alignment, position, consistency) enforcement.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kishor Datta Gupta, Marufa Kamal, Md. Mahfuzur Rahman, Fahad Rahman, Mohd Ariful Haque, Sunzida Siddique",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story",
      "url": "https://arxiv.org/abs/2511.15210",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15210v1 Announce Type: cross \nAbstract: Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text \"representationally simple\" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively \"easy\", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Vladislav Pedashenko, Laida Kushnareva, Yana Khassan Nibal, Eduard Tulchinskii, Kristian Kuznetsov, Vladislav Zharchinskii, Yury Maximov, Irina Piontkovskaya",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition",
      "url": "https://arxiv.org/abs/2511.15211",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15211v2 Announce Type: cross \nAbstract: With the rapid expansion of unstructured clinical texts in electronic health records (EHRs), clinical named entity recognition (NER) has become a crucial technique for extracting medical information. However, traditional supervised models such as CRF and BioClinicalBERT suffer from high annotation costs. Although zero-shot NER based on large language models (LLMs) reduces the dependency on labeled data, challenges remain in aligning example selection with task granularity and effectively integrating prompt design with self-improvement frameworks. To address these limitations, we propose OEMA, a novel zero-shot clinical NER framework based on multi-agent collaboration. OEMA consists of three core components: (1) a self-annotator that autonomously generates candidate examples; (2) a discriminator that leverages SNOMED CT to filter token-level examples by clinical relevance; and (3) a predictor that incorporates entity-type descriptions to enhance inference accuracy. Experimental results on two benchmark datasets, MTSamples and VAERS, demonstrate that OEMA achieves state-of-the-art performance under exact-match evaluation. Moreover, under related-match criteria, OEMA performs comparably to the supervised BioClinicalBERT model while significantly outperforming the traditional CRF method. OEMA improves zero-shot clinical NER, achieving near-supervised performance under related-match criteria. Future work will focus on continual learning and open-domain adaptation to expand its applicability in clinical NLP.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xinli Tao, Xin Dong, Xuezhong Zhou",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control",
      "url": "https://arxiv.org/abs/2511.15248",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15248v1 Announce Type: cross \nAbstract: Long-term training of large language models (LLMs) requires maintaining stable exploration to prevent the model from collapsing into sub-optimal behaviors. Entropy is crucial in this context, as it controls exploration and helps avoid premature convergence to sub-optimal solutions. However, existing reinforcement learning methods struggle to maintain an appropriate level of entropy, as the training process involves a mix of positive and negative samples, each affecting entropy in different ways across steps. To address this, we propose Entropy stablilization via Proportional-Integral Control (EntroPIC), a novel method that adaptively adjusts the influence of positive and negative samples by dynamically tuning their loss coefficients. This approach stabilizes entropy throughout training, ensuring efficient exploration and steady progress. We provide a comprehensive theoretical analysis for both on-policy and off-policy learning settings, demonstrating that EntroPIC is effective at controlling entropy in large-scale LLM training. Experimental results show that our method successfully maintains desired entropy levels, enabling stable and optimal RL training for LLMs.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kai Yang, Xin Xu, Yangkun Chen, Weijie Liu, Jiafei Lyu, Zichuan Lin, Deheng Ye, Saiyong Yang",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback",
      "url": "https://arxiv.org/abs/2511.15253",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15253v1 Announce Type: cross \nAbstract: Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sirui Chen, Jinsong Zhou, Xinli Xu, Xiaoyu Yang, Litao Guo, Ying-Cong Chen",
      "tags": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms",
      "url": "https://arxiv.org/abs/2511.15274",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15274v1 Announce Type: cross \nAbstract: This paper compares two distinct approaches to modeling robotic behavior: imperative Behavior Trees (BTs) and declarative Executable Ontologies (EO), implemented through the boldsea framework. BTs structure behavior hierarchically using control-flow, whereas EO represents the domain as a temporal, event-based semantic graph driven by dataflow rules. We demonstrate that EO achieves comparable reactivity and modularity to BTs through a fundamentally different architecture: replacing polling-based tick execution with event-driven state propagation. We propose that EO offers an alternative framework, moving from procedural programming to semantic domain modeling, to address the semantic-process gap in traditional robotic control. EO supports runtime model modification, full temporal traceability, and a unified representation of data, logic, and interface - features that are difficult or sometimes impossible to achieve with BTs, although BTs excel in established, predictable scenarios. The comparison is grounded in a practical mobile manipulation task. This comparison highlights the respective operational strengths of each approach in dynamic, evolving robotic systems.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Alexander Boldachev",
      "tags": [
        "cs.RO",
        "cs.AI",
        "cs.FL"
      ]
    },
    {
      "title": "Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments",
      "url": "https://arxiv.org/abs/2511.15284",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15284v1 Announce Type: cross \nAbstract: Path planning in dynamic environments is a fundamental challenge in intelligent transportation and robotics, where obstacles and conditions change over time, introducing uncertainty and requiring continuous adaptation. While existing approaches often assume complete environmental unpredictability or rely on global planners, these assumptions limit scalability and practical deployment in real-world settings. In this paper, we propose a scalable, region-aware reinforcement learning (RL) framework for path planning in dynamic environments. Our method builds on the observation that environmental changes, although dynamic, are often localized within bounded regions. To exploit this, we introduce a hierarchical decomposition of the environment and deploy distributed RL agents that adapt to changes locally. We further propose a retraining mechanism based on sub-environment success rates to determine when policy updates are necessary. Two training paradigms are explored: single-agent Q-learning and multi-agent federated Q-learning, where local Q-tables are aggregated periodically to accelerate the learning process. Unlike prior work, we evaluate our methods in more realistic settings, where multiple simultaneous obstacle changes and increasing difficulty levels are present. Results show that the federated variants consistently outperform their single-agent counterparts and closely approach the performance of A* Oracle while maintaining shorter adaptation times and robust scalability. Although initial training remains time-consuming in large environments, our decentralized framework eliminates the need for a global planner and lays the groundwork for future improvements using deep RL and flexible environment decomposition.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jonas De Maeyer, Hossein Yarahmadi, Moharram Challenger",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models",
      "url": "https://arxiv.org/abs/2511.15304",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15304v2 Announce Type: cross \nAbstract: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for Large Language Models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of 3 open-weight LLM judges, whose binary safety assessments were validated on a stratified human-labeled subset. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Piercosma Bisconti, Matteo Prandi, Federico Pierucci, Francesco Giarrusso, Marcantonio Bracale, Marcello Galisai, Vincenzo Suriani, Olga Sorokoletova, Federico Sartore, Daniele Nardi",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "STREAM-VAE: Dual-Path Routing for Slow and Fast Dynamics in Vehicle Telemetry Anomaly Detection",
      "url": "https://arxiv.org/abs/2511.15339",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15339v1 Announce Type: cross \nAbstract: Automotive telemetry data exhibits slow drifts and fast spikes, often within the same sequence, making reliable anomaly detection challenging. Standard reconstruction-based methods, including sequence variational autoencoders (VAEs), use a single latent process and therefore mix heterogeneous time scales, which can smooth out spikes or inflate variances and weaken anomaly separation.\n  In this paper, we present STREAM-VAE, a variational autoencoder for anomaly detection in automotive telemetry time-series data. Our model uses a dual-path encoder to separate slow drift and fast spike signal dynamics, and a decoder that represents transient deviations separately from the normal operating pattern. STREAM-VAE is designed for deployment, producing stable anomaly scores across operating modes for both in-vehicle monitors and backend fleet analytics.\n  Experiments on an automotive telemetry dataset and the public SMD benchmark show that explicitly separating drift and spike dynamics improves robustness compared to strong forecasting, attention, graph, and VAE baselines.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kadir-Kaan \\\"Ozer, Ren\\'e Ebeling, Markus Enzweiler",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions",
      "url": "https://arxiv.org/abs/2511.15342",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15342v1 Announce Type: cross \nAbstract: Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Shan Shan",
      "tags": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers",
      "url": "https://arxiv.org/abs/2511.15369",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15369v1 Announce Type: cross \nAbstract: Previous Quantization-Aware Training (QAT) methods for vision transformers rely on expensive retraining to recover accuracy loss in non-linear layer quantization, limiting their use in resource-constrained environments. In contrast, existing Post-Training Quantization (PTQ) methods either partially quantize non-linear functions or adjust activation distributions to maintain accuracy but fail to achieve fully integer-only inference. In this paper, we introduce IPTQ-ViT, a novel PTQ framework for fully integer-only vision transformers without retraining. We present approximation functions: a polynomial-based GELU optimized for vision data and a bit-shifting-based Softmax designed to improve approximation accuracy in PTQ. In addition, we propose a unified metric integrating quantization sensitivity, perturbation, and computational cost to select the optimal approximation function per activation layer. IPTQ-ViT outperforms previous PTQ methods, achieving up to 6.44\\%p (avg. 1.78\\%p) top-1 accuracy improvement for image classification, 1.0 mAP for object detection. IPTQ-ViT outperforms partial floating-point PTQ methods under W8A8 and W4A8, and achieves accuracy and latency comparable to integer-only QAT methods. We plan to release our code https://github.com/gihwan-kim/IPTQ-ViT.git.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Gihwan Kim, Jemin Lee, Hyungshin Kim",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "The Empowerment of Science of Science by Large Language Models: New Tools and Methods",
      "url": "https://arxiv.org/abs/2511.15370",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15370v1 Announce Type: cross \nAbstract: Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Guoqiang Liang, Jingqian Gong, Mengxuan Li, Gege Lin, Shuo Zhang",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Parameter Importance-Driven Continual Learning for Foundation Models",
      "url": "https://arxiv.org/abs/2511.15375",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15375v1 Announce Type: cross \nAbstract: Domain-specific post-training often causes catastrophic forgetting, making foundation models lose their general reasoning ability and limiting their adaptability to dynamic real-world environments. Preserving general capabilities while acquiring downstream domain knowledge is a central challenge for large language and multimodal models. Traditional continual learning methods, such as regularization, replay and architectural isolation, suffer from poor downstream performance, reliance on inaccessible historical data, or additional parameter overhead. While recent parameter-efficient tuning (PET) methods can alleviate forgetting, their effectiveness strongly depends on the choice of parameters and update strategies. In this paper, we introduce PIECE, a Parameter Importance Estimation-based Continual Enhancement method that preserves general ability while efficiently learning domain knowledge without accessing prior training data or increasing model parameters. PIECE selectively updates only 0.1% of core parameters most relevant to new tasks, guided by two importance estimators: PIECE-F based on Fisher Information, and PIECE-S based on a second-order normalization that combines gradient and curvature information. Experiments across three language models and two multimodal models show that PIECE maintains general capabilities and achieves state-of-the-art continual learning performance across diverse downstream tasks. Our results highlight a practical path to scalable, domain-adaptive foundation models without catastrophic forgetting.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Lingxiang Wang, Hainan Zhang, Zhiming Zheng",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Compliance-Preserving Retrieval System for Aircraft MRO Task Search",
      "url": "https://arxiv.org/abs/2511.15383",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15383v1 Announce Type: cross \nAbstract: Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Byungho Jo",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.IR"
      ]
    },
    {
      "title": "DEPO: Dual-Efficiency Preference Optimization for LLM Agents",
      "url": "https://arxiv.org/abs/2511.15392",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15392v1 Announce Type: cross \nAbstract: Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at https://opencausalab.github.io/DEPO.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sirui Chen, Mengshi Zhao, Lei Xu, Yuying Zhao, Beier Zhu, Hanwang Zhang, Shengjie Zhao, Chaochao Lu",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework",
      "url": "https://arxiv.org/abs/2511.15408",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15408v1 Announce Type: cross \nAbstract: Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Shanlin Zhou (Tongji University), Xinpeng Wang (Tongji University), Jianxun Lian (Microsoft Research Asia), Zhenghao Liu (Northeastern University), Laks V. S. Lakshmanan (The University of British Columbia), Xiaoyuan Yi (Microsoft Research Asia), Yongtao Hao (Tongji University)",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.MA",
        "cs.NE"
      ]
    },
    {
      "title": "RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer",
      "url": "https://arxiv.org/abs/2511.15414",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15414v1 Announce Type: cross \nAbstract: We investigate the sampling-based optimal path planning problem for robotics in complex and dynamic environments. Most existing sampling-based algorithms neglect environmental information or the information from previous samples. Yet, these pieces of information are highly informative, as leveraging them can provide better heuristics when sampling the next state. In this paper, we propose a novel sampling-based planning algorithm, called \\emph{RRT*former}, which integrates the standard RRT* algorithm with a Transformer network in a novel way. Specifically, the Transformer is used to extract features from the environment and leverage information from previous samples to better guide the sampling process. Our extensive experiments demonstrate that, compared to existing sampling-based approaches such as RRT*, Neural RRT*, and their variants, our algorithm achieves considerable improvements in both the optimality of the path and sampling efficiency. The code for our implementation is available on https://github.com/fengmingyang666/RRTformer.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mingyang Feng, Shaoyuan Li, Xiang Yin",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Building Robust and Scalable Multilingual ASR for Indian Languages",
      "url": "https://arxiv.org/abs/2511.15418",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15418v1 Announce Type: cross \nAbstract: This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Arjun Gangwar, Kaousheik Jayakumar, S. Umesh",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Towards Understanding Layer Contributions in Tabular In-Context Learning Models",
      "url": "https://arxiv.org/abs/2511.15432",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15432v1 Announce Type: cross \nAbstract: Despite the architectural similarities between tabular in-context learning (ICL) models and large language models (LLMs), little is known about how individual layers contribute to tabular prediction. In this paper, we investigate how the latent spaces evolve across layers in tabular ICL models, identify potential redundant layers, and compare these dynamics with those observed in LLMs. We analyze TabPFN and TabICL through the \"layers as painters\" perspective, finding that only subsets of layers share a common representational language, suggesting structural redundancy and offering opportunities for model compression and improved interpretability.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Amir Rezaei Balef, Mykhailo Koshil, Katharina Eggensperger",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Small Language Models for Phishing Website Detection: Cost, Performance, and Privacy Trade-Offs",
      "url": "https://arxiv.org/abs/2511.15434",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15434v1 Announce Type: cross \nAbstract: Phishing websites pose a major cybersecurity threat, exploiting unsuspecting users and causing significant financial and organisational harm. Traditional machine learning approaches for phishing detection often require extensive feature engineering, continuous retraining, and costly infrastructure maintenance. At the same time, proprietary large language models (LLMs) have demonstrated strong performance in phishing-related classification tasks, but their operational costs and reliance on external providers limit their practical adoption in many business environments. This paper investigates the feasibility of small language models (SLMs) for detecting phishing websites using only their raw HTML code. A key advantage of these models is that they can be deployed on local infrastructure, providing organisations with greater control over data and operations. We systematically evaluate 15 commonly used Small Language Models (SLMs), ranging from 1 billion to 70 billion parameters, benchmarking their classification accuracy, computational requirements, and cost-efficiency. Our results highlight the trade-offs between detection performance and resource consumption, demonstrating that while SLMs underperform compared to state-of-the-art proprietary LLMs, they can still provide a viable and scalable alternative to external LLM services. By presenting a comparative analysis of costs and benefits, this work lays the foundation for future research on the adaptation, fine-tuning, and deployment of SLMs in phishing detection systems, aiming to balance security effectiveness and economic practicality.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Georg Goldenits, Philip Koenig, Sebastian Raubitzek, Andreas Ekelhart",
      "tags": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation",
      "url": "https://arxiv.org/abs/2511.15435",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15435v1 Announce Type: cross \nAbstract: Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Linyin Luo, Yujuan Ding, Yunshan Ma, Wenqi Fan, Hanjiang Lai",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "TSFM in-context learning for time-series classification of bearing-health status",
      "url": "https://arxiv.org/abs/2511.15447",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15447v1 Announce Type: cross \nAbstract: This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Michel Tokic, Slobodan Djukanovi\\'c, Anja von Beuningen, Cheng Feng",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Insights from the ICLR Peer Review and Rebuttal Process",
      "url": "https://arxiv.org/abs/2511.15462",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15462v1 Announce Type: cross \nAbstract: Peer review is a cornerstone of scientific publishing, including at premier machine learning conferences such as ICLR. As submission volumes increase, understanding the nature and dynamics of the review process is crucial for improving its efficiency, effectiveness, and the quality of published papers. We present a large-scale analysis of the ICLR 2024 and 2025 peer review processes, focusing on before- and after-rebuttal scores and reviewer-author interactions. We examine review scores, author-reviewer engagement, temporal patterns in review submissions, and co-reviewer influence effects. Combining quantitative analyses with LLM-based categorization of review texts and rebuttal discussions, we identify common strengths and weaknesses for each rating group, as well as trends in rebuttal strategies that are most strongly associated with score changes. Our findings show that initial scores and the ratings of co-reviewers are the strongest predictors of score changes during the rebuttal, pointing to a degree of reviewer influence. Rebuttals play a valuable role in improving outcomes for borderline papers, where thoughtful author responses can meaningfully shift reviewer perspectives. More broadly, our study offers evidence-based insights to improve the peer review process, guiding authors on effective rebuttal strategies and helping the community design fairer and more efficient review processes. Our code and score changes data are available at https://github.com/papercopilot/iclr-insights.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Amir Hossein Kargaran, Nafiseh Nikeghbal, Jing Yang, Nedjma Ousidhoum",
      "tags": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "RS-CA-HSICT: A Residual and Spatial Channel Augmented CNN Transformer Framework for Monkeypox Detection",
      "url": "https://arxiv.org/abs/2511.15476",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15476v1 Announce Type: cross \nAbstract: This work proposes a hybrid deep learning approach, namely Residual and Spatial Learning based Channel Augmented Integrated CNN-Transformer architecture, that leverages the strengths of CNN and Transformer towards enhanced MPox detection. The proposed RS-CA-HSICT framework is composed of an HSICT block, a residual CNN module, a spatial CNN block, and a CA, which enhances the diverse feature space, detailed lesion information, and long-range dependencies. The new HSICT module first integrates an abstract representation of the stem CNN and customized ICT blocks for efficient multihead attention and structured CNN layers with homogeneous (H) and structural (S) operations. The customized ICT blocks learn global contextual interactions and local texture extraction. Additionally, H and S layers learn spatial homogeneity and fine structural details by reducing noise and modeling complex morphological variations. Moreover, inverse residual learning enhances vanishing gradient, and stage-wise resolution reduction ensures scale invariance. Furthermore, the RS-CA-HSICT framework augments the learned HSICT channels with the TL-driven Residual and Spatial CNN maps for enhanced multiscale feature space capturing global and localized structural cues, subtle texture, and contrast variations. These channels, preceding augmentation, are refined through the Channel-Fusion-and-Attention block, which preserves discriminative channels while suppressing redundant ones, thereby enabling efficient computation. Finally, the spatial attention mechanism refines pixel selection to detect subtle patterns and intra-class contrast variations in Mpox. Experimental results on both the Kaggle benchmark and a diverse MPox dataset reported classification accuracy as high as 98.30% and an F1-score of 98.13%, which outperforms the existing CNNs and ViTs.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Rashid Iqbal, Saddam Hussain Khan",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Evaluating Low-Light Image Enhancement Across Multiple Intensity Levels",
      "url": "https://arxiv.org/abs/2511.15496",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15496v1 Announce Type: cross \nAbstract: Imaging in low-light environments is challenging due to reduced scene radiance, which leads to elevated sensor noise and reduced color saturation. Most learning-based low-light enhancement methods rely on paired training data captured under a single low-light condition and a well-lit reference. The lack of radiance diversity limits our understanding of how enhancement techniques perform across varying illumination intensities. We introduce the Multi-Illumination Low-Light (MILL) dataset, containing images captured at diverse light intensities under controlled conditions with fixed camera settings and precise illuminance measurements. MILL enables comprehensive evaluation of enhancement algorithms across variable lighting conditions. We benchmark several state-of-the-art methods and reveal significant performance variations across intensity levels. Leveraging the unique multi-illumination structure of our dataset, we propose improvements that enhance robustness across diverse illumination scenarios. Our modifications achieve up to 10 dB PSNR improvement for DSLR and 2 dB for the smartphone on Full HD images.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Maria Pilligua, David Serrano-Lozano, Pai Peng, Ramon Baldrich, Michael S. Brown, Javier Vazquez-Corral",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies",
      "url": "https://arxiv.org/abs/2511.15520",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15520v1 Announce Type: cross \nAbstract: Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Gabriel Lauzier, Alexandre Girard, Fran\\c{c}ois Ferland",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Multimodal Evaluation of Russian-language Architectures",
      "url": "https://arxiv.org/abs/2511.15552",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15552v2 Announce Type: cross \nAbstract: Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Artem Chervyakov, Ulyana Isaeva, Anton Emelyanov, Artem Safin, Maria Tikhonova, Alexander Kharitonov, Yulia Lyakh, Petr Surovtsev, Denis Shevelev, Vildan Saburov, Vasily Konovalov, Elisei Rykov, Ivan Sviridov, Amina Miftakhova, Ilseyar Alimova, Alexander Panchenko, Alexander Kapitanov, Alena Fenogenova",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "B+ANN: A Fast Billion-Scale Disk-based Nearest-Neighbor Index",
      "url": "https://arxiv.org/abs/2511.15557",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15557v1 Announce Type: cross \nAbstract: Storing and processing of embedding vectors by specialized Vector databases (VDBs) has become the linchpin in building modern AI pipelines. Most current VDBs employ variants of a graph-based ap- proximate nearest-neighbor (ANN) index algorithm, HNSW, to an- swer semantic queries over stored vectors. Inspite of its wide-spread use, the HNSW algorithm suffers from several issues: in-memory design and implementation, random memory accesses leading to degradation in cache behavior, limited acceleration scope due to fine-grained pairwise computations, and support of only semantic similarity queries. In this paper, we present a novel disk-based ANN index, B+ANN, to address these issues: it first partitions input data into blocks containing semantically similar items, then builds an B+ tree variant to store blocks both in-memory and on disks, and finally, enables hybrid edge- and block-based in-memory traversals. As demonstrated by our experimantal evaluation, the proposed B+ANN disk-based index improves both quality (Recall value), and execution performance (Queries per second/QPS) over HNSW, by improving spatial and temporal locality for semantic operations, reducing cache misses (19.23% relative gain), and decreasing the memory consumption and disk-based build time by 24x over the DiskANN algorithm. Finally, it enables dissimilarity queries, which are not supported by similarity-oriented ANN indices.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Selim Furkan Tekin, Rajesh Bordawekar",
      "tags": [
        "cs.DB",
        "cs.AI",
        "cs.DS"
      ]
    },
    {
      "title": "HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning",
      "url": "https://arxiv.org/abs/2511.15574",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15574v1 Announce Type: cross \nAbstract: Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: https://github.com/CharlesYang030/HSKB.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Qihao Yang, Xuelin Wang, Jiale Chen, Xuelian Dong, Yuxin Hao, Tianyong Hao",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking",
      "url": "https://arxiv.org/abs/2511.15580",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15580v2 Announce Type: cross \nAbstract: 3D single object tracking (SOT) in LiDAR point clouds is a critical task in computer vision and autonomous driving. Despite great success having been achieved, the inherent sparsity of point clouds introduces a dual-redundancy challenge that limits existing trackers: (1) vast spatial redundancy from background noise impairs accuracy, and (2) informational redundancy within the foreground hinders efficiency. To tackle these issues, we propose CompTrack, a novel end-to-end framework that systematically eliminates both forms of redundancy in point clouds. First, CompTrack incorporates a Spatial Foreground Predictor (SFP) module to filter out irrelevant background noise based on information entropy, addressing spatial redundancy. Subsequently, its core is an Information Bottleneck-guided Dynamic Token Compression (IB-DTC) module that eliminates the informational redundancy within the foreground. Theoretically grounded in low-rank approximation, this module leverages an online SVD analysis to adaptively compress the redundant foreground into a compact and highly informative set of proxy tokens. Extensive experiments on KITTI, nuScenes and Waymo datasets demonstrate that CompTrack achieves top-performing tracking performance with superior efficiency, running at a real-time 90 FPS on a single RTX 3090 GPU.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sifan Zhou, Yichao Cao, Jiahao Nie, Yuqian Fu, Ziyu Zhao, Xiaobo Lu, Shuo Wang",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography",
      "url": "https://arxiv.org/abs/2511.15614",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15614v1 Announce Type: cross \nAbstract: The integration of advanced robotics in nuclear power plants (NPPs) presents a transformative opportunity to enhance safety, efficiency, and environmental monitoring in high-stakes environments. Our paper introduces the Optimus-Q robot, a sophisticated system designed to autonomously monitor air quality and detect contamination while leveraging adaptive learning techniques and secure quantum communication. Equipped with advanced infrared sensors, the Optimus-Q robot continuously streams real-time environmental data to predict hazardous gas emissions, including carbon dioxide (CO$_2$), carbon monoxide (CO), and methane (CH$_4$). Utilizing a federated learning approach, the robot collaborates with other systems across various NPPs to improve its predictive capabilities without compromising data privacy. Additionally, the implementation of Quantum Key Distribution (QKD) ensures secure data transmission, safeguarding sensitive operational information. Our methodology combines systematic navigation patterns with machine learning algorithms to facilitate efficient coverage of designated areas, thereby optimizing contamination monitoring processes. Through simulations and real-world experiments, we demonstrate the effectiveness of the Optimus-Q robot in enhancing operational safety and responsiveness in nuclear facilities. This research underscores the potential of integrating robotics, machine learning, and quantum technologies to revolutionize monitoring systems in hazardous environments.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sai Puppala, Ismail Hossain, Jahangir Alam, Sajedul Talukder",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification",
      "url": "https://arxiv.org/abs/2511.15622",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15622v1 Announce Type: cross \nAbstract: Automated video analysis is critical for wildlife conservation. A foundational task in this domain is multi-animal tracking (MAT), which underpins applications such as individual re-identification and behavior recognition. However, existing datasets are limited in scale, constrained to a few species, or lack sufficient temporal and geographical diversity - leaving no suitable benchmark for training general-purpose MAT models applicable across wild animal populations. To address this, we introduce SA-FARI, the largest open-source MAT dataset for wild animals. It comprises 11,609 camera trap videos collected over approximately 10 years (2014-2024) from 741 locations across 4 continents, spanning 99 species categories. Each video is exhaustively annotated culminating in ~46 hours of densely annotated footage containing 16,224 masklet identities and 942,702 individual bounding boxes, segmentation masks, and species labels. Alongside the task-specific annotations, we publish anonymized camera trap locations for each video. Finally, we present comprehensive benchmarks on SA-FARI using state-of-the-art vision-language models for detection and tracking, including SAM 3, evaluated with both species-specific and generic animal prompts. We also compare against vision-only methods developed specifically for wildlife analysis. SA-FARI is the first large-scale dataset to combine high species diversity, multi-region coverage, and high-quality spatio-temporal annotations, offering a new foundation for advancing generalizable multianimal tracking in the wild. The dataset is available at $\\href{https://www.conservationxlabs.com/sa-fari}{\\text{conservationxlabs.com/SA-FARI}}$.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Dante Francisco Wasmuht, Otto Brookes, Maximillian Schall, Pablo Palencia, Chris Beirne, Tilo Burghardt, Majid Mirmehdi, Hjalmar K\\\"uhl, Mimi Arandjelovic, Sam Pottie, Peter Bermant, Brandon Asheim, Yi Jin Toh, Adam Elzinga, Jason Holmberg, Andrew Whitworth, Eleanor Flatt, Laura Gustafson, Chaitanya Ryali, Yuan-Ting Hu, Baishan Guo, Andrew Westbury, Kate Saenko, Didac Suris",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Sufficient Explanations in Databases and their Connections to Necessary Explanations and Repairs",
      "url": "https://arxiv.org/abs/2511.15623",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15623v1 Announce Type: cross \nAbstract: The notion of cause, as formalized by Halpern and Pearl, has been recently applied to relational databases, to characterize and compute causal explanations for query answers. In this work we consider the alternative notion of sufficient explanation. We investigate its connections with database repairs as used for dealing with inconsistent databases, and with causality-based necessary explanations. We also obtain some computational results.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Leopoldo Bertossi, Nina Pardal",
      "tags": [
        "cs.DB",
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges",
      "url": "https://arxiv.org/abs/2511.15652",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15652v1 Announce Type: cross \nAbstract: Continual learning (CL) is a branch of machine learning that aims to enable agents to adapt and generalise previously learned abilities so that these can be reapplied to new tasks or environments. This is particularly useful in multi-task settings or in non-stationary environments, where the dynamics can change over time. This is particularly relevant in cyber-physical systems such as autonomous driving. However, despite recent advances in CL, successfully applying it to reinforcement learning (RL) is still an open problem.\n  This paper highlights open challenges in continual RL (CRL) based on experiments in an autonomous driving environment. In this environment, the agent must learn to successfully park in four different scenarios corresponding to parking spaces oriented at varying angles. The agent is successively trained in these four scenarios one after another, representing a CL environment, using Proximal Policy Optimisation (PPO). These experiments exposed a number of open challenges in CRL: finding suitable abstractions of the environment, oversensitivity to hyperparameters, catastrophic forgetting, and efficient use of neural network capacity.\n  Based on these identified challenges, we present open research questions that are important to be addressed for creating robust CRL systems. In addition, the identified challenges call into question the suitability of neural networks for CL. We also identify the need for interdisciplinary research, in particular between computer science and neuroscience.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kim N. Nolle, Ivana Dusparic, Rhodri Cusack, Vinny Cahill",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "GEO-Bench-2: From Performance to Capability, Rethinking Evaluation in Geospatial AI",
      "url": "https://arxiv.org/abs/2511.15658",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15658v1 Announce Type: cross \nAbstract: Geospatial Foundation Models (GeoFMs) are transforming Earth Observation (EO), but evaluation lacks standardized protocols. GEO-Bench-2 addresses this with a comprehensive framework spanning classification, segmentation, regression, object detection, and instance segmentation across 19 permissively-licensed datasets. We introduce ''capability'' groups to rank models on datasets that share common characteristics (e.g., resolution, bands, temporality). This enables users to identify which models excel in each capability and determine which areas need improvement in future work. To support both fair comparison and methodological innovation, we define a prescriptive yet flexible evaluation protocol. This not only ensures consistency in benchmarking but also facilitates research into model adaptation strategies, a key and open challenge in advancing GeoFMs for downstream tasks.\n  Our experiments show that no single model dominates across all tasks, confirming the specificity of the choices made during architecture design and pretraining. While models pretrained on natural images (ConvNext ImageNet, DINO V3) excel on high-resolution tasks, EO-specific models (TerraMind, Prithvi, and Clay) outperform them on multispectral applications such as agriculture and disaster response. These findings demonstrate that optimal model choice depends on task requirements, data modalities, and constraints. This shows that the goal of a single GeoFM model that performs well across all tasks remains open for future research. GEO-Bench-2 enables informed, reproducible GeoFM evaluation tailored to specific use cases. Code, data, and leaderboard for GEO-Bench-2 are publicly released under a permissive license.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Naomi Simumba, Nils Lehmann, Paolo Fraccaro, Hamed Alemohammad, Geeth De Mel, Salman Khan, Manil Maskey, Nicolas Longepe, Xiao Xiang Zhu, Hannah Kerner, Juan Bernabe-Moreno, Alexander Lacoste",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "VisPlay: Self-Evolving Vision-Language Models from Images",
      "url": "https://arxiv.org/abs/2511.15661",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15661v2 Announce Type: cross \nAbstract: Reinforcement learning (RL) provides a principled framework for improving Vision-Language Models (VLMs) on complex reasoning tasks. However, existing RL approaches often rely on human-annotated labels or task-specific heuristics to define verifiable rewards, both of which are costly and difficult to scale. We introduce VisPlay, a self-evolving RL framework that enables VLMs to autonomously improve their reasoning abilities using large amounts of unlabeled image data. Starting from a single base VLM, VisPlay assigns the model into two interacting roles: an Image-Conditioned Questioner that formulates challenging yet answerable visual questions, and a Multimodal Reasoner that generates silver responses. These roles are jointly trained with Group Relative Policy Optimization (GRPO), which incorporates diversity and difficulty rewards to balance the complexity of generated questions with the quality of the silver answers. VisPlay scales efficiently across two model families. When trained on Qwen2.5-VL and MiMo-VL, VisPlay achieves consistent improvements in visual reasoning, compositional generalization, and hallucination reduction across eight benchmarks, including MM-Vet and MMMU, demonstrating a scalable path toward self-evolving multimodal intelligence. The project page is available at https://bruno686.github.io/VisPlay/",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yicheng He, Chengsong Huang, Zongxia Li, Jiaxin Huang, Yonghui Yang",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models",
      "url": "https://arxiv.org/abs/2511.15669",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15669v1 Announce Type: cross \nAbstract: Enabling Vision-Language-Action (VLA) models to \"think before acting\" via Chain-of-Thought (CoT) is a promising path to overcoming the data-hungry nature of end-to-end robot policies. However, progress is stalled by a fundamental conflict: existing models use a single autoregressive decoder for both sequential CoT reasoning and high-dimensional, parallelizable robot actions. This architectural mismatch degrades motor control and fails to forge a strong causal link between thought and action. We introduce DeepThinkVLA, which resolves this conflict through a tightly integrated architecture and training strategy. Architecturally, our hybrid-attention decoder generates sequential CoT with causal attention and then switches to bidirectional attention for fast, parallel decoding of action vectors. This design is complemented by a two-stage training pipeline: we first use Supervised Fine-Tuning (SFT) to teach the model foundational reasoning, then apply Reinforcement Learning (RL) with task-success rewards to causally align the full reasoning-action sequence with desired outcomes. This synergy leads to state-of-the-art performance, achieving a 97.0% success rate on the LIBERO benchmark. Our ablations confirm the design's effectiveness: the hybrid architecture alone outperforms standard decoders by 15.5%, and the final RL stage provides a crucial 2% boost to secure top performance.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Cheng Yin, Yankai Lin, Wang Xu, Sikyuen Tam, Xiangrui Zeng, Zhiyuan Liu, Zhouping Yin",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features",
      "url": "https://arxiv.org/abs/2511.15675",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15675v1 Announce Type: cross \nAbstract: Eye tracking data quantifies the attentional bias towards negative stimuli that is frequently observed in depressed groups. Audio and video data capture the affective flattening and psychomotor retardation characteristic of depression. Statistical validation confirmed their significant discriminative power in distinguishing depressed from non depressed groups. We address a critical limitation of existing graph-based models that focus on low-frequency information and propose a Multi-Frequency Graph Convolutional Network (MF-GCN). This framework consists of a novel Multi-Frequency Filter Bank Module (MFFBM), which can leverage both low and high frequency signals. Extensive evaluation against traditional machine learning algorithms and deep learning frameworks demonstrates that MF-GCN consistently outperforms baselines. In binary (depressed and non depressed) classification, the model achieved a sensitivity of 0.96 and F2 score of 0.94. For the 3 class (no depression, mild to moderate depression and severe depression) classification task, the proposed method achieved a sensitivity of 0.79 and specificity of 0.87 and siginificantly suprassed other models. To validate generalizability, the model was also evaluated on the Chinese Multimodal Depression Corpus (CMDC) dataset and achieved a sensitivity of 0.95 and F2 score of 0.96. These results confirm that our trimodal, multi frequency framework effectively captures cross modal interaction for accurate depression detection.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sejuti Rahman, Swakshar Deb, MD. Sameer Iqbal Chowdhury, MD. Jubair Ahmed Sourov, Mohammad Shamsuddin",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Walrus: A Cross-Domain Foundation Model for Continuum Dynamics",
      "url": "https://arxiv.org/abs/2511.15684",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15684v1 Announce Type: cross \nAbstract: Foundation models have transformed machine learning for language and vision, but achieving comparable impact in physical simulation remains a challenge. Data heterogeneity and unstable long-term dynamics inhibit learning from sufficiently diverse dynamics, while varying resolutions and dimensionalities challenge efficient training on modern hardware. Through empirical and theoretical analysis, we incorporate new approaches to mitigate these obstacles, including a harmonic-analysis-based stabilization method, load-balanced distributed 2D and 3D training strategies, and compute-adaptive tokenization. Using these tools, we develop Walrus, a transformer-based foundation model developed primarily for fluid-like continuum dynamics. Walrus is pretrained on nineteen diverse scenarios spanning astrophysics, geoscience, rheology, plasma physics, acoustics, and classical fluids. Experiments show that Walrus outperforms prior foundation models on both short and long term prediction horizons on downstream tasks and across the breadth of pretraining data, while ablation studies confirm the value of our contributions to forecast stability, training throughput, and transfer performance over conventional approaches. Code and weights are released for community use.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Michael McCabe, Payel Mukhopadhyay, Tanya Marwah, Bruno Regaldo-Saint Blancard, Francois Rozet, Cristiana Diaconu, Lucas Meyer, Kaze W. K. Wong, Hadi Sotoudeh, Alberto Bietti, Irina Espejo, Rio Fear, Siavash Golkar, Tom Hehir, Keiya Hirashima, Geraud Krawezik, Francois Lanusse, Rudy Morel, Ruben Ohana, Liam Parker, Mariel Pettee, Jeff Shen, Kyunghyun Cho, Miles Cranmer, Shirley Ho",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ]
    },
    {
      "title": "Joint Semantic-Channel Coding and Modulation for Token Communications",
      "url": "https://arxiv.org/abs/2511.15699",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15699v1 Announce Type: cross \nAbstract: In recent years, the Transformer architecture has achieved outstanding performance across a wide range of tasks and modalities. Token is the unified input and output representation in Transformer-based models, which has become a fundamental information unit. In this work, we consider the problem of token communication, studying how to transmit tokens efficiently and reliably. Point cloud, a prevailing three-dimensional format which exhibits a more complex spatial structure compared to image or video, is chosen to be the information source. We utilize the set abstraction method to obtain point tokens. Subsequently, to get a more informative and transmission-friendly representation based on tokens, we propose a joint semantic-channel and modulation (JSCCM) scheme for the token encoder, mapping point tokens to standard digital constellation points (modulated tokens). Specifically, the JSCCM consists of two parallel Point Transformer-based encoders and a differential modulator which combines the Gumel-softmax and soft quantization methods. Besides, the rate allocator and channel adapter are developed, facilitating adaptive generation of high-quality modulated tokens conditioned on both semantic information and channel conditions. Extensive simulations demonstrate that the proposed method outperforms both joint semantic-channel coding and traditional separate coding, achieving over 1dB gain in reconstruction and more than 6x compression ratio in modulated symbols.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jingkai Ying, Zhijin Qin, Yulong Feng, Liejun Wang, Xiaoming Tao",
      "tags": [
        "eess.SP",
        "cs.AI"
      ]
    },
    {
      "title": "Think Visually, Reason Textually: Vision-Language Synergy in ARC",
      "url": "https://arxiv.org/abs/2511.15703",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15703v1 Announce Type: cross \nAbstract: Abstract reasoning from minimal examples remains a core unsolved problem for frontier foundation models such as GPT-5 and Grok 4. These models still fail to infer structured transformation rules from a handful of examples, which is a key hallmark of human intelligence. The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) provides a rigorous testbed for this capability, demanding conceptual rule induction and transfer to novel tasks. Most existing methods treat ARC-AGI as a purely textual reasoning task, overlooking the fact that humans rely heavily on visual abstraction when solving such puzzles. However, our pilot experiments reveal a paradox: naively rendering ARC-AGI grids as images degrades performance due to imprecise rule execution. This leads to our central hypothesis that vision and language possess complementary strengths across distinct reasoning stages: vision supports global pattern abstraction and verification, whereas language specializes in symbolic rule formulation and precise execution. Building on this insight, we introduce two synergistic strategies: (1) Vision-Language Synergy Reasoning (VLSR), which decomposes ARC-AGI into modality-aligned subtasks; and (2) Modality-Switch Self-Correction (MSSC), which leverages vision to verify text-based reasoning for intrinsic error correction. Extensive experiments demonstrate that our approach yields up to a 4.33% improvement over text-only baselines across diverse flagship models and multiple ARC-AGI tasks. Our findings suggest that unifying visual abstraction with linguistic reasoning is a crucial step toward achieving generalizable, human-like intelligence in future foundation models. Source code will be released soon.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Beichen Zhang, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data",
      "url": "https://arxiv.org/abs/2511.15704",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15704v1 Announce Type: cross \nAbstract: Egocentric videos are a valuable and scalable data source to learn manipulation policies. However, due to significant data heterogeneity, most existing approaches utilize human data for simple pre-training, which does not unlock its full potential. This paper first provides a scalable recipe for collecting and using egocentric data by categorizing human data into two categories: in-the-wild and on-task alongside with systematic analysis on how to use the data. We first curate a dataset, PHSD, which contains over 1,000 hours of diverse in-the-wild egocentric data and over 20 hours of on-task data directly aligned to the target manipulation tasks. This enables learning a large egocentric language-conditioned flow matching policy, Human0. With domain adaptation techniques, Human0 minimizes the gap between humans and humanoids. Empirically, we show Human0 achieves several novel properties from scaling human data, including language following of instructions from only human data, few-shot learning, and improved robustness using on-task data. Project website: https://xiongyicai.github.io/In-N-On/",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xiongyi Cai, Ri-Zhao Qiu, Geng Chen, Lai Wei, Isabella Liu, Tianshu Huang, Xuxin Cheng, Xiaolong Wang",
      "tags": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Driving with Regulation: Trustworthy and Interpretable Decision-Making for Autonomous Driving with Retrieval-Augmented Reasoning",
      "url": "https://arxiv.org/abs/2410.04759",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2410.04759v3 Announce Type: replace \nAbstract: Understanding and adhering to traffic regulations is essential for autonomous vehicles to ensure safety and trustworthiness. However, traffic regulations are complex, context-dependent, and differ between regions, posing a major challenge to conventional rule-based decision-making approaches. We present an interpretable, regulation-aware decision-making framework, DriveReg, which enables autonomous vehicles to understand and adhere to region-specific traffic laws and safety guidelines. The framework integrates a Retrieval-Augmented Generation (RAG)-based Traffic Regulation Retrieval Agent, which retrieves relevant rules from regulatory documents based on the current situation, and a Large Language Model (LLM)-powered Reasoning Agent that evaluates actions for legal compliance and safety. Our design emphasizes interpretability to enhance transparency and trustworthiness. To support systematic evaluation, we introduce the DriveReg Scenarios Dataset, a comprehensive dataset of driving scenarios across Boston, Singapore, and Los Angeles, with both hypothesized text-based cases and real-world driving data, constructed and annotated to evaluate models' capacity for regulation understanding and reasoning. We validate our framework on the DriveReg Scenarios Dataset and real-world deployment, demonstrating strong performance and robustness across diverse environments.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Tianhui Cai, Yifan Liu, Zewei Zhou, Haoxuan Ma, Seth Z. Zhao, Zhiwen Wu, Xu Han, Zhiyu Huang, Jiaqi Ma",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs",
      "url": "https://arxiv.org/abs/2501.15791",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2501.15791v5 Announce Type: replace \nAbstract: Knowledge graphs are widely used in industrial applications, making error detection crucial for ensuring the reliability of downstream applications. Existing error detection methods often fail to effectively utilize fine-grained subgraph information and rely solely on fixed graph structures, while also lacking transparency in their decision-making processes, which results in suboptimal detection performance. In this paper, we propose a novel Multi-Agent framework for Knowledge Graph Error Detection (MAKGED) that utilizes multiple large language models (LLMs) in a collaborative setting. By concatenating fine-grained, bidirectional subgraph embeddings with LLM-based query embeddings during training, our framework integrates these representations to produce four specialized agents. These agents utilize subgraph information from different dimensions to engage in multi-round discussions, thereby improving error detection accuracy and ensuring a transparent decision-making process. Extensive experiments on FB15K and WN18RR demonstrate that MAKGED outperforms state-of-the-art methods, enhancing the accuracy and robustness of KG evaluation. For specific industrial scenarios, our framework can facilitate the training of specialized agents using domain-specific knowledge graphs for error detection, which highlights the potential industrial application value of our framework. Our code and datasets are available at https://github.com/kse-ElEvEn/MAKGED.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yu Li, Yi Huang, Guilin Qi, Junlan Feng, Nan Hu, Songlin Zhai, Haohan Xue, Yongrui Chen, Ruoyan Shen, Tongtong Wu",
      "tags": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "Intrinsic Barriers and Practical Pathways for Human-AI Alignment: An Agreement-Based Complexity Analysis",
      "url": "https://arxiv.org/abs/2502.05934",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2502.05934v3 Announce Type: replace \nAbstract: We formalize AI alignment as a multi-objective optimization problem called $\\langle M,N,\\varepsilon,\\delta\\rangle$-agreement, in which a set of $N$ agents (including humans) must reach approximate ($\\varepsilon$) agreement across $M$ candidate objectives, with probability at least $1-\\delta$. Analyzing communication complexity, we prove an information-theoretic lower bound showing that once either $M$ or $N$ is large enough, no amount of computational power or rationality can avoid intrinsic alignment overheads. This establishes rigorous limits to alignment *itself*, not merely to particular methods, clarifying a \"No-Free-Lunch\" principle: encoding \"all human values\" is inherently intractable and must be managed through consensus-driven reduction or prioritization of objectives. Complementing this impossibility result, we construct explicit algorithms as achievability certificates for alignment under both unbounded and bounded rationality with noisy communication. Even in these best-case regimes, our bounded-agent and sampling analysis shows that with large task spaces ($D$) and finite samples, *reward hacking is globally inevitable*: rare high-loss states are systematically under-covered, implying scalable oversight must target safety-critical slices rather than uniform coverage. Together, these results identify fundamental complexity barriers -- tasks ($M$), agents ($N$), and state-space size ($D$) -- and offer principles for more scalable human-AI collaboration.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Aran Nayebi",
      "tags": [
        "cs.AI",
        "cs.CC",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Trade-offs in Large Reasoning Models: An Empirical Analysis of Deliberative and Adaptive Reasoning over Foundational Capabilities",
      "url": "https://arxiv.org/abs/2503.17979",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2503.17979v2 Announce Type: replace \nAbstract: Recent advancements in Large Reasoning Models (LRMs), such as OpenAI's o1/o3 and DeepSeek-R1, have demonstrated remarkable performance in specialized reasoning tasks through human-like deliberative thinking and long chain-of-thought reasoning. However, our systematic evaluation across various model families (DeepSeek, Qwen, and LLaMA) and scales (7B to 32B) reveals that acquiring these deliberative reasoning capabilities significantly reduces the foundational capabilities of LRMs, including notable declines in helpfulness and harmlessness, alongside substantially increased inference costs. Importantly, we demonstrate that adaptive reasoning -- employing modes like Zero-Thinking, Less-Thinking, and Summary-Thinking -- can effectively alleviate these drawbacks. Our empirical insights underline the critical need for developing more versatile LRMs capable of dynamically allocating inference-time compute according to specific task characteristics.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Weixiang Zhao, Xingyu Sui, Jiahe Guo, Yulin Hu, Yang Deng, Yanyan Zhao, Xuda Zhi, Yongbo Huang, Hao He, Wanxiang Che, Ting Liu, Bing Qin",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Agent-SAMA: State-Aware Mobile Assistant",
      "url": "https://arxiv.org/abs/2505.23596",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.23596v3 Announce Type: replace \nAbstract: Mobile Graphical User Interface (GUI) agents aim to autonomously complete tasks within or across apps based on user instructions. While recent Multimodal Large Language Models (MLLMs) enable these agents to interpret UI screens and perform actions, existing agents remain fundamentally reactive. They reason over the current UI screen but lack a structured representation of the app navigation flow, limiting GUI agents' ability to understand execution context, detect unexpected execution results, and recover from errors. We introduce Agent-SAMA, a state-aware multi-agent framework that models app execution as a Finite State Machine (FSM), treating UI screens as states and user actions as transitions. Agent-SAMA implements four specialized agents that collaboratively construct and use FSMs in real time to guide task planning, execution verification, and recovery. We evaluate Agent-SAMA on two types of benchmarks: cross-app (Mobile-Eval-E, SPA-Bench) and mostly single-app (AndroidWorld). On Mobile-Eval-E, Agent-SAMA achieves an 84.0% success rate and a 71.9% recovery rate. On SPA-Bench, it reaches an 80.0% success rate with a 66.7% recovery rate. Compared to prior methods, Agent-SAMA improves task success by up to 12% and recovery success by 13.8%. On AndroidWorld, Agent-SAMA achieves a 63.7% success rate, outperforming the baselines. Our results demonstrate that structured state modeling enhances robustness and can serve as a lightweight, model-agnostic memory layer for future GUI agents.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Linqiang Guo (Peter), Wei Liu (Peter), Yi Wen Heng (Peter),  Tse-Hsun (Peter),  Chen, Yang Wang",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "MAGIC: Multi-Agent Argumentation and Grammar Integrated Critiquer",
      "url": "https://arxiv.org/abs/2506.13037",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2506.13037v2 Announce Type: replace \nAbstract: Automated Essay Scoring (AES) and Automatic Essay Feedback (AEF) systems aim to reduce the workload of human raters in educational assessment. However, most existing systems prioritize numerical scoring accuracy over feedback quality and are primarily evaluated on pre-secondary school level writing. This paper presents Multi-Agent Argumentation and Grammar Integrated Critiquer (MAGIC), a framework using five specialized agents to evaluate prompt adherence, persuasiveness, organization, vocabulary, and grammar for both holistic scoring and detailed feedback generation. To support evaluation at the college level, we collated a dataset of Graduate Record Examination (GRE) practice essays with expert-evaluated scores and feedback. MAGIC achieves substantial to near-perfect scoring agreement with humans on the GRE data, outperforming baseline LLM models while providing enhanced interpretability through its multi-agent approach. We also compare MAGIC's feedback generation capabilities against ground truth human feedback and baseline models, finding that MAGIC achieves strong feedback quality and naturalness.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Joaqu\\'in Jord\\'an, Xavier Yin, Melissa Fabros, Gireeja Ranade, Narges Norouzi",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Core Safety Values for Provably Corrigible Agents",
      "url": "https://arxiv.org/abs/2507.20964",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2507.20964v2 Announce Type: replace \nAbstract: We introduce the first complete formal solution to corrigibility in the off-switch game, with provable guarantees in multi-step, partially observed environments. Our framework consists of five *structurally separate* utility heads -- deference, switch-access preservation, truthfulness, low-impact behavior via a belief-based extension of Attainable Utility Preservation, and bounded task reward -- combined lexicographically by strict weight gaps. Theorem 1 proves exact single-round corrigibility in the partially observable off-switch game; Theorem 3 extends the guarantee to multi-step, self-spawning agents, showing that even if each head is *learned* to mean-squared error $\\varepsilon$ and the planner is $\\varepsilon$-sub-optimal, the probability of violating *any* safety property is bounded while still ensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF, which merge all norms into one learned scalar, our separation makes obedience and impact-limits provably dominate even when incentives conflict. For settings where adversaries can modify the agent, we prove that deciding whether an arbitrary post-hack agent will ever violate corrigibility is undecidable by reduction to the halting problem, then carve out a finite-horizon \"decidable island\" where safety can be certified in randomized polynomial time and verified with privacy-preserving, constant-round zero-knowledge proofs.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Aran Nayebi",
      "tags": [
        "cs.AI",
        "cs.CC",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "title": "Best-Effort Policies for Robust Markov Decision Processes",
      "url": "https://arxiv.org/abs/2508.07790",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.07790v2 Announce Type: replace \nAbstract: We study the common generalization of Markov decision processes (MDPs) with sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal in RMDPs is to compute a policy that maximizes the expected return under an adversarial choice of the transition probabilities. If the uncertainty in the probabilities is independent between the states, known as s-rectangularity, such optimal robust policies can be computed efficiently using robust value iteration. However, there might still be multiple optimal robust policies, which, while equivalent with respect to the worst-case, reflect different expected returns under non-adversarial choices of the transition probabilities. Hence, we propose a refined policy selection criterion for RMDPs, drawing inspiration from the notions of dominance and best-effort in game theory. Instead of seeking a policy that only maximizes the worst-case expected return, we additionally require the policy to achieve a maximal expected return under different (i.e., not fully adversarial) transition probabilities. We call such a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE policies always exist, characterize their structure, and present an algorithm to compute them with a manageable overhead compared to standard robust value iteration. ORBE policies offer a principled tie-breaker among optimal robust policies. Numerical experiments show the feasibility of our approach.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Alessandro Abate, Thom Badings, Giuseppe De Giacomo, Francesco Fabiano",
      "tags": [
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "Enabling MoE on the Edge via Importance-Driven Expert Scheduling",
      "url": "https://arxiv.org/abs/2508.18983",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.18983v2 Announce Type: replace \nAbstract: The Mixture of Experts (MoE) architecture has emerged as a key technique for scaling Large Language Models by activating only a subset of experts per query. Deploying MoE on consumer-grade edge hardware, however, is constrained by limited device memory, making dynamic expert offloading essential. Unlike prior work that treats offloading purely as a scheduling problem, we leverage expert importance to guide decisions, substituting low-importance activated experts with functionally similar ones already cached in GPU memory, thereby preserving accuracy. As a result, this design reduces memory usage and data transfer, while largely eliminating PCIe overhead. In addition, we introduce a scheduling policy that maximizes the reuse ratio of GPU-cached experts, further boosting efficiency. Extensive evaluations show that our approach delivers 48% lower decoding latency with over 60% expert cache hit rate, while maintaining nearly lossless accuracy.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Guoying Zhu, Meng Li, Haipeng Dai, Xuechen Liu, Weijun Wang, Keran Li, Jun xiao, Ligeng Chen, Wei Wang",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "MedLA: A Logic-Driven Multi-Agent Framework for Complex Medical Reasoning with Large Language Models",
      "url": "https://arxiv.org/abs/2509.23725",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.23725v2 Announce Type: replace \nAbstract: Answering complex medical questions requires not only domain expertise and patient-specific information, but also structured and multi-perspective reasoning. Existing multi-agent approaches often rely on fixed roles or shallow interaction prompts, limiting their ability to detect and resolve fine-grained logical inconsistencies. To address this, we propose \\textsc{MedLA}, a logic-driven multi-agent framework built on large language models. Each agent organizes its reasoning process into an explicit logical tree based on syllogistic triads (major premise, minor premise, and conclusion), enabling transparent inference and premise-level alignment. Agents engage in a multi-round, graph-guided discussion to compare and iteratively refine their logic trees, achieving consensus through error correction and contradiction resolution. We demonstrate that \\textsc{MedLA} consistently outperforms both static role-based systems and single-agent baselines on challenging benchmarks such as MedDDx and standard medical QA tasks. Furthermore, \\textsc{MedLA} scales effectively across both open-source and commercial LLM backbones, achieving state-of-the-art performance and offering a generalizable paradigm for trustworthy medical reasoning.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Siqi Ma, Jiajie Huang, Fan Zhang, Jinlin Wu, Yue Shen, Guohui Fan, Zhu Zhang, Zelin Zang",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding",
      "url": "https://arxiv.org/abs/2511.06761",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.06761v2 Announce Type: replace \nAbstract: Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. On the CLEVRER benchmark, SRNN achieves competitive performance, thereby confirming its capability to represent essential spatiotemporal relations from the visual stream. Cognitive ablation analysis further reveals a benchmark bias, outlining a path for a more holistic evaluation. Finally, the white-box nature of SRNN enables precise pinpointing of error root causes. Our work provides a proof-of-concept that confirms the viability of translating key principles of biological intelligence into engineered systems for intuitive physics understanding in constrained environments.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Fei Yang",
      "tags": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "TimeFlow: Towards Stochastic-Aware and Efficient Time Series Generation via Flow Matching Modeling",
      "url": "https://arxiv.org/abs/2511.07968",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.07968v2 Announce Type: replace \nAbstract: Generating high-quality time series data has emerged as a critical research topic due to its broad utility in supporting downstream time series mining tasks. A major challenge lies in modeling the intrinsic stochasticity of temporal dynamics, as real-world sequences often exhibit random fluctuations and localized variations. While diffusion models have achieved remarkable success, their generation process is computationally inefficient, often requiring hundreds to thousands of expensive function evaluations per sample. Flow matching has emerged as a more efficient paradigm, yet its conventional ordinary differential equation (ODE)-based formulation fails to explicitly capture stochasticity, thereby limiting the fidelity of generated sequences. By contrast, stochastic differential equation (SDE) are naturally suited for modeling randomness and uncertainty. Motivated by these insights, we propose TimeFlow, a novel SDE-based flow matching framework that integrates a encoder-only architecture. Specifically, we design a component-wise decomposed velocity field to capture the multi-faceted structure of time series and augment the vanilla flow-matching optimization with an additional stochastic term to enhance representational expressiveness. TimeFlow is flexible and general, supporting both unconditional and conditional generation tasks within a unified framework. Extensive experiments across diverse datasets demonstrate that our model consistently outperforms strong baselines in generation quality, diversity, and efficiency.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "He Panjing, Cheng Mingyue, Li Li, Zhang XiaoHan",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarking Multi-Step Legal Reasoning and Analyzing Chain-of-Thought Effects in Large Language Models",
      "url": "https://arxiv.org/abs/2511.07979",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.07979v3 Announce Type: replace \nAbstract: Large language models (LLMs) have demonstrated strong reasoning abilities across specialized domains, motivating research into their application to legal reasoning. However, existing legal benchmarks often conflate factual recall with genuine inference, fragment the reasoning process, and overlook the quality of reasoning. To address these limitations, we introduce MSLR, the first Chinese multi-step legal reasoning dataset grounded in real-world judicial decision making. MSLR adopts the IRAC framework (Issue, Rule, Application, Conclusion) to model structured expert reasoning from official legal documents. In addition, we design a scalable Human-LLM collaborative annotation pipeline that efficiently produces fine-grained step-level reasoning annotations and provides a reusable methodological framework for multi-step reasoning datasets. Evaluation of multiple LLMs on MSLR shows only moderate performance, highlighting the challenges of adapting to complex legal reasoning. Further experiments demonstrate that Self-Initiated Chain-of-Thought prompts generated by models autonomously improve reasoning coherence and quality, outperforming human-designed prompts. MSLR contributes to advancing LLM reasoning and Chain-of-Thought strategies and offers open resources for future research. The dataset and code are available at https://github.com/yuwenhan07/MSLR-Bench and https://law.sjtu.edu.cn/flszyjzx/index.html.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Wenhan Yu, Xinbo Lin, Lanxin Ni, Jinhua Cheng, Lei Sha",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Combining LLM Semantic Reasoning with GNN Structural Modeling for Multi-View Multi-Label Feature Selection",
      "url": "https://arxiv.org/abs/2511.08008",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.08008v2 Announce Type: replace \nAbstract: Multi-view multi-label feature selection aims to identify informative features from heterogeneous views, where each sample is associated with multiple interdependent labels. This problem is particularly important in machine learning involving high-dimensional, multimodal data such as social media, bioinformatics or recommendation systems. Existing Multi-View Multi-Label Feature Selection (MVMLFS) methods mainly focus on analyzing statistical information of data, but seldom consider semantic information. In this paper, we aim to use these two types of information jointly and propose a method that combines Large Language Models (LLMs) semantic reasoning with Graph Neural Networks (GNNs) structural modeling for MVMLFS. Specifically, the method consists of three main components. (1) LLM is first used as an evaluation agent to assess the latent semantic relevance among feature, view, and label descriptions. (2) A semantic-aware heterogeneous graph with two levels is designed to represent relations among features, views and labels: one is a semantic graph representing semantic relations, and the other is a statistical graph. (3) A lightweight Graph Attention Network (GAT) is applied to learn node embedding in the heterogeneous graph as feature saliency scores for ranking and selection. Experimental results on multiple benchmark datasets demonstrate the superiority of our method over state-of-the-art baselines, and it is still effective when applied to small-scale datasets, showcasing its robustness, flexibility, and generalization ability.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zhiqi Chen, Yuzhou Liu, Jiarui Liu, Wanfu Gao",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Boosting In-Silicon Directed Evolution with Fine-Tuned Protein Language Model and Tree Search",
      "url": "https://arxiv.org/abs/2511.09900",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.09900v2 Announce Type: replace \nAbstract: Protein evolution through amino acid sequence mutations is a cornerstone of life sciences. While current in-silicon directed evolution algorithms largely focus on designing heuristic search strategies, they overlook how to integrate the transformative protein language models, which encode rich evolutionary patterns, with reinforcement learning to learn to directly evolve proteins. To bridge this gap, we propose AlphaDE, a novel framework to optimize protein sequences by harnessing the innovative paradigms of large language models such as fine-tuning and test-time inference. First, AlphaDE fine-tunes pretrained protein language models using masked language modeling on homologous protein sequences to activate the evolutionary plausibility for the interested protein class. Second, AlphaDE introduces test-time inference based on Monte Carlo tree search, which effectively evolves proteins with evolutionary guidance from the fine-tuned protein language model. Extensive benchmark experiments show that AlphaDE remarkably outperforms previous state-of-the-art methods even with few-shot fine-tuning. A further case study demonstrates that AlphaDE supports condensing the protein sequence space of avGFP through computational evolution.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yaodong Yang, Yang Wang, Jinpeng Li, Pei Guo, Da Han, Guangyong Chen, Pheng-Ann Heng",
      "tags": [
        "cs.AI",
        "cs.CE"
      ]
    },
    {
      "title": "Intelligent Collaborative Optimization for Rubber Tyre Film Production Based on Multi-path Differentiated Clipping Proximal Policy Optimization",
      "url": "https://arxiv.org/abs/2511.12060",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.12060v2 Announce Type: replace \nAbstract: The advent of smart manufacturing is addressing the limitations of traditional centralized scheduling and inflexible production line configurations in the rubber tyre industry, especially in terms of coping with dynamic production demands. Contemporary tyre manufacturing systems form complex networks of tightly coupled subsystems pronounced nonlinear interactions and emergent dynamics. This complexity renders the effective coordination of multiple subsystems, posing an essential yet formidable task. For high-dimensional, multi-objective optimization problems in this domain, we introduce a deep reinforcement learning algorithm: Multi-path Differentiated Clipping Proximal Policy Optimization (MPD-PPO). This algorithm employs a multi-branch policy architecture with differentiated gradient clipping constraints to ensure stable and efficient high-dimensional policy updates. Validated through experiments on width and thickness control in rubber tyre film production, MPD-PPO demonstrates substantial improvements in both tuning accuracy and operational efficiency. The framework successfully tackles key challenges, including high dimensionality, multi-objective trade-offs, and dynamic adaptation, thus delivering enhanced performance and production stability for real-time industrial deployment in tyre manufacturing.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yinghao Ruan, Wei Pang, Shuaihao Liu, Huili Yang, Leyi Han, Xinghui Dong",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Incremental Maintenance of DatalogMTL Materialisations",
      "url": "https://arxiv.org/abs/2511.12169",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.12169v2 Announce Type: replace \nAbstract: DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kaiyue Zhao, Dingqi Chen, Shaoyu Wang, Pan Hu",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning",
      "url": "https://arxiv.org/abs/2511.12344",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.12344v2 Announce Type: replace \nAbstract: Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Baolong Bi, Shenghua Liu, Yiwei Wang, Siqian Tong, Lingrui Mei, Yuyao Ge, Yilong Xu, Jiafeng Guo, Xueqi Cheng",
      "tags": [
        "cs.AI"
      ]
    },
    {
      "title": "Do Large Language Models (LLMs) Understand Chronology?",
      "url": "https://arxiv.org/abs/2511.14214",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14214v2 Announce Type: replace \nAbstract: Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Pattaraphon Kenny Wongchamcharoen, Paul Glasserman",
      "tags": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling",
      "url": "https://arxiv.org/abs/2511.14334",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14334v2 Announce Type: replace \nAbstract: One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Alessio Pellegrino, Jacopo Mauro",
      "tags": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Explaining Time Series Classification Predictions via Causal Attributions",
      "url": "https://arxiv.org/abs/2405.15871",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2405.15871v2 Announce Type: replace-cross \nAbstract: Despite the excelling performance of machine learning models, understanding their decisions remains a long-standing goal. Although commonly used attribution methods from explainable AI attempt to address this issue, they typically rely on associational rather than causal relationships. In this study, within the context of time series classification, we introduce a novel model-agnostic attribution method to assess the causal effect of concepts i.e., predefined segments within a time series, on classification outcomes. Our approach compares these causal attributions with closely related associational attributions, both theoretically and empirically. To estimate counterfactual outcomes, we use state-of-the-art diffusion models backed by state space models. We demonstrate the insights gained by our approach for a diverse set of qualitatively different time series classification tasks. Although causal and associational attributions might often share some similarities, in all cases they differ in important details, underscoring the risks associated with drawing causal conclusions from associational data alone. We believe that the proposed approach is also widely applicable in other domains to shed some light on the limits of associational attributions.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Juan Miguel Lopez Alcaraz, Nils Strodthoff",
      "tags": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation",
      "url": "https://arxiv.org/abs/2406.10519",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2406.10519v3 Announce Type: replace-cross \nAbstract: Masked Autoencoders (MAEs) have been shown to be effective in pre-training Vision Transformers (ViTs) for natural and medical image analysis problems. By reconstructing missing pixel/voxel information in visible patches, a ViT encoder can aggregate contextual information for downstream tasks. But, existing MAE pre-training methods, which were specifically developed with the ViT architecture, lack the ability to capture geometric shape and spatial information, which is critical for medical image segmentation tasks. In this paper, we propose a novel extension of known MAEs for self pre-training (i.e., models pre-trained on the same target dataset) for 3D medical image segmentation. (1) We propose a new topological loss to preserve geometric shape information by computing topological signatures of both the input and reconstructed volumes, learning geometric shape information. (2) We introduce a pre-text task that predicts the positions of the centers and eight corners of 3D crops, enabling the MAE to aggregate spatial information. (3) We extend the MAE pre-training strategy to a hybrid state-of-the-art (SOTA) medical image segmentation architecture and co-pretrain it alongside the ViT. (4) We develop a fine-tuned model for downstream segmentation tasks by complementing the pre-trained ViT encoder with our pre-trained SOTA model. Extensive experiments on five public 3D segmentation datasets show the effectiveness of our new approach.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Pengfei Gu, Huimin Li, Yejia Zhang, Chaoli Wang, Danny Z. Chen",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "VeriFlow: Modeling Distributions for Neural Network Verification",
      "url": "https://arxiv.org/abs/2406.14265",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2406.14265v3 Announce Type: replace-cross \nAbstract: Formal verification has emerged as a promising method to ensure the safety and reliability of neural networks. However, many relevant properties, such as fairness or global robustness, pertain to the entire input space. If one applies verification techniques naively, the neural network is checked even on inputs that do not occur in the real world and have no meaning. To tackle this shortcoming, we propose the VeriFlow architecture as a flow-based density model tailored to allow any verification approach to restrict its search to some data distribution of interest. We argue that our architecture is particularly well suited for this purpose because of two major properties. First, we show that the transformation that is defined by our model is piecewise affine. Therefore, the model allows the usage of verifiers based on constraint solving with linear arithmetic. Second, upper density level sets (UDL) of the data distribution are definable via linear constraints in the latent space. As a consequence, representations of UDLs specified by a given probability are effectively computable in the latent space. This property allows for effective verification with a fine-grained, probabilistically interpretable control of how a-typical the inputs subject to verification are.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Faried Abu Zaid, Daniel Neider, Mustafa Yal\\c{c}{\\i}ner",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "cs.SC"
      ]
    },
    {
      "title": "MessIRve: A Large-Scale Spanish Information Retrieval Dataset",
      "url": "https://arxiv.org/abs/2409.05994",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2409.05994v2 Announce Type: replace-cross \nAbstract: Information retrieval (IR) is the task of finding relevant documents in response to a user query. Although Spanish is the second most spoken native language, there are few Spanish IR datasets, which limits the development of information access tools for Spanish speakers. We introduce MessIRve, a large-scale Spanish IR dataset with almost 700,000 queries from Google's autocomplete API and relevant documents sourced from Wikipedia. MessIRve's queries reflect diverse Spanish-speaking regions, unlike other datasets that are translated from English or do not consider dialectal variations. The large size of the dataset allows it to cover a wide variety of topics, unlike smaller datasets. We provide a comprehensive description of the dataset, comparisons with existing datasets, and baseline evaluations of prominent IR models. Our contributions aim to advance Spanish IR research and improve information access for Spanish speakers.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Francisco Valentini, Viviana Cotik, Dami\\'an Furman, Ivan Bercovich, Edgar Altszyler, Juan Manuel P\\'erez",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Tensorflow Pretrained Models",
      "url": "https://arxiv.org/abs/2409.13566",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2409.13566v3 Announce Type: replace-cross \nAbstract: The application of TensorFlow pre-trained models in deep learning is explored, with an emphasis on practical guidance for tasks such as image classification and object detection. The study covers modern architectures, including ResNet, MobileNet, and EfficientNet, and demonstrates the effectiveness of transfer learning through real-world examples and experiments. A comparison of linear probing and model fine-tuning is presented, supplemented by visualizations using techniques like PCA, t-SNE, and UMAP, allowing for an intuitive understanding of the impact of these approaches. The work provides complete example code and step-by-step instructions, offering valuable insights for both beginners and advanced users. By integrating theoretical concepts with hands-on practice, the paper equips readers with the tools necessary to address deep learning challenges efficiently.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Keyu Chen, Ziqian Bi, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Ming Liu, Xinyuan Song, Zekun Jiang, Tianyang Wang, Ming Li, Xuanhe Pan, Jiawei Xu, Jinlang Wang, Pohsun Feng",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Eguard: Defending LLM Embeddings Against Inversion Attacks via Text Mutual Information Optimization",
      "url": "https://arxiv.org/abs/2411.05034",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2411.05034v2 Announce Type: replace-cross \nAbstract: Embeddings have become a cornerstone in the functionality of large language models (LLMs) due to their ability to transform text data into rich, dense numerical representations that capture semantic and syntactic properties. These embedding vector databases serve as the long-term memory of LLMs, enabling efficient handling of a wide range of natural language processing tasks. However, the surge in popularity of embedding vector databases in LLMs has been accompanied by significant concerns about privacy leakage. Embedding vector databases are particularly vulnerable to embedding inversion attacks, where adversaries can exploit the embeddings to reverse-engineer and extract sensitive information from the original text data. Existing defense mechanisms have shown limitations, often struggling to balance security with the performance of downstream tasks. To address these challenges, we introduce Eguard, a novel defense mechanism designed to mitigate embedding inversion attacks. Eguard employs a transformer-based projection network and text mutual information optimization to safeguard embeddings while preserving the utility of LLMs. Our approach significantly reduces privacy risks, protecting over 95% of tokens from inversion while maintaining high performance across downstream tasks consistent with original embeddings.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Tiantian Liu, Hongwei Yao, Feng Lin, Tong Wu, Zhan Qin, Kui Ren",
      "tags": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Efficient Document Image Dewarping via Hybrid Deep Learning and Cubic Polynomial Geometry Restoration",
      "url": "https://arxiv.org/abs/2501.03145",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2501.03145v3 Announce Type: replace-cross \nAbstract: Camera-captured document images often suffer from geometric distortions caused by paper deformation, perspective distortion, and lens aberrations, significantly reducing OCR accuracy. This study develops an efficient automated method for document image dewarping that balances accuracy with computational efficiency. We propose a hybrid approach combining deep learning for document detection with classical computer vision for geometry restoration. YOLOv8 performs initial document segmentation and mask generation. Subsequently, classical CV techniques construct a topological 2D grid through cubic polynomial interpolation of document boundaries, followed by image remapping to correct nonlinear distortions. A new annotated dataset and open-source framework are provided to facilitate reproducibility and further research. Experimental evaluation against state-of-the-art methods (RectiNet, DocGeoNet, DocTr++) and mobile applications (DocScan, CamScanner, TapScanner) demonstrates superior performance. Our method achieves the lowest median Character Error Rate (CER=0.0235), Levenshtein Distance (LD=27.8), and highest Jaro--Winkler similarity (JW=0.902), approaching the quality of scanned originals. The approach requires significantly fewer computational resources and memory compared to pure deep learning solutions while delivering better OCR readability and geometry restoration quality. The proposed hybrid methodology effectively restores document geometry with computational efficiency superior to existing deep learning approaches, making it suitable for resource-constrained applications while maintaining high-quality document digitization. Project page: https://github.com/HorizonParadox/DRCCBI",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Valery Istomin, Oleg Pereziabov, Ilya Afanasyev",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction",
      "url": "https://arxiv.org/abs/2502.01550",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2502.01550v2 Announce Type: replace-cross \nAbstract: With climate change intensifying fire weather conditions globally, accurate seasonal wildfire forecasting has become critical for disaster preparedness and ecosystem management. We introduce FireCastNet, a novel deep learning architecture that combines 3D convolutional encoding with GraphCast-based Graph Neural Networks (GNNs) to model complex spatio-temporal dependencies for global wildfire prediction. Our approach leverages the SeasFire dataset, a comprehensive multivariate Earth system datacube containing climate, vegetation, and human-related variables, to forecast burned area patterns up to six months in advance. FireCastNet treats the Earth as an interconnected graph, enabling it to capture both local fire dynamics and long-range teleconnections that influence wildfire behavior across different spatial and temporal scales. Through comprehensive benchmarking against state-of-the-art models including GRU, Conv-GRU, Conv-LSTM, U-TAE, and TeleViT, we demonstrate that FireCastNet achieves superior performance in global burned area forecasting, with particularly strong results in fire-prone regions such as Africa, South America, and Southeast Asia. Our analysis reveals that longer input time-series significantly improve prediction robustness, while spatial context integration enhances model performance across extended forecasting horizons. Additionally, we implement local area modeling techniques that provide enhanced spatial resolution and accuracy for region-specific predictions. These findings highlight the importance of modeling Earth system interactions for long-term wildfire prediction.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Dimitrios Michail, Charalampos Davalas, Konstantinos Chafis, Lefki-Ioanna Panagiotou, Ioannis Prapas, Spyros Kondylatos, Nikolaos Ioannis Bountos, Ioannis Papoutsis",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection",
      "url": "https://arxiv.org/abs/2502.15488",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2502.15488v4 Announce Type: replace-cross \nAbstract: Camera-based multi-view 3D detection is crucial for autonomous driving. PETR and its variants (PETRs) excel in benchmarks but face deployment challenges due to high computational cost and memory footprint. Quantization is an effective technique for compressing deep neural networks by reducing the bit width of weights and activations. However, directly applying existing quantization methods to PETRs leads to severe accuracy degradation. This issue primarily arises from two key challenges: (1) significant magnitude disparity between multi-modal features-specifically, image features and camera-ray positional embeddings (PE), and (2) the inefficiency and approximation error of quantizing non-linear operators, which commonly rely on hardware-unfriendly computations. In this paper, we propose FQ-PETR, a fully quantized framework for PETRs, featuring three key innovations: (1) Quantization-Friendly LiDAR-ray Position Embedding (QFPE): Replacing multi-point sampling with LiDAR-prior-guided single-point sampling and anchor-based embedding eliminates problematic non-linearities (e.g., inverse-sigmoid) and aligns PE scale with image features, preserving accuracy. (2) Dual-Lookup Table (DULUT): This algorithm approximates complex non-linear functions using two cascaded linear LUTs, achieving high fidelity with minimal entries and no specialized hardware. (3) Quantization After Numerical Stabilization (QANS): Performing quantization after softmax numerical stabilization mitigates attention distortion from large inputs. On PETRs (e.g. PETR, StreamPETR, PETRv2, MV2d), FQ-PETR under W8A8 achieves near-floating-point accuracy (1% degradation) while reducing latency by up to 75%, significantly outperforming existing PTQ and QAT baselines.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jiangyong Yu, Changyong Shu, Sifan Zhou, Zichen Yu, Xing Hu, Yan Chen, Dawei Yang",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "RIZE: Adaptive Regularization for Imitation Learning",
      "url": "https://arxiv.org/abs/2502.20089",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2502.20089v3 Announce Type: replace-cross \nAbstract: We propose a novel Inverse Reinforcement Learning (IRL) method that mitigates the rigidity of fixed reward structures and the limited flexibility of implicit reward regularization. Building on the Maximum Entropy IRL framework, our approach incorporates a squared temporal-difference (TD) regularizer with adaptive targets that evolve dynamically during training, thereby imposing adaptive bounds on recovered rewards and promoting robust decision-making. To capture richer return information, we integrate distributional RL into the learning process. Empirically, our method achieves expert-level performance on complex MuJoCo and Adroit environments, surpassing baseline methods on the Humanoid-v2 task with limited expert demonstrations. Extensive experiments and ablation studies further validate the effectiveness of the approach and provide insights into reward dynamics in imitation learning. Our source code is available at https://github.com/adibka/RIZE.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Adib Karimi, Mohammad Mehdi Ebadzadeh",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ]
    },
    {
      "title": "Adversarial Agents: Black-Box Evasion Attacks with Reinforcement Learning",
      "url": "https://arxiv.org/abs/2503.01734",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2503.01734v2 Announce Type: replace-cross \nAbstract: Attacks on machine learning models have been extensively studied through stateless optimization. In this paper, we demonstrate how a reinforcement learning (RL) agent can learn a new class of attack algorithms that generate adversarial samples. Unlike traditional adversarial machine learning (AML) methods that craft adversarial samples independently, our RL-based approach retains and exploits past attack experience to improve the effectiveness and efficiency of future attacks. We formulate adversarial sample generation as a Markov Decision Process and evaluate RL's ability to (a) learn effective and efficient attack strategies and (b) compete with state-of-the-art AML. On two image classification benchmarks, our agent increases attack success rate by up to 13.2% and decreases the average number of victim model queries per attack by up to 16.9% from the start to the end of training. In a head-to-head comparison with state-of-the-art image attacks, our approach enables an adversary to generate adversarial samples with 17% more success on unseen inputs post-training. From a security perspective, this work demonstrates a powerful new attack vector that uses RL to train agents that attack ML models efficiently and at scale.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kyle Domico, Jean-Charles Noirot Ferrand, Ryan Sheatsley, Eric Pauley, Josiah Hanna, Patrick McDaniel",
      "tags": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Natural Selection via Foundation Models for Soft Robot Evolution",
      "url": "https://arxiv.org/abs/2503.02249",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2503.02249v2 Announce Type: replace-cross \nAbstract: Designing soft robots is a complex and iterative process that demands cross-disciplinary expertise in materials science, mechanics, and control, often relying on intuition and extensive experimentation. While foundation models, especially Large Language Models (LLMs), have demonstrated impressive reasoning abilities, their capacity to conduct embodied design remains largely unexplored. This paper introduces RoboCrafter-QA, a novel benchmark to evaluate whether LLMs can learn representations of soft robot designs that effectively bridge the gap between high-level task descriptions and low-level morphological and material choices. RoboCrafter-QA leverages the EvoGym simulator to generate a diverse set of soft robot design challenges, spanning robotic locomotion, manipulation, and balancing tasks. Our experiments with SOTA multi-modal LLMs reveal that while these models exhibit promising capabilities in learning design representations, they struggle with fine-grained distinctions between designs with subtle performance differences. To overcome these limitations, we finetune an efficient, open-source LLM that achieves SOTA performance on our benchmark, demonstrating superior capabilities in both design selection and direct generation of high-performing robot morphologies. Furthermore, we construct a physical replica of the modular soft robot and demonstrate a strong sim-to-real correlation, validating that superior benchmark performance has the potential to translate to effective real-world design selection. Our full system will be open-sourced to foster this exciting direction.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Changhe Chen, Xiaohao Xu, Xiangdong Wang, Xiaonan Huang",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds?",
      "url": "https://arxiv.org/abs/2503.02687",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2503.02687v3 Announce Type: replace-cross \nAbstract: Due to the significant effort required for data collection and annotation in 3D perception tasks, mixed sample data augmentation (MSDA) has been widely studied to generate diverse training samples by mixing existing data. Recently, many MSDA techniques have been developed for point clouds, but they mainly target LiDAR data, leaving their application to radar point clouds largely unexplored. In this paper, we examine the feasibility of applying existing MSDA methods to radar point clouds and identify several challenges in adapting these techniques. These obstacles stem from the radar's irregular angular distribution, deviations from a single-sensor polar layout in multi-radar setups, and point sparsity. To address these issues, we propose Class-Aware PillarMix (CAPMix), a novel MSDA approach that applies MixUp at the pillar level in 3D point clouds, guided by class labels. Unlike methods that rely a single mix ratio to the entire sample, CAPMix assigns an independent ratio to each pillar, boosting sample diversity. To account for the density of different classes, we use class-specific distributions: for dense objects (e.g., large vehicles), we skew ratios to favor points from another sample, while for sparse objects (e.g., pedestrians), we sample more points from the original. This class-aware mixing retains critical details and enriches each sample with new information, ultimately generating more diverse training data. Experimental results demonstrate that our method not only significantly boosts performance but also outperforms existing MSDA approaches across two datasets (Bosch Street and K-Radar). We believe that this straightforward yet effective approach will spark further investigation into MSDA techniques for radar data.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Miao Zhang, Sherif Abdulatif, Benedikt Loesch, Marco Altmann, Bin Yang",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation",
      "url": "https://arxiv.org/abs/2503.07265",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2503.07265v3 Announce Type: replace-cross \nAbstract: Text-to-Image (T2I) models are capable of generating high-quality artistic creations and visual content. However, existing research and evaluation standards predominantly focus on image realism and shallow text-image alignment, lacking a comprehensive assessment of complex semantic understanding and world knowledge integration in text-to-image generation. To address this challenge, we propose \\textbf{WISE}, the first benchmark specifically designed for \\textbf{W}orld Knowledge-\\textbf{I}nformed \\textbf{S}emantic \\textbf{E}valuation. WISE moves beyond simple word-pixel mapping by challenging models with 1000 meticulously crafted prompts across 25 subdomains in cultural common sense, spatio-temporal reasoning, and natural science. To overcome the limitations of traditional CLIP metric, we introduce \\textbf{WiScore}, a novel quantitative metric for assessing knowledge-image alignment. Through comprehensive testing of 20 models (10 dedicated T2I models and 10 unified multimodal models) using 1,000 structured prompts spanning 25 subdomains, our findings reveal significant limitations in their ability to effectively integrate and apply world knowledge during image generation, highlighting critical pathways for enhancing knowledge incorporation and application in next-generation T2I models. Code and data are available at \\href{https://github.com/PKU-YuanGroup/WISE}{PKU-YuanGroup/WISE}.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yuwei Niu, Munan Ning, Mengren Zheng, Weiyang Jin, Bin Lin, Peng Jin, Jiaqi Liao, Chaoran Feng, Kunpeng Ning, Bin Zhu, Li Yuan",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space",
      "url": "https://arxiv.org/abs/2503.09215",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2503.09215v4 Announce Type: replace-cross \nAbstract: Advanced end-to-end autonomous driving systems predict other vehicles' motions and plan ego vehicle's trajectory. The world model that can foresee the outcome of the trajectory has been used to evaluate the autonomous driving system. However, existing world models predominantly emphasize the trajectory of the ego vehicle and leave other vehicles uncontrollable. This limitation hinders their ability to realistically simulate the interaction between the ego vehicle and the driving scenario. In this paper, we propose a driving World Model named EOT-WM, unifying Ego-Other vehicle Trajectories in videos for driving simulation. Specifically, it remains a challenge to match multiple trajectories in the BEV space with each vehicle in the video to control the video generation. We first project ego-other vehicle trajectories in the BEV space into the image coordinate for vehicle-trajectory match via pixel positions. Then, trajectory videos are encoded by the Spatial-Temporal Variational Auto Encoder to align with driving video latents spatially and temporally in the unified visual space. A trajectory-injected diffusion Transformer is further designed to denoise the noisy video latents for video generation with the guidance of ego-other vehicle trajectories. In addition, we propose a metric based on control latent similarity to evaluate the controllability of trajectories. Extensive experiments are conducted on the nuScenes dataset, and the proposed model outperforms the state-of-the-art method by 30% in FID and 55% in FVD. The model can also predict unseen driving scenes with self-produced trajectories.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jian Zhu, Zhengyu Jia, Tian Gao, Jiaxin Deng, Shidi Li, Lang Zhang, Fu Liu, Peng Jia, Xianpeng Lang",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Measuring the (Un)Faithfulness of Concept-Based Explanations",
      "url": "https://arxiv.org/abs/2504.10833",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2504.10833v3 Announce Type: replace-cross \nAbstract: Deep vision models perform input-output computations that are hard to interpret. Concept-based explanation methods (CBEMs) increase interpretability by re-expressing parts of the model with human-understandable semantic units, or concepts. Checking if the derived explanations are faithful -- that is, they represent the model's internal computation -- requires a surrogate that combines concepts to compute the output. Simplifications made for interpretability inevitably reduce faithfulness, resulting in a tradeoff between the two. State-of-the-art unsupervised CBEMs (U-CBEMs) have reported increasingly interpretable concepts, while also being more faithful to the model. However, we observe that the reported improvement in faithfulness artificially results from either (1) using overly complex surrogates, which introduces an unmeasured cost to the explanation's interpretability, or (2) relying on deletion-based approaches that, as we demonstrate, do not properly measure faithfulness. We propose Surrogate Faithfulness (SURF), which (1) replaces prior complex surrogates with a simple, linear surrogate that measures faithfulness without changing the explanation's interpretability and (2) introduces well-motivated metrics that assess loss across all output classes, not just the predicted class. We validate SURF with a measure-over-measure study by proposing a simple sanity check -- explanations with random concepts should be less faithful -- which prior surrogates fail. SURF enables the first reliable faithfulness benchmark of U-CBEMs, revealing that many visually compelling U-CBEMs are not faithful. Code to be released.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Shubham Kumar, Narendra Ahuja",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "AdCare-VLM: Towards a Unified and Pre-aligned Latent Representation for Healthcare Video Understanding",
      "url": "https://arxiv.org/abs/2505.00275",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.00275v3 Announce Type: replace-cross \nAbstract: Chronic diseases, including diabetes, hypertension, asthma, HIV-AIDS, epilepsy, and tuberculosis, necessitate rigorous adherence to medication to avert disease progression, manage symptoms, and decrease mortality rates. Adherence is frequently undermined by factors including patient behavior, caregiver support, elevated medical costs, and insufficient healthcare infrastructure. We propose AdCare-VLM, a specialized LLaVA-based multimodal large vision language model (LVLM) by introducing a unified visual latent space with pre-alignment to facilitate visual question answering (VQA) concerning medication adherence through patient videos. We employ a private dataset comprising 806 custom-annotated tuberculosis (TB) medication monitoring videos, which have been labeled by clinical experts, to fine-tune the model for adherence pattern detection. We present LLM-TB-VQA, a detailed medical adherence VQA dataset that encompasses positive, negative, and ambiguous adherence cases. Our method identifies correlations between visual features, such as the clear visibility of the patient's face, medication, water intake, and the act of ingestion, and their associated medical concepts in captions. This facilitates the integration of aligned visual-linguistic representations and improves multimodal interactions. Experimental results indicate that our method surpasses parameter-efficient fine-tuning (PEFT) enabled VLM models, such as LLaVA-V1.5 and Chat-UniVi, with absolute improvements ranging from 3.1% to 3.54% across pre-trained, regular, and low-rank adaptation (LoRA) configurations. Comprehensive ablation studies and attention map visualizations substantiate our approach, enhancing interpretability.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Md Asaduzzaman Jabin, Hanqi Jiang, Yiwei Li, Patrick Kaggwa, Eugene Douglass, Juliet N. Sekandi, Tianming Liu",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "OODTE: A Differential Testing Engine for the ONNX Optimizer",
      "url": "https://arxiv.org/abs/2505.01892",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.01892v4 Announce Type: replace-cross \nAbstract: With over 760 stars on GitHub and being part of the official ONNX repository, the ONNX Optimizer is the default tool for applying graph-based optimizations to ONNX models. Despite its widespread use, its ability to maintain model accuracy during optimization has not been thoroughly investigated. In this work, we present OODTE, a utility designed to automatically and comprehensively evaluate the correctness of the ONNX Optimizer. OODTE adopts a straightforward yet powerful differential testing and evaluation methodology, which can be readily adapted for use with other compiler optimizers. Specifically, OODTE takes a collection of ONNX models, applies optimizations, and executes both the original and optimized versions across a user-defined input set, automatically capturing any issues encountered during optimization. When discrepancies in accuracy arise, OODTE iteratively isolates the responsible optimization pass by repeating the process at a finer granularity. We applied OODTE to 130 well-known models from the official ONNX Model Hub, spanning diverse tasks including classification, object detection, semantic segmentation, text summarization, question answering, and sentiment analysis. Our evaluation revealed that 9.2% of the model instances either caused the optimizer to crash or led to the generation of invalid models using default optimization strategies. Additionally, 30% of classification models and 16.6% of object detection and segmentation models exhibited differing outputs across original and optimized versions, whereas models focused on text-related tasks were generally robust to optimization. OODTE uncovered 15 issues-14 previously unknown-affecting 9 of 47 optimization passes and the optimizer overall. All issues were reported to the ONNX Optimizer team. OODTE offers a simple but effective framework for validating AI model optimizers, applicable beyond the ONNX ecosystem.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Nikolaos Louloudakis, Ajitha Rajan",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.SE",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "A Typology of Synthetic Datasets for Dialogue Processing in Clinical Contexts",
      "url": "https://arxiv.org/abs/2505.03025",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.03025v2 Announce Type: replace-cross \nAbstract: Synthetic data sets are used across linguistic domains and NLP tasks, particularly in scenarios where authentic data is limited (or even non-existent). One such domain is that of clinical (healthcare) contexts, where there exist significant and long-standing challenges (e.g., privacy, anonymization, and data governance) which have led to the development of an increasing number of synthetic datasets. One increasingly important category of clinical dataset is that of clinical dialogues which are especially sensitive and difficult to collect, and as such are commonly synthesized.\n  While such synthetic datasets have been shown to be sufficient in some situations, little theory exists to inform how they may be best used and generalized to new applications. In this paper, we provide an overview of how synthetic datasets are created, evaluated and being used for dialogue related tasks in the medical domain. Additionally, we propose a novel typology for use in classifying types and degrees of data synthesis, to facilitate comparison and evaluation.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Steven Bedrick, A. Seza Do\\u{g}ru\\\"oz, Sergiu Nisioi",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning",
      "url": "https://arxiv.org/abs/2505.05226",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.05226v2 Announce Type: replace-cross \nAbstract: The Combined Algorithm Selection and Hyperparameter optimization (CASH) is a challenging resource allocation problem in the field of AutoML. We propose MaxUCB, a max k-armed bandit method to trade off exploring different model classes and conducting hyperparameter optimization. MaxUCB is specifically designed for the light-tailed and bounded reward distributions arising in this setting and, thus, provides an efficient alternative compared to classic max k-armed bandit methods assuming heavy-tailed reward distributions. We theoretically and empirically evaluate our method on four standard AutoML benchmarks, demonstrating superior performance over prior approaches. We make our code and data available at https://github.com/amirbalef/CASH_with_Bandits",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Amir Rezaei Balef, Claire Vernade, Katharina Eggensperger",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Turb-L1: Achieving Long-term Turbulence Tracing By Tackling Spectral Bias",
      "url": "https://arxiv.org/abs/2505.19038",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.19038v3 Announce Type: replace-cross \nAbstract: Accurately predicting the long-term evolution of turbulence is crucial for advancing scientific understanding and optimizing engineering applications. However, existing deep learning methods face significant bottlenecks in long-term autoregressive prediction, which exhibit excessive smoothing and fail to accurately track complex fluid dynamics. Our extensive experimental and spectral analysis of prevailing methods provides an interpretable explanation for this shortcoming, identifying Spectral Bias as the core obstacle. Concretely, spectral bias is the inherent tendency of models to favor low-frequency, smooth features while overlooking critical high-frequency details during training, thus reducing fidelity and causing physical distortions in long-term predictions. Building on this insight, we propose Turb-L1, an innovative turbulence prediction method, which utilizes a Hierarchical Dynamics Synthesis mechanism within a multi-grid architecture to explicitly overcome spectral bias. It accurately captures cross-scale interactions and preserves the fidelity of high-frequency dynamics, enabling reliable long-term tracking of turbulence evolution. Extensive experiments on the 2D turbulence benchmark show that Turb-L1 demonstrates excellent performance: (I) In long-term predictions, it reduces Mean Squared Error (MSE) by $80.3\\%$ and increases Structural Similarity (SSIM) by over $9\\times$ compared to the SOTA baseline, significantly improving prediction fidelity. (II) It effectively overcomes spectral bias, accurately reproducing the full enstrophy spectrum and maintaining physical realism in high-wavenumber regions, thus avoiding the spectral distortions or spurious energy accumulation seen in other methods.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Hao Wu, Yuan Gao, Chang Liu, Fan Xu, Fan Zhang, Zhihong Zhu, Yuqi Li, Xian Wu, Yuxuan Liang, Li Liu, Qingsong Wen, Kun Wang, Yu Zheng, Xiaomeng Huang",
      "tags": [
        "cs.LG",
        "cs.AI",
        "physics.flu-dyn"
      ]
    },
    {
      "title": "VeriThoughts: Enabling Automated Verilog Code Generation using Reasoning and Formal Verification",
      "url": "https://arxiv.org/abs/2505.20302",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.20302v3 Announce Type: replace-cross \nAbstract: This paper introduces VeriThoughts, a novel dataset designed for reasoning-based Verilog code generation. We establish a new benchmark framework grounded in formal verification methods to evaluate the quality and correctness of generated hardware descriptions. Additionally, we present a suite of specialized small-scale models optimized specifically for Verilog generation. Our work addresses the growing need for automated hardware design tools that can produce verifiably correct implementations from high-level specifications, potentially accelerating the hardware development process while maintaining rigorous correctness guarantees. Our code and data are available at \\href{https://github.com/wilyub/VeriThoughts}{this URL}.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Patrick Yubeaton, Andre Nakkab, Weihua Xiao, Luca Collini, Ramesh Karri, Chinmay Hegde, Siddharth Garg",
      "tags": [
        "cs.PL",
        "cs.AI",
        "cs.LO"
      ]
    },
    {
      "title": "MelodySim: Measuring Melody-aware Music Similarity for Plagiarism Detection",
      "url": "https://arxiv.org/abs/2505.20979",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.20979v2 Announce Type: replace-cross \nAbstract: We propose MelodySim, a melody-aware music similarity model and dataset for plagiarism detection. First, we introduce a novel method to construct a dataset focused on melodic similarity. By augmenting Slakh2100, an existing MIDI dataset, we generate variations of each piece while preserving the melody through modifications such as note splitting, arpeggiation, minor track dropout, and re-instrumentation. A user study confirms that positive pairs indeed contain similar melodies, while other musical tracks are significantly changed. Second, we develop a segment-wise melodic-similarity detection model that uses a MERT encoder and applies a triplet neural network to capture melodic similarity. The resulting decision matrix highlights where plagiarism might occur. The experiments show that our model is able to outperform baseline models in detecting similar melodic fragments on the MelodySim test set.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Tongyu Lu, Charlotta-Marlena Geist, Jan Melechovsky, Abhinaba Roy, Dorien Herremans",
      "tags": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ]
    },
    {
      "title": "Causal Representation Learning with Observational Grouping for CXR Classification",
      "url": "https://arxiv.org/abs/2506.20582",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2506.20582v2 Announce Type: replace-cross \nAbstract: Identifiable causal representation learning seeks to uncover the true causal relationships underlying a data generation process. In medical imaging, this presents opportunities to improve the generalisability and robustness of task-specific latent features. This work introduces the concept of grouping observations to learn identifiable representations for disease classification in chest X-rays via an end-to-end framework. Our experiments demonstrate that these causal representations improve generalisability and robustness across multiple classification tasks when grouping is used to enforce invariance w.r.t race, sex, and imaging views.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Rajat Rasal, Avinash Kori, Ben Glocker",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for Advertiser Keyphrase Recommendations",
      "url": "https://arxiv.org/abs/2508.03628",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.03628v5 Announce Type: replace-cross \nAbstract: E-commerce sellers are advised to bid on keyphrases to boost their advertising campaigns. These keyphrases must be relevant to prevent irrelevant items from cluttering search systems and to maintain positive seller perception. It is vital that keyphrase suggestions align with seller, search and buyer judgments. Given the challenges in collecting negative feedback in these systems, LLMs have been used as a scalable proxy to human judgments. This paper presents an empirical study on a major ecommerce platform of a distillation framework involving an LLM teacher, a cross-encoder assistant and a bi-encoder Embedding Based Retrieval (EBR) student model, aimed at mitigating click-induced biases in keyphrase recommendations.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Soumik Dey, Benjamin Braun, Naveen Ravipati, Hansi Wu, Binbin Li",
      "tags": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Data-driven ML Approach for Maximizing Performance in LLM-Adapter Serving",
      "url": "https://arxiv.org/abs/2508.08343",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.08343v3 Announce Type: replace-cross \nAbstract: With the rapid adoption of Large Language Models (LLMs), LLM-adapters have become increasingly common, providing lightweight specialization of large-scale models. Serving hundreds or thousands of these adapters on a single GPU allows request aggregation, increasing throughput, but may also cause request starvation if GPU memory limits are exceeded. To address this issue, this study focuses on determining the joint configuration of concurrent and parallel adapters that maximizes GPU throughput without inducing starvation, given heterogeneous adapter and traffic properties. We propose a data-driven ML approach leveraging interpretable models to tackle this caching problem and introduce the first Digital Twin capable of reproducing an LLM-adapter serving system, enabling efficient training data generation. Experiments with the vLLM framework and LoRA adapters show that the Digital Twin reproduces throughput within 5.1% of real results, while the ML approach predicts optimal numbers of concurrent and parallel adapters with an error of at most 7.2% under heterogeneous, real-world workloads. The code is publicly available at https://github.com/FerranAgulloLopez/GPULLMAdapterOptimization.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Ferran Agullo, Joan Oliveras, Chen Wang, Alberto Gutierrez-Torre, Olivier Tardieu, Alaa Youssef, Jordi Torres, Josep Ll. Berral",
      "tags": [
        "cs.PF",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding",
      "url": "https://arxiv.org/abs/2508.11999",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.11999v3 Announce Type: replace-cross \nAbstract: With the rapid advancement of e-commerce, exploring general representations rather than task-specific ones has attracted increasing research attention. For product understanding, although existing discriminative dual-flow architectures drive progress in this field, they inherently struggle to model the many-to-one alignment between multiple images and texts of products. Therefore, we argue that generative Multimodal Large Language Models (MLLMs) hold significant potential for improving product representation learning. Nevertheless, achieving this goal still remains non-trivial due to several key challenges: the lack of multimodal and aspect-aware modeling modules in typical LLMs; the common presence of background noise in product images; and the absence of a standard benchmark for evaluation. To address these issues, we propose the first generative MLLM-based model named MOON for product representation learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for targeted modeling of multimodal and aspect-specific product content; (2) effectively detects core semantic regions in product images to mitigate the distraction and interference caused by background noise; and (3) introduces the specialized negative sampling strategy to increase the difficulty and diversity of negative samples. In addition, we release a large-scale multimodal benchmark MBE for various product understanding tasks. Experimentally, our model demonstrates competitive zero-shot performance on both our benchmark and the public dataset, showcasing strong generalization across various downstream tasks, including cross-modal retrieval, product classification, and attribute prediction. Furthermore, the case study and visualization illustrate the effectiveness of MOON for product understanding.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Daoze Zhang, Chenghan Fu, Zhanheng Nie, Jianyu Liu, Wanxian Guan, Yuan Gao, Jun Song, Pengjie Wang, Jian Xu, Bo Zheng",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Few-shot Class-incremental Fault Diagnosis by Preserving Class-Agnostic Knowledge with Dual-Granularity Representations",
      "url": "https://arxiv.org/abs/2508.16634",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.16634v3 Announce Type: replace-cross \nAbstract: Few-Shot Class-Incremental Fault Diagnosis (FSC-FD), which aims to continuously learn from new fault classes with only a few samples without forgetting old ones, is critical for real-world industrial systems. However, this challenging task severely amplifies the issues of catastrophic forgetting of old knowledge and overfitting on scarce new data. To address these challenges, this paper proposes a novel framework built upon Dual-Granularity Representations, termed the Dual-Granularity Guidance Network (DGGN). Our DGGN explicitly decouples feature learning into two parallel streams: 1) a fine-grained representation stream, which utilizes a novel Multi-Order Interaction Aggregation module to capture discriminative, class-specific features from the limited new samples. 2) a coarse-grained representation stream, designed to model and preserve general, class-agnostic knowledge shared across all fault types. These two representations are dynamically fused by a multi-semantic cross-attention mechanism, where the stable coarse-grained knowledge guides the learning of fine-grained features, preventing overfitting and alleviating feature conflicts. To further mitigate catastrophic forgetting, we design a Boundary-Aware Exemplar Prioritization strategy. Moreover, a decoupled Balanced Random Forest classifier is employed to counter the decision boundary bias caused by data imbalance. Extensive experiments on the TEP benchmark and a real-world MFF dataset demonstrate that our proposed DGGN achieves superior diagnostic performance and stability compared to state-of-the-art FSC-FD approaches. Our code is publicly available at https://github.com/MentaY/DGGN",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zhendong Yang, Jie Wang, Liansong Zong, Xiaorong Liu, Quan Qian, Shiqian Chen",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ReFactX: Scalable Reasoning with Reliable Facts via Constrained Generation",
      "url": "https://arxiv.org/abs/2508.16983",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.16983v2 Announce Type: replace-cross \nAbstract: Knowledge gaps and hallucinations are persistent challenges for Large Language Models (LLMs), which generate unreliable responses when lacking the necessary information to fulfill user instructions. Existing approaches, such as Retrieval-Augmented Generation (RAG) and tool use, aim to address these issues by incorporating external knowledge. Yet, they rely on additional models or services, resulting in complex pipelines, potential error propagation, and often requiring the model to process a large number of tokens. In this paper, we present a scalable method that enables LLMs to access external knowledge without depending on retrievers or auxiliary models. Our approach uses constrained generation with a pre-built prefix-tree index. Triples from a Knowledge Graph are verbalized in textual facts, tokenized, and indexed in a prefix tree for efficient access. During inference, to acquire external knowledge, the LLM generates facts with constrained generation which allows only sequences of tokens that form an existing fact. We evaluate our proposal on Question Answering and show that it scales to large knowledge bases (800 million facts), adapts to domain-specific data, and achieves effective results. These gains come with minimal generation-time overhead. ReFactX code is available at https://github.com/rpo19/ReFactX.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Riccardo Pozzi, Matteo Palmonari, Andrea Coletta, Luigi Bellomarini, Jens Lehmann, Sahar Vahdati",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Inference of Human-derived Specifications of Object Placement via Demonstration",
      "url": "https://arxiv.org/abs/2508.19367",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.19367v2 Announce Type: replace-cross \nAbstract: As robots' manipulation capabilities improve for pick-and-place tasks (e.g., object packing, sorting, and kitting), methods focused on understanding human-acceptable object configurations remain limited expressively with regard to capturing spatial relationships important to humans. To advance robotic understanding of human rules for object arrangement, we introduce positionally-augmented RCC (PARCC), a formal logic framework based on region connection calculus (RCC) for describing the relative position of objects in space. Additionally, we introduce an inference algorithm for learning PARCC specifications via demonstrations. Finally, we present the results from a human study, which demonstrate our framework's ability to capture a human's intended specification and the benefits of learning from demonstration approaches over human-provided specifications.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Alex Cuellar, Ho Chit Siu, Julie A Shah",
      "tags": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "U2UData+: A Scalable Swarm UAVs Autonomous Flight Dataset for Embodied Long-horizon Tasks",
      "url": "https://arxiv.org/abs/2509.00055",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.00055v2 Announce Type: replace-cross \nAbstract: Swarm UAV autonomous flight for Embodied Long-Horizon (ELH) tasks is crucial for advancing the low-altitude economy. However, existing methods focus only on specific basic tasks due to dataset limitations, failing in real-world deployment for ELH tasks. ELH tasks are not mere concatenations of basic tasks, requiring handling long-term dependencies, maintaining embodied persistent states, and adapting to dynamic goal shifts. This paper presents U2UData+, the first large-scale swarm UAV autonomous flight dataset for ELH tasks and the first scalable swarm UAV data online collection and algorithm closed-loop verification platform. The dataset is captured by 15 UAVs in autonomous collaborative flights for ELH tasks, comprising 12 scenes, 720 traces, 120 hours, 600 seconds per trajectory, 4.32M LiDAR frames, and 12.96M RGB frames. This dataset also includes brightness, temperature, humidity, smoke, and airflow values covering all flight routes. The platform supports the customization of simulators, UAVs, sensors, flight algorithms, formation modes, and ELH tasks. Through a visual control window, this platform allows users to collect customized datasets through one-click deployment online and to verify algorithms by closed-loop simulation. U2UData+ also introduces an ELH task for wildlife conservation and provides comprehensive benchmarks with 9 SOTA models. U2UData+ can be found at https://fengtt42.github.io/U2UData-2/.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Tongtong Feng, Xin Wang, Feilin Han, Leping Zhang, Wenwu Zhu",
      "tags": [
        "cs.RO",
        "cs.AI",
        "cs.MA",
        "cs.MM"
      ]
    },
    {
      "title": "In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents",
      "url": "https://arxiv.org/abs/2509.01560",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.01560v2 Announce Type: replace-cross \nAbstract: Tool agents -- LLM-based systems that interact with external APIs -- offer a way to execute real-world tasks. However, as tasks become increasingly complex, these agents struggle to identify and call the correct APIs in the proper order. To tackle this problem, we investigate converting API documentation into a structured API graph that captures API dependencies and leveraging it for multi-tool queries that require compositional API calls. To support this, we introduce In-N-Out, the first expert-annotated dataset of API graphs built from two real-world API benchmarks and their documentation. Using In-N-Out significantly improves performance on both tool retrieval and multi-tool query generation, nearly doubling that of LLMs using documentation alone. Moreover, graphs generated by models fine-tuned on In-N-Out close 90% of this gap, showing that our dataset helps models learn to comprehend API documentation and parameter relationships. Our findings highlight the promise of using explicit API graphs for tool agents and the utility of In-N-Out as a valuable resource. We will release the dataset and code publicly.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Seungkyu Lee, Nalim Kim, Yohan Jo",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Differentiable Entropy Regularization: A Complexity-Aware Approach for Neural Optimization",
      "url": "https://arxiv.org/abs/2509.03733",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.03733v2 Announce Type: replace-cross \nAbstract: We introduce the first differentiable approximation of range-partition entropy, a complexity measure from computational geometry that directly bounds algorithmic runtime. Unlike architectural modifications, our method is a complementary regularizer that provides orthogonal efficiency gains when combined with existing optimizations. We establish theoretical guarantees in computational geometry, achieving 4--5$\\times$ provable speedups on convex hull and triangulation with $<$0.2\\% error. On ImageNet-1K with ViT-Base, entropy regularization achieves 80.1\\% top-1 accuracy at 80\\% sparsity (1.60$\\times$ standalone speedup), and when combined with FlashAttention yields 2.07$\\times$ speedup versus 1.63$\\times$ for FlashAttention alone. On large language models (LLaMA-2 7B, Mistral-7B, Phi-2), we achieve 1.48--1.60$\\times$ inference speedups at 70--75\\% sparsity with minimal quality degradation (ROUGE-L drops of 0.3--0.4 points, perplexity increase of 0.9). Unlike prior regularization methods that target output distributions, we directly minimize representation complexity, yielding both efficiency gains and improved robustness through semantically structured sparsity patterns (IoU 0.73 vs 0.41 for magnitude pruning, CIFAR-100-C mCE 48.7 vs 55.4). Benefits are strongest for geometry and vision transformers, with more modest but measurable gains on LLMs, demonstrating that complexity regularization offers a principled pathway to joint efficiency-robustness optimization.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "From Vision to Validation: A Theory- and Data-Driven Construction of a GCC-Specific AI Adoption Index",
      "url": "https://arxiv.org/abs/2509.05474",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.05474v4 Announce Type: replace-cross \nAbstract: Artificial intelligence (AI) is rapidly transforming public-sector processes worldwide, yet standardized measures rarely address the unique drivers, governance models, and cultural nuances of the Gulf Cooperation Council (GCC) countries. This study employs a theory-driven foundation derived from an in-depth analysis of literature review and six National AI Strategies (NASs), coupled with a data-driven approach that utilizes a survey of 203 mid- and senior-level government employees and advanced statistical techniques (K-Means clustering, Principal Component Analysis, and Partial Least Squares Structural Equation Modeling). By combining policy insights with empirical evidence, the research develops and validates a novel AI Adoption Index specifically tailored to the GCC public sector. Findings indicate that robust technical infrastructure and clear policy mandates exert the strongest influence on successful AI implementations, overshadowing organizational readiness in early adoption stages. The combined model explains 70% of the variance in AI outcomes, suggesting that resource-rich environments and top-down policy directives can drive rapid but uneven technology uptake. By consolidating key dimensions (Technical Infrastructure (TI), Organizational Readiness (OR), and Governance Environment (GE)) into a single composite index, this study provides a holistic yet context-sensitive tool for benchmarking AI maturity. The index offers actionable guidance for policymakers seeking to harmonize large-scale deployments with ethical and regulatory standards. Beyond advancing academic discourse, these insights inform more strategic allocation of resources, cross-country cooperation, and capacity-building initiatives, thereby supporting sustained AI-driven transformation in the GCC region and beyond.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mohammad Rashed Albous, Abdel Latef Anouze",
      "tags": [
        "cs.CY",
        "cs.AI"
      ]
    },
    {
      "title": "Accelerating Local AI on Consumer GPUs: A Hardware-Aware Dynamic Strategy for YOLOv10s",
      "url": "https://arxiv.org/abs/2509.07928",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.07928v2 Announce Type: replace-cross \nAbstract: As local AI grows in popularity, there is a critical gap between the benchmark performance of object detectors and their practical viability on consumer-grade hardware. While models like YOLOv10s promise real-time speeds, these metrics are typically achieved on high-power, desktop-class GPUs. This paper reveals that on resource-constrained systems, such as laptops with RTX 4060 GPUs, performance is not compute-bound but is instead dominated by system-level bottlenecks, as illustrated by a simple bottleneck test. To overcome this hardware-level constraint, we introduce a Two-Pass Adaptive Inference algorithm, a model-independent approach that requires no architectural changes. This study mainly focuses on adaptive inference strategies and undertakes a comparative analysis of architectural early-exit and resolution-adaptive routing, highlighting their respective trade-offs within a unified evaluation framework. The system uses a fast, low-resolution pass and only escalates to a high-resolution model pass when detection confidence is low. On a 5000-image COCO dataset, our method achieves a 1.85x speedup over a PyTorch Early-Exit baseline, with a modest mAP loss of 5.51%. This work provides a practical and reproducible blueprint for deploying high-performance, real-time AI on consumer-grade devices by shifting the focus from pure model optimization to hardware-aware inference strategies that maximize throughput.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Mahmudul Islam Masum, Miad Islam",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Beyond Diagnosis: Evaluating Multimodal LLMs for Pathology Localization in Chest Radiographs",
      "url": "https://arxiv.org/abs/2509.18015",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.18015v2 Announce Type: replace-cross \nAbstract: Recent work has shown promising performance of frontier large language models (LLMs) and their multimodal counterparts in medical quizzes and diagnostic tasks, highlighting their potential for broad clinical utility given their accessible, general-purpose nature. However, beyond diagnosis, a fundamental aspect of medical image interpretation is the ability to localize pathological findings. Evaluating localization not only has clinical and educational relevance but also provides insight into a model's spatial understanding of anatomy and disease. Here, we systematically assess two general-purpose MLLMs (GPT-4 and GPT-5) and a domain-specific model (MedGemma) in their ability to localize pathologies on chest radiographs, using a prompting pipeline that overlays a spatial grid and elicits coordinate-based predictions. Averaged across nine pathologies in the CheXlocalize dataset, GPT-5 exhibited a localization accuracy of 49.7%, followed by GPT-4 (39.1%) and MedGemma (17.7%), all lower than a task-specific CNN baseline (59.9%) and a radiologist benchmark (80.1%). Despite modest performance, error analysis revealed that GPT-5's predictions were largely in anatomically plausible regions, just not always precisely localized. GPT-4 performed well on pathologies with fixed anatomical locations, but struggled with spatially variable findings and exhibited anatomically implausible predictions more frequently. MedGemma demonstrated the lowest performance on all pathologies, but showed improvements when provided examples through few shot prompting. Our findings highlight both the promise and limitations of current MLLMs in medical imaging and underscore the importance of integrating them with task-specific tools for reliable use.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Advait Gosai, Arun Kavishwar, Stephanie L. McNamara, Soujanya Samineni, Renato Umeton, Alexander Chowdhury, William Lotter",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "MMG: Mutual Information Estimation via the MMSE Gap in Diffusion",
      "url": "https://arxiv.org/abs/2509.20609",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.20609v2 Announce Type: replace-cross \nAbstract: Mutual information (MI) is one of the most general ways to measure relationships between random variables, but estimating this quantity for complex systems is challenging. Denoising diffusion models have recently set a new bar for density estimation, so it is natural to consider whether these methods could also be used to improve MI estimation. Using the recently introduced information-theoretic formulation of denoising diffusion models, we show the diffusion models can be used in a straightforward way to estimate MI. In particular, the MI corresponds to half the gap in the Minimum Mean Square Error (MMSE) between conditional and unconditional diffusion, integrated over all Signal-to-Noise-Ratios (SNRs) in the noising process. Our approach not only passes self-consistency tests but also outperforms traditional and score-based diffusion MI estimators. Furthermore, our method leverages adaptive importance sampling to achieve scalable MI estimation, while maintaining strong performance even when the MI is high.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Longxuan Yu, Xing Shi, Xianghao Kong, Tong Jia, Greg Ver Steeg",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Observation-Free Attacks on Online Learning to Rank",
      "url": "https://arxiv.org/abs/2509.22855",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.22855v3 Announce Type: replace-cross \nAbstract: Online learning to rank (OLTR) plays a critical role in information retrieval and machine learning systems, with a wide range of applications in search engines and content recommenders. However, despite their extensive adoption, the susceptibility of OLTR algorithms to coordinated adversarial attacks remains poorly understood. In this work, we present a novel framework for attacking some of the widely used OLTR algorithms. Our framework is designed to promote a set of target items so that they appear in the list of top-K recommendations for T - o(T) rounds, while simultaneously inducing linear regret in the learning algorithm. We propose two novel attack strategies: CascadeOFA for CascadeUCB1 and PBMOFA for PBM-UCB . We provide theoretical guarantees showing that both strategies require only O(log T) manipulations to succeed. Additionally, we supplement our theoretical analysis with empirical results on real-world data.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sameep Chattopadhyay, Nikhil Karamchandani, Sharayu Moharir",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention",
      "url": "https://arxiv.org/abs/2509.24006",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.24006v2 Announce Type: replace-cross \nAbstract: In Diffusion Transformer (DiT) models, particularly for video generation, attention latency is a major bottleneck due to the long sequence length and the quadratic complexity. We find that attention weights can be separated into two parts: a small fraction of large weights with high rank and the remaining weights with very low rank. This naturally suggests applying sparse acceleration to the first part and low-rank acceleration to the second. Based on this finding, we propose SLA (Sparse-Linear Attention), a trainable attention method that fuses sparse and linear attention to accelerate diffusion models. SLA classifies attention weights into critical, marginal, and negligible categories, applying O(N^2) attention to critical weights, O(N) attention to marginal weights, and skipping negligible ones. SLA combines these computations into a single GPU kernel and supports both forward and backward passes. With only a few fine-tuning steps using SLA, DiT models achieve a 20x reduction in attention computation, resulting in significant acceleration without loss of generation quality. Experiments show that SLA reduces attention computation by 95% without degrading end-to-end generation quality, outperforming baseline methods. In addition, we implement an efficient GPU kernel for SLA, which yields a 13.7x speedup in attention computation and a 2.2x end-to-end speedup in video generation on Wan2.1-1.3B. The code is available at https://github.com/thu-ml/SLA.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jintao Zhang, Haoxu Wang, Kai Jiang, Shuo Yang, Kaiwen Zheng, Haocheng Xi, Ziteng Wang, Hongzhou Zhu, Min Zhao, Ion Stoica, Joseph E. Gonzalez, Jun Zhu, Jianfei Chen",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks",
      "url": "https://arxiv.org/abs/2509.24473",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.24473v3 Announce Type: replace-cross \nAbstract: Spatial intelligence spans a rich suite of abilities, including visualising and transforming shapes, mentally rotating objects, judging relational positions and containment, and estimating numerosity. However, it still remains a critical unresolved challenge for Multimodal Large Language Models (MLLMs). To fill this gap, we propose to treat Euclidean geometry problem-solving as a surrogate task. Specifically, we meticulously constructed a curated multimodal dataset, called Euclid30K, comprising approximately 30K plane and solid geometry problems. Furthermore, to enable the model to learn and apply Euclidean principles from these geometry problems, we fine-tuned seven model variants (spanning 3--72B parameters) from the Qwen2.5VL, Qwen3VL, and RoboBrain2.0 families using Group Relative Policy Optimization (GRPO), inspiring the models to identify shapes, count, and relate entities, and perform multi-step deductive reasoning using Euclidean principles. Our experiments demonstrate that the resulting models achieve substantial zero-shot gains across four spatial reasoning benchmarks (Super-CLEVR, Omni3DBench, VSI-Bench, and MindCube) without any task-specific adaptations. Notably, after training on the Euclid30K, the mean VSI-Bench accuracy rose from 36.6\\% to 41.8\\% (+5.2\\%), and the mean MindCube accuracy rose from 31.4\\% to 38.1\\% (+6.7\\%). To our knowledge, this is the first systematic study showing that geometry-centric fine-tuning can confer vision-language models with broadly transferable spatial skills. Code and Euclid30K dataset can be found in \\href{https://zgca-ai4edu.github.io/Euclids_Gift}{this}.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Shijie Lian, Changti Wu, Laurence Tianruo Yang, Hang Yuan, Bin Yu, Lei Zhang, Kai Chen",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "A Denoising Framework for Real-World Ultra-Low-Dose Lung CT Images Based on an Image Purification Strategy",
      "url": "https://arxiv.org/abs/2510.07492",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.07492v3 Announce Type: replace-cross \nAbstract: Computed Tomography (CT) is a vital diagnostic tool in clinical practice, yet the health risks associated with ionizing radiation cannot be overlooked. Low-dose CT (LDCT) helps mitigate radiation exposure but simultaneously leads to reduced image quality. Consequently, researchers have sought to reconstruct clear images from LDCT scans using artificial intelligence-based image enhancement techniques. However, these studies typically rely on synthetic LDCT images for algorithm training, which introduces significant domain-shift issues and limits the practical effectiveness of these algorithms in real-world scenarios. To address this challenge, we constructed a real-world paired lung dataset, referred to as Patient-uLDCT (ultra-low-dose CT), by performing multiple scans on volunteers. The radiation dose for the low-dose images in this dataset is only 2% of the normal dose, substantially lower than the conventional 25% low-dose and 10% ultra-low-dose levels. Furthermore, to resolve the anatomical misalignment between normal-dose and uLDCT images caused by respiratory motion during acquisition, we propose a novel purification strategy to construct corresponding aligned image pairs. Finally, we introduce a Frequency-domain Flow Matching model (FFM) that achieves excellent image reconstruction performance. Code is available at https://github.com/MonkeyDadLufy/flow-matching.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Guoliang Gong, Man Yu",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "DeepEN: A Deep Reinforcement Learning Framework for Personalized Enteral Nutrition in Critical Care",
      "url": "https://arxiv.org/abs/2510.08350",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.08350v2 Announce Type: replace-cross \nAbstract: ICU enteral feeding remains sub-optimal due to limited personalization and uncertainty about appropriate calorie, protein, and fluid targets, particularly under rapidly changing metabolic demands and heterogeneous patient responses. This study introduces DeepEN, a reinforcement learning (RL)-based framework that personalizes enteral nutrition (EN) dosing for critically ill patients using electronic health record data. DeepEN was trained on over 11,000 ICU patients from the MIMIC-IV database to generate 4-hourly, patient-specific targets for caloric, protein, and fluid intake. The model's state space integrates demographics, comorbidities, vital signs, laboratory results, and prior interventions relevant to nutritional management, while its reward function balances short-term physiological and nutrition-related goals with long-term survival. A dueling double deep Q-network with Conservative Q-Learning regularization is used to ensure safe and reliable policy learning from retrospective data. DeepEN achieved a 3.7 $\\pm$ 0.17 percentage-point absolute reduction in estimated mortality compared with the clinician policy (18.8% vs 22.5%) and higher expected returns compared with guideline-based dosing (11.89 vs 8.11), with improvements in key nutritional biomarkers. U-shaped associations between deviations from clinician dosing and mortality suggest that the learned policy aligns with high-value clinician actions while diverging from suboptimal ones. These findings demonstrate the feasibility of conservative offline RL for individualized EN therapy and suggest that data-driven personalization may improve outcomes beyond guideline- or heuristic-based approaches.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Daniel Jason Tan, Jiayang Chen, Dilruk Perera, Kay Choong See, Mengling Feng",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Automating Android Build Repair: Bridging the Reasoning-Execution Gap in LLM Agents with Domain-Specific Tools",
      "url": "https://arxiv.org/abs/2510.08640",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.08640v2 Announce Type: replace-cross \nAbstract: Android is the largest mobile platform, yet automatically building applications remains a practical challenge. While Large Language Models (LLMs) show promise for code repair, their use for fixing Android build errors remains underexplored. To address this gap, we first introduce AndroidBuildBench, a benchmark of 1,019 build failures curated from the commit histories of 43 open-source Android projects. Each problem is paired with a verified solution from a subsequent commit, ensuring that fixes are feasible. Second, we propose GradleFixer, an LLM agent with domain-specific tools for inspecting and manipulating the Gradle build environment. GradleFixer achieves a resolve rate of 81.4% (pass@1), significantly outperforming a state-of-the-art coding agent that relies on a general-purpose shell. GradleFixer's success suggests that while LLMs possess the high-level knowledge to solve these failures, they struggle to translate this knowledge into effective low-level actions using a general-purpose shell. We demonstrate the effectiveness of a strategy we term Tool Bridging, which replaces general-purpose shell commands with domain-aware abstractions. We hypothesize this approach works through two mechanisms: 1) it provides tools in an API-like format that LLMs use more reliably, and 2) it constrains the action space to relevant operations. This approach bridges the gap between the model's high-level reasoning and effective low-level execution.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Ha Min Son, Huan Ren, Xin Liu, Zhe Zhao",
      "tags": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning",
      "url": "https://arxiv.org/abs/2510.13515",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.13515v2 Announce Type: replace-cross \nAbstract: Universal multimodal embedding models are foundational to various tasks. Existing approaches typically employ in-batch negative mining by measuring the similarity of query-candidate pairs. However, these methods often struggle to capture subtle semantic differences among candidates and lack diversity in negative samples. Moreover, the embeddings exhibit limited discriminative ability in distinguishing false and hard negatives. In this paper, we leverage the advanced understanding capabilities of MLLMs to enhance representation learning and present a novel Universal Multimodal Embedding (UniME-V2) model. Our approach first constructs a potential hard negative set through global retrieval. We then introduce the MLLM-as-a-Judge mechanism, which utilizes MLLMs to assess the semantic alignment of query-candidate pairs and generate soft semantic matching scores. These scores serve as a foundation for hard negative mining, mitigating the impact of false negatives and enabling the identification of diverse, high-quality hard negatives. Furthermore, the semantic matching scores are used as soft labels to mitigate the rigid one-to-one mapping constraint. By aligning the similarity matrix with the soft semantic matching score matrix, the model learns semantic distinctions among candidates, significantly enhancing its discriminative capacity. To further improve performance, we propose UniME-V2-Reranker, a reranking model trained on our mined hard negatives through a joint pairwise and listwise optimization approach. We conduct comprehensive experiments on the MMEB benchmark and multiple retrieval tasks, demonstrating that our method achieves state-of-the-art performance on average across all tasks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Tiancheng Gu, Kaicheng Yang, Kaichen Zhang, Xiang An, Ziyong Feng, Yueyi Zhang, Weidong Cai, Jiankang Deng, Lidong Bing",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning",
      "url": "https://arxiv.org/abs/2510.14830",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.14830v3 Announce Type: replace-cross \nAbstract: Real-world robotic manipulation in homes and factories demands reliability, efficiency, and robustness that approach or surpass the performance of skilled human operators. We present RL-100, a real-world reinforcement learning framework built on diffusion-based visuomotor policies. RL-100 unifies imitation and reinforcement learning under a single PPO-style objective applied within the denoising process, yielding conservative and stable policy improvements across both offline and online stages. To meet deployment latency constraints, we employ a lightweight consistency distillation procedure that compresses multi-step diffusion into a one-step controller for high-frequency control. The framework is task-, embodiment-, and representation-agnostic, and supports both single-action outputs and action-chunking control. We evaluate RL-100 on seven diverse real-robot manipulation tasks, ranging from dynamic pushing and agile bowling to pouring, cloth folding, unscrewing, and multi-stage juicing. RL-100 attains 100% success across evaluated trials, achieving 900 out of 900 successful episodes, including up to 250 out of 250 consecutive trials on one task, and matches or surpasses expert teleoperators in time-to-completion. Without retraining, a single policy attains approximately 90% zero-shot success under environmental and dynamics shifts, adapts in a few-shot regime to significant task variations (86.7%), and remains robust to aggressive human perturbations (about 95%). In a public shopping-mall deployment, the juicing robot served random customers continuously for roughly seven hours without failure. Together, these results suggest a practical path toward deployment-ready robot learning: start from human priors, align training objectives with human-grounded metrics, and reliably extend performance beyond human demonstrations.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kun Lei, Huanyu Li, Dongjie Yu, Zhenyu Wei, Lingxiao Guo, Zhennan Jiang, Ziyu Wang, Shiyu Liang, Huazhe Xu",
      "tags": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains",
      "url": "https://arxiv.org/abs/2510.17793",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.17793v2 Announce Type: replace-cross \nAbstract: Finetuning specialized generative evaluators has emerged as a popular paradigm to meet the increasing demand for scalable evaluation during both training and test-time. However, recent work has largely focused on applying new methodology, such as reinforcement learning (RL), to training evaluators, shying away from large-scale, data-driven development. In this work, we focus on data scaling, curating a set of 2.5M samples spanning five unique evaluation tasks (pairwise, step-level, reference-free and reference-based verification, and single rating) and multiple domains focused on reasoning evaluation. With our data, we train Foundational Automatic Reasoning Evaluators (FARE), a family of 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative rejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges larger specialized RL-trained evaluators and FARE-20B sets the new standard for open-source evaluators, surpassing specialized 70B+ evaluators. Beyond static benchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers, FARE-20B achieves near-oracle performance on MATH. As verifiers in RL training, FARE improves the downstream RL-trained model performance by up to 14.1% vs. string-matching verifiers. When initialized from FARE, a continually-finetuned FARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Austin Xu, Xuan-Phi Nguyen, Yilun Zhou, Chien-Sheng Wu, Caiming Xiong, Shafiq Joty",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning",
      "url": "https://arxiv.org/abs/2510.20098",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.20098v2 Announce Type: replace-cross \nAbstract: Entity Linking (EL) has traditionally relied on large annotated datasets and extensive model fine-tuning. While recent few-shot methods leverage large language models (LLMs) through prompting to reduce training requirements, they often suffer from inefficiencies due to expensive LLM-based reasoning. ARTER (Adaptive Routing and Targeted Entity Reasoning) presents a structured pipeline that achieves high performance without deep fine-tuning by strategically combining candidate generation, context-based scoring, adaptive routing, and selective reasoning. ARTER computes a small set of complementary signals(both embedding and LLM-based) over the retrieved candidates to categorize contextual mentions into easy and hard cases. The cases are then handled by a low-computational entity linker (e.g. ReFinED) and more expensive targeted LLM-based reasoning respectively. On standard benchmarks, ARTER outperforms ReFinED by up to +4.47%, with an average gain of +2.53% on 5 out of 6 datasets, and performs comparably to pipelines using LLM-based reasoning for all mentions, while being as twice as efficient in terms of the number of LLM tokens.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yajie Li, Albert Galimov, Mitra Datta Ganapaneni, Pujitha Thejaswi, De Meng, Priyanshu Kumar, Saloni Potdar",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2510.20548",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.20548v2 Announce Type: replace-cross \nAbstract: Reinforcement learning has recently shown promise in improving retrieval-augmented generation (RAG). Despite these advances, its effectiveness in multi-hop question answering (QA) remains limited by two fundamental limitations: (i) global planning absence to structure multi-step reasoning, and (ii) unfaithful execution, which hinders effective query formulation and consistent use of retrieved evidence. We propose GlobalRAG, a reinforcement learning framework designed to enhance global reasoning in multi-hop QA. GlobalRAG decomposes questions into subgoals, coordinates retrieval with reasoning, and refines evidence iteratively. To guide this process, we introduce Planning Quality Reward and SubGoal Completion Reward, which encourage coherent planning and reliable subgoal execution. In addition, a progressive weight annealing strategy balances process-oriented and outcome-based objectives. Extensive experiments on both in-domain and out-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms strong baselines while using only 8k training data (42% of the training data used by strong baselines), achieving average improvements of 14.2% in both EM and F1.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jinchang Luo, Mingquan Cheng, Fan Wan, Ni Li, Xiaoling Xia, Shuangshuang Tian, Tingcheng Bian, Haiwei Wang, Haohuan Fu, Yan Tao",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start",
      "url": "https://arxiv.org/abs/2510.25801",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.25801v2 Announce Type: replace-cross \nAbstract: Reinforcement learning (RL) with verifiable rewards has recently catalyzed a wave of \"MLLM-r1\" approaches that bring RL to vision language models. Most representative paradigms begin with a cold start, typically employing supervised fine-tuning (SFT), to initialize the policy before RL. However, SFT-based cold start adopts the reasoning paradigm intertwined with task solution and output format, which may induce instruction-style overfitting, weakens out-of-distribution generalization, and ultimately affects downstream RL. We revisit the cold start along two views, its training method and data construction, and introduce the Generalization Factor (GF) coefficient to quantify the generalization capability under different methods. Our empirical study finds that preference-based training methods (e.g. DPO) generalizes better than SFT-based methods in cold start. Motivated by this, we propose SPECS-a Self-distilled, Preference-based Cold Start framework that decouples multimodal learning: (1) generates introspective preference data pairs via self-distillation, avoiding reliance on larger teachers or manual annotation; (2) performs preference-based training to learn, focusing on shallow, transferable surface-form criteria (format, structure, style) rather than memorizing content; and (3) hands off to RL with verifiable rewards for deep reasoning results. Experimental results across multiple multimodal benchmarks show that our decoupling learning framework yields consistent performance gains over strong baselines, improving MEGA-Bench by 4.1% and MathVista by 12.2%. Additional experiments indicate that SPECS contributes to reducing in-distribution \"stuckness,\" improving exploration, stabilizing training, and raising the performance ceiling.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kun Chen, Peng Shi, Haibo Qiu, Zhixiong Zeng, Siqi Yang, Wenji Mao, Lin Ma",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots",
      "url": "https://arxiv.org/abs/2511.00917",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.00917v2 Announce Type: replace-cross \nAbstract: Today's best-explored routes towards generalist robots center on collecting ever larger \"observations-in actions-out\" robotics datasets to train large end-to-end models, copying a recipe that has worked for vision-language models (VLMs). We pursue a road less traveled: building generalist policies directly around VLMs by augmenting their general capabilities with specific robot capabilities encapsulated in a carefully curated set of perception, planning, and control modules. In Maestro, a VLM coding agent dynamically composes these modules into a programmatic policy for the current task and scenario. Maestro's architecture benefits from a streamlined closed-loop interface without many manually imposed structural constraints, and a comprehensive and diverse tool repertoire. As a result, it largely surpasses today's VLA models for zero-shot performance on challenging manipulation skills. Further, Maestro is easily extensible to incorporate new modules, easily editable to suit new embodiments such as a quadruped-mounted arm, and even easily adapts from minimal real-world experiences through local code edits.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Junyao Shi, Rujia Yang, Kaitian Chao, Selina Bingqing Wan, Yifei Shao, Jiahui Lei, Jianing Qian, Long Le, Pratik Chaudhari, Kostas Daniilidis, Chuan Wen, Dinesh Jayaraman",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "Importance Ranking in Complex Networks via Influence-aware Causal Node Embedding",
      "url": "https://arxiv.org/abs/2511.01228",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.01228v2 Announce Type: replace-cross \nAbstract: Understanding and quantifying node importance is a fundamental problem in network science and engineering, underpinning a wide range of applications such as influence maximization, social recommendation, and network dismantling. Prior research often relies on centrality measures or advanced graph embedding techniques using structural information, followed by downstream classification or regression tasks to identify critical nodes. However, these methods typically decouple node representation learning from the ranking objective and rely on the topological structure of target networks, leading to feature-task inconsistency and limited generalization across networks. This paper proposes a novel framework that leverages causal representation learning to get robust, invariant node embeddings for cross-network ranking tasks. Firstly, we introduce an influence-aware causal node embedding module within an autoencoder architecture to extract node embeddings that are causally related to node importance. Moreover, we introduce a causal ranking loss and design a unified optimization framework that jointly optimizes the reconstruction and ranking objectives, enabling mutual reinforcement between node representation learning and ranking optimization. This design allows the proposed model to be trained on synthetic networks and to generalize effectively across diverse real-world networks. Extensive experiments on multiple benchmark datasets demonstrate that the proposed model consistently outperforms state-of-the-art baselines in terms of both ranking accuracy and cross-network transferability, offering new insights for network analysis and engineering applications-particularly in scenarios where the target network's structure is inaccessible in advance due to privacy or security constraints.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jiahui Gao, Kuang Zhou, Yuchen Zhu, Keyu Wu",
      "tags": [
        "cs.SI",
        "cs.AI"
      ]
    },
    {
      "title": "Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image",
      "url": "https://arxiv.org/abs/2511.01767",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.01767v2 Announce Type: replace-cross \nAbstract: In this work, we introduce \\textbf{Wonder3D++}, a novel method for efficiently generating high-fidelity textured meshes from single-view images. Recent methods based on Score Distillation Sampling (SDS) have shown the potential to recover 3D geometry from 2D diffusion priors, but they typically suffer from time-consuming per-shape optimization and inconsistent geometry. In contrast, certain works directly produce 3D information via fast network inferences, but their results are often of low quality and lack geometric details. To holistically improve the quality, consistency, and efficiency of single-view reconstruction tasks, we propose a cross-domain diffusion model that generates multi-view normal maps and the corresponding color images. To ensure the consistency of generation, we employ a multi-view cross-domain attention mechanism that facilitates information exchange across views and modalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that drives high-quality surfaces from the multi-view 2D representations in only about $3$ minute in a coarse-to-fine manner. Our extensive evaluations demonstrate that our method achieves high-quality reconstruction results, robust generalization, and good efficiency compared to prior works. Code available at https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yuxiao Yang, Xiao-Xiao Long, Zhiyang Dou, Cheng Lin, Yuan Liu, Qingsong Yan, Yuexin Ma, Haoqian Wang, Zhiqiang Wu, Wei Yin",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Step-Audio-EditX Technical Report",
      "url": "https://arxiv.org/abs/2511.03601",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.03601v2 Announce Type: replace-cross \nAbstract: We present Step-Audio-EditX, the first open-source LLM-based audio model excelling at expressive and iterative audio editing encompassing emotion, speaking style, and paralinguistics alongside robust zero-shot text-to-speech (TTS) capabilities. Our core innovation lies in leveraging only large-margin synthetic data, which circumvents the need for embedding-based priors or auxiliary modules. This large-margin learning approach enables both iterative control and high expressivity across voices, and represents a fundamental pivot from the conventional focus on representation-level disentanglement. Evaluation results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Chao Yan (Tony), Boyong Wu (Tony), Peng Yang (Tony), Pengfei Tan (Tony), Guoqiang Hu (Tony), Li Xie (Tony), Yuxin Zhang (Tony),  Xiangyu (Tony),  Zhang, Fei Tian, Xuerui Yang, Xiangyu Zhang, Daxin Jiang, Shuchang Zhou, Gang Yu",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models",
      "url": "https://arxiv.org/abs/2511.05171",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.05171v2 Announce Type: replace-cross \nAbstract: Foundation models capable of generalizing across species and tasks represent a promising new frontier in bioacoustics, with NatureLM being one of the most prominent examples. While its domain-specific fine-tuning yields strong performance on bioacoustic benchmarks, we observe that it also introduces trade-offs in instruction-following flexibility. For instance, NatureLM achieves high accuracy when prompted for either the common or scientific name individually, but its accuracy drops significantly when both are requested in a single prompt. We address this by applying a simple model merging strategy that interpolates NatureLM with its base language model, recovering instruction-following capabilities with minimal loss of domain expertise. Finally, we show that the merged model exhibits markedly stronger zero-shot generalization, achieving over a 200% relative improvement and setting a new state-of-the-art in closed-set zero-shot classification of unseen species.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Davide Marincione, Donato Crisostomi, Roberto Dessi, Emanuele Rodol\\`a, Emanuele Rossi",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.SD"
      ]
    },
    {
      "title": "Models Got Talent: Identifying High Performing Wearable Human Activity Recognition Models Without Training",
      "url": "https://arxiv.org/abs/2511.06157",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.06157v2 Announce Type: replace-cross \nAbstract: A promising alternative to the computationally expensive Neural Architecture Search (NAS) involves the development of Zero Cost Proxies (ZCPs), which correlate well with trained performance, but can be computed through a single forward/backward pass on a randomly sampled batch of data. In this paper, we investigate the effectiveness of ZCPs for HAR on six benchmark datasets, and demonstrate that they discover network architectures that obtain within 5% of performance attained by full-scale training involving 1500 randomly sampled architectures. This results in substantial computational savings as high-performing architectures can be discovered with minimal training. Our experiments not only introduce ZCPs to sensor-based HAR, but also demonstrate that they are robust to data noise, further showcasing their suitability for practical scenarios.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Richard Goldman, Varun Komperla, Thomas Ploetz, Harish Haresamudram",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "S-DAG: A Subject-Based Directed Acyclic Graph for Multi-Agent Heterogeneous Reasoning",
      "url": "https://arxiv.org/abs/2511.06727",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.06727v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) have achieved impressive performance in complex reasoning problems. Their effectiveness highly depends on the specific nature of the task, especially the required domain knowledge. Existing approaches, such as mixture-of-experts, typically operate at the task level; they are too coarse to effectively solve the heterogeneous problems involving multiple subjects. This work proposes a novel framework that performs fine-grained analysis at subject level equipped with a designated multi-agent collaboration strategy for addressing heterogeneous problem reasoning. Specifically, given an input query, we first employ a Graph Neural Network to identify the relevant subjects and infer their interdependencies to generate an \\textit{Subject-based Directed Acyclic Graph} (S-DAG), where nodes represent subjects and edges encode information flow. Then we profile the LLM models by assigning each model a subject-specific expertise score, and select the top-performing one for matching corresponding subject of the S-DAG. Such subject-model matching enables graph-structured multi-agent collaboration where information flows from the starting model to the ending model over S-DAG. We curate and release multi-subject subsets of standard benchmarks (MMLU-Pro, GPQA, MedMCQA) to better reflect complex, real-world reasoning tasks. Extensive experiments show that our approach significantly outperforms existing task-level model selection and multi-agent collaboration baselines in accuracy and efficiency. These results highlight the effectiveness of subject-aware reasoning and structured collaboration in addressing complex and multi-subject problems.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jiangwen Dong, Zehui Lin, Wanyu Lin, Mingjin Zhang",
      "tags": [
        "cs.MA",
        "cs.AI"
      ]
    },
    {
      "title": "Cortex AISQL: A Production SQL Engine for Unstructured Data",
      "url": "https://arxiv.org/abs/2511.07663",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.07663v2 Announce Type: replace-cross \nAbstract: Snowflake's Cortex AISQL is a production SQL engine that integrates native semantic operations directly into SQL. This integration allows users to write declarative queries that combine relational operations with semantic reasoning, enabling them to query both structured and unstructured data effortlessly. However, making semantic operations efficient at production scale poses fundamental challenges. Semantic operations are more expensive than traditional SQL operations, possess distinct latency and throughput characteristics, and their cost and selectivity are unknown during query compilation. Furthermore, existing query engines are not designed to optimize semantic operations. The AISQL query execution engine addresses these challenges through three novel techniques informed by production deployment data from Snowflake customers. First, AI-aware query optimization treats AI inference cost as a first-class optimization objective, reasoning about large language model (LLM) cost directly during query planning to achieve 2-8$\\times$ speedups. Second, adaptive model cascades reduce inference costs by routing most rows through a fast proxy model while escalating uncertain cases to a powerful oracle model, achieving 2-6$\\times$ speedups while maintaining 90-95% of oracle model quality. Third, semantic join query rewriting lowers the quadratic time complexity of join operations to linear through reformulation as multi-label classification tasks, achieving 15-70$\\times$ speedups with often improved prediction quality. AISQL is deployed in production at Snowflake, where it powers diverse customer workloads across analytics, search, and content understanding.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Pawe{\\l} Liskowski, Benjamin Han, Paritosh Aggarwal, Bowei Chen, Boxin Jiang, Nitish Jindal, Zihan Li, Aaron Lin, Kyle Schmaus, Jay Tayade, Weicheng Zhao, Anupam Datta, Nathan Wiegand, Dimitris Tsirogiannis",
      "tags": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space",
      "url": "https://arxiv.org/abs/2511.10555",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.10555v4 Announce Type: replace-cross \nAbstract: Innovative visual stylization is a cornerstone of artistic creation, yet generating novel and consistent visual styles remains a significant challenge. Existing generative approaches typically rely on lengthy textual prompts, reference images, or parameter-efficient fine-tuning to guide style-aware image generation, but often struggle with style consistency, limited creativity, and complex style representations. In this paper, we affirm that a style is worth one numerical code by introducing the novel task, code-to-style image generation, which produces images with novel, consistent visual styles conditioned solely on a numerical style code. To date, this field has only been primarily explored by the industry (e.g., Midjourney), with no open-source research from the academic community. To fill this gap, we propose CoTyle, the first open-source method for this task. Specifically, we first train a discrete style codebook from a collection of images to extract style embeddings. These embeddings serve as conditions for a text-to-image diffusion model (T2I-DM) to generate stylistic images. Subsequently, we train an autoregressive style generator on the discrete style embeddings to model their distribution, allowing the synthesis of novel style embeddings. During inference, a numerical style code is mapped to a unique style embedding by the style generator, and this embedding guides the T2I-DM to generate images in the corresponding style. Unlike existing methods, our method offers unparalleled simplicity and diversity, unlocking a vast space of reproducible styles from minimal input. Extensive experiments validate that CoTyle effectively turns a numerical code into a style controller, demonstrating a style is worth one code.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Huijie Liu, Shuhao Cui, Haoxiang Cao, Shuai Ma, Kai Wu, Guoliang Kang",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Understanding the Nature of Depth-1 Equivariant Quantum Circuit",
      "url": "https://arxiv.org/abs/2511.10756",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.10756v2 Announce Type: replace-cross \nAbstract: The Equivariant Quantum Circuit (EQC) for the Travelling Salesman Problem (TSP) has been shown to achieve near-optimal performance in solving small TSP problems (up to 20 nodes) using only two parameters at depth 1. However, extending EQCs to larger TSP problem sizes remains challenging due to the exponential time and memory for quantum circuit simulation, as well as increasing noise and decoherence when running on actual quantum hardware. In this work, we propose the Size-Invariant Grid Search (SIGS), an efficient training optimization for Quantum Reinforcement Learning (QRL), and use it to simulate the outputs of a trained Depth-1 EQC up to 350-node TSP instances - well beyond previously tractable limits. At TSP with 100 nodes, we reduce total simulation times by 96.4%, when comparing to RL simulations with the analytical expression (151 minutes using RL to under 6 minutes using SIGS on TSP-100), while achieving a mean optimality gap within 0.005 of the RL trained model on the test set. SIGS provides a practical benchmarking tool for the QRL community, allowing us to efficiently analyze the performance of QRL algorithms on larger problem sizes. We provide a theoretical explanation for SIGS called the Size-Invariant Properties that goes beyond the concept of equivariance discussed in prior literature.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Jonathan Teo (Singapore Management University), Lee Xin Wei (Singapore Management University), Hoong Chuin Lau (Singapore Management University)",
      "tags": [
        "quant-ph",
        "cs.AI"
      ]
    },
    {
      "title": "DINOv3 as a Frozen Encoder for CRPS-Oriented Probabilistic Rainfall Nowcasting",
      "url": "https://arxiv.org/abs/2511.10894",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.10894v2 Announce Type: replace-cross \nAbstract: This paper proposes a competitive and computationally efficient approach to probabilistic rainfall nowcasting. A video projector (V-JEPA Vision Transformer) associated to a lightweight probabilistic head is attached to a pre-trained satellite vision encoder (DINOv3-SAT493M) to map encoder tokens into a discrete empirical CDF (eCDF) over 4-hour accumulated rainfall. The projector-head is optimized end-to-end over the Ranked Probability Score (RPS). As an alternative, 3D-UNET baselines trained with an aggregate Rank Probability Score and a per-pixel Gamma-Hurdle objective are used. On the Weather4Cast 2025 benchmark, the proposed method achieved a promising performance, with a CRPS of 3.5102, which represents $\\approx$ 26% in effectiveness gain against the best 3D-UNET.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Luciano Araujo Dourado Filho, Almir Moreira da Silva Neto, Anthony Miyaguchi, Rodrigo Pereira David, Rodrigo Tripodi Calumby, Luk\\'a\\v{s} Picek",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Expert-Guided Prompting and Retrieval-Augmented Generation for Emergency Medical Service Question Answering",
      "url": "https://arxiv.org/abs/2511.10900",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.10900v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) have shown promise in medical question answering, yet they often overlook the domain-specific expertise that professionals depend on, such as the clinical subject areas (e.g., trauma, airway) and the certification level (e.g., EMT, Paramedic). Existing approaches typically apply general-purpose prompting or retrieval strategies without leveraging this structured context, limiting performance in high-stakes settings. We address this gap with EMSQA, an 24.3K-question multiple-choice dataset spanning 10 clinical subject areas and 4 certification levels, accompanied by curated, subject area-aligned knowledge bases (40K documents and 2M tokens). Building on EMSQA, we introduce (i) Expert-CoT, a prompting strategy that conditions chain-of-thought (CoT) reasoning on specific clinical subject area and certification level, and (ii) ExpertRAG, a retrieval-augmented generation pipeline that grounds responses in subject area-aligned documents and real-world patient data. Experiments on 4 LLMs show that Expert-CoT improves up to 2.05% over vanilla CoT prompting. Additionally, combining Expert-CoT with ExpertRAG yields up to a 4.59% accuracy gain over standard RAG baselines. Notably, the 32B expertise-augmented LLMs pass all the computer-adaptive EMS certification simulation exams.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xueren Ge, Sahil Murtaza, Anthony Cortez, Homa Alemzadeh",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "MedBuild AI: An Agent-Based Hybrid Intelligence Framework for Reshaping Agency in Healthcare Infrastructure Planning through Generative Design for Medical Architecture",
      "url": "https://arxiv.org/abs/2511.11587",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.11587v3 Announce Type: replace-cross \nAbstract: Globally, disparities in healthcare infrastructure remain stark, leaving countless communities without access to even basic services. Traditional infrastructure planning is often slow and inaccessible, and although many architects are actively delivering humanitarian and aid-driven hospital projects worldwide, these vital efforts still fall far short of the sheer scale and urgency of demand. This paper introduces MedBuild AI, a hybrid-intelligence framework that integrates large language models (LLMs) with deterministic expert systems to rebalance the early design and conceptual planning stages. As a web-based platform, it enables any region with satellite internet access to obtain guidance on modular, low-tech, low-cost medical building designs. The system operates through three agents: the first gathers local health intelligence via conversational interaction; the second translates this input into an architectural functional program through rule-based computation; and the third generates layouts and 3D models. By embedding computational negotiation into the design process, MedBuild AI fosters a reciprocal, inclusive, and equitable approach to healthcare planning, empowering communities and redefining agency in global healthcare architecture.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Yiming Zhang, Yuejia Xu, Ziyao Wang, Xin Yan, Xiaosai Hao",
      "tags": [
        "cs.HC",
        "cs.AI",
        "cs.CE",
        "cs.GR",
        "cs.MA"
      ]
    },
    {
      "title": "Uncertainty Makes It Stable: Curiosity-Driven Quantized Mixture-of-Experts",
      "url": "https://arxiv.org/abs/2511.11743",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.11743v2 Announce Type: replace-cross \nAbstract: Deploying deep neural networks on resource-constrained devices faces two critical challenges: maintaining accuracy under aggressive quantization while ensuring predictable inference latency. We present a curiosity-driven quantized Mixture-of-Experts framework that addresses both through Bayesian epistemic uncertainty-based routing across heterogeneous experts (BitNet ternary, 1-16 bit BitLinear, post-training quantization). Evaluated on audio classification benchmarks (ESC-50, Quinn, UrbanSound8K), our 4-bit quantization maintains 99.9 percent of 16-bit accuracy (0.858 vs 0.859 F1) with 4x compression and 41 percent energy savings versus 8-bit. Crucially, curiosity-driven routing reduces MoE latency variance by 82 percent (p = 0.008, Levene's test) from 230 ms to 29 ms standard deviation, enabling stable inference for battery-constrained devices. Statistical analysis confirms 4-bit/8-bit achieve practical equivalence with full precision (p > 0.05), while MoE architectures introduce 11 percent latency overhead (p < 0.001) without accuracy gains. At scale, deployment emissions dominate training by 10000x for models serving more than 1,000 inferences, making inference efficiency critical. Our information-theoretic routing demonstrates that adaptive quantization yields accurate (0.858 F1, 1.2M params), energy-efficient (3.87 F1/mJ), and predictable edge models, with simple 4-bit quantized architectures outperforming complex MoE for most deployments.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Sebasti\\'an Andr\\'es Cajas Ord\\'o\\~nez, Luis Fernando Torres Torres, Mackenzie J. Meni, Carlos Andr\\'es Duran Paredes, Eric Arazo, Cristian Bosch, Ricardo Simon Carbajo, Yuan Lai, Leo Anthony Celi",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Better LLM Reasoning via Dual-Play",
      "url": "https://arxiv.org/abs/2511.11881",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.11881v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) have achieved remarkable progress through Reinforcement Learning with Verifiable Rewards (RLVR), yet still rely heavily on external supervision (e.g., curated labels). Adversarial learning, particularly through self-play, offers a promising alternative that enables models to iteratively learn from themselves - thus reducing reliance on external supervision. Dual-play extends adversarial learning by assigning specialized roles to two models and training them against each other, fostering sustained competition and mutual evolution. Despite its promise, adapting dual-play training to LLMs remains limited, largely due to their susceptibility to reward hacking and training instability. In this paper, we introduce PasoDoble, a novel LLM dual-play framework. PasoDoble adversarially trains two models initialized from the same base model: a Proposer, which generates challenging questions with ground-truth answers, and a Solver, which attempts to solve them. We enrich the Proposer with knowledge from a pre-training dataset to ensure the questions' quality and diversity. To avoid reward hacking, the Proposer is rewarded for producing only valid questions that push the Solver's limit, while the Solver is rewarded for solving them correctly, and both are updated jointly. To further enhance training stability, we introduce an optional offline paradigm that decouples Proposer and Solver updates, alternately updating each for several steps while holding the other fixed. Notably, PasoDoble operates without supervision during training. Experimental results show that PasoDoble can improve the reasoning performance of LLMs. Our project page is available at https://hcy123902.github.io/PasoDoble.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Zhengxin Zhang, Chengyu Huang, Aochong Oliver Li, Claire Cardie",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MF-Speech: Achieving Fine-Grained and Compositional Control in Speech Generation via Factor Disentanglement",
      "url": "https://arxiv.org/abs/2511.12074",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.12074v2 Announce Type: replace-cross \nAbstract: Generating expressive and controllable human speech is one of the core goals of generative artificial intelligence, but its progress has long been constrained by two fundamental challenges: the deep entanglement of speech factors and the coarse granularity of existing control mechanisms. To overcome these challenges, we have proposed a novel framework called MF-Speech, which consists of two core components: MF-SpeechEncoder and MF-SpeechGenerator. MF-SpeechEncoder acts as a factor purifier, adopting a multi-objective optimization strategy to decompose the original speech signal into highly pure and independent representations of content, timbre, and emotion. Subsequently, MF-SpeechGenerator functions as a conductor, achieving precise, composable and fine-grained control over these factors through dynamic fusion and Hierarchical Style Adaptive Normalization (HSAN). Experiments demonstrate that in the highly challenging multi-factor compositional speech generation task, MF-Speech significantly outperforms current state-of-the-art methods, achieving a lower word error rate (WER=4.67%), superior style control (SECS=0.5685, Corr=0.68), and the highest subjective evaluation scores(nMOS=3.96, sMOS_emotion=3.86, sMOS_style=3.78). Furthermore, the learned discrete factors exhibit strong transferability, demonstrating their significant potential as a general-purpose speech representation.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xinyue Yu, Youqing Fang, Pingyu Wu, Guoyang Ye, Wenbo Zhou, Weiming Zhang, Song Xiao",
      "tags": [
        "cs.SD",
        "cs.AI"
      ]
    },
    {
      "title": "Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos",
      "url": "https://arxiv.org/abs/2511.12882",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.12882v2 Announce Type: replace-cross \nAbstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Taiyi Su, Jian Zhu, Yaxuan Li, Chong Ma, Zitai Huang, Hanli Wang, Yi Xu",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "NuBench: An Open Benchmark for Deep Learning-Based Event Reconstruction in Neutrino Telescopes",
      "url": "https://arxiv.org/abs/2511.13111",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.13111v2 Announce Type: replace-cross \nAbstract: Neutrino telescopes are large-scale detectors designed to observe Cherenkov radiation produced from neutrino interactions in water or ice. They exist to identify extraterrestrial neutrino sources and to probe fundamental questions pertaining to the elusive neutrino itself. A central challenge common across neutrino telescopes is to solve a series of inverse problems known as event reconstruction, which seeks to resolve properties of the incident neutrino, based on the detected Cherenkov light. In recent times, significant efforts have been made in adapting advances from deep learning research to event reconstruction, as such techniques provide several benefits over traditional methods. While a large degree of similarity in reconstruction needs and low-level data exists, cross-experimental collaboration has been hindered by a lack of diverse open-source datasets for comparing methods.\n  We present NuBench, an open benchmark for deep learning-based event reconstruction in neutrino telescopes. NuBench comprises seven large-scale simulated datasets containing nearly 130 million charged- and neutral-current muon-neutrino interactions spanning 10 GeV to 100 TeV, generated across six detector geometries inspired by existing and proposed experiments. These datasets provide pulse- and event-level information suitable for developing and comparing machine-learning reconstruction methods in both water and ice environments. Using NuBench, we evaluate four reconstruction algorithms - ParticleNeT and DynEdge, both actively used within the KM3NeT and IceCube collaborations, respectively, along with GRIT and DeepIce - on up to five core tasks: energy and direction reconstruction, topology classification, interaction vertex prediction, and inelasticity estimation.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Rasmus F. Orsoe, Stephan Meighen-Berger, Jeffrey Lazar, Jorge Prado, Ivan Mozun-Mateo, Aske Rosted, Philip Weigel, Arturo Llorente Anaya",
      "tags": [
        "hep-ex",
        "cs.AI",
        "cs.LG",
        "physics.data-an",
        "physics.ins-det"
      ]
    },
    {
      "title": "Making Evidence Actionable in Adaptive Learning Closing the Diagnostic Pedagogical Loop",
      "url": "https://arxiv.org/abs/2511.13542",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.13542v2 Announce Type: replace-cross \nAbstract: Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows derived from ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy with diversity. Greedy selection serves low-richness and tight-latency settings, gradient-based relaxation serves rich repositories, and a hybrid switches along a richness-latency frontier. In simulation and in an introductory physics deployment with 1204 students, both solvers achieved full skill coverage for nearly all learners within bounded watch time. The gradient-based method reduced redundant coverage by about 12 percentage points relative to greedy and produced more consistent difficulty alignment, while greedy delivered comparable adequacy at lower computational cost in resource-scarce environments. Slack variables localized missing content and guided targeted curation, sustaining sufficiency across student subgroups. The result is a tractable and auditable controller that closes the diagnostic pedagogical loop and enables equitable, load-aware personalization at the classroom scale.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Amirreza Mehrabi, Jason Wade Morphew, Breejha Quezada, N. Sanjay Rebello",
      "tags": [
        "cs.CE",
        "cs.AI",
        "cs.CY",
        "stat.AP"
      ]
    },
    {
      "title": "Alpha Divergence Losses for Biometric Verification",
      "url": "https://arxiv.org/abs/2511.13621",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.13621v2 Announce Type: replace-cross \nAbstract: Performance in face and speaker verification is largely driven by margin based softmax losses like CosFace and ArcFace. Recently introduced $\\alpha$-divergence loss functions offer a compelling alternative, particularly for their ability to induce sparse solutions (when $\\alpha>1$). However, integrating an angular margin-crucial for verification tasks-is not straightforward. We find this integration can be achieved in at least two distinct ways: via the reference measure (prior probabilities) or via the logits (unnormalized log-likelihoods). In this paper, we explore both pathways, deriving two novel margin-based $\\alpha$-divergence losses: Q-Margin (margin in the reference measure) and A3M (margin in the logits). We identify and address a critical training instability in A3M-caused by the interplay of penalized logits and sparsity-with a simple yet effective prototype re-initialization strategy. Our methods achieve significant performance gains on the challenging IJB-B and IJB-C face verification benchmarks. We demonstrate similarly strong performance in speaker verification on VoxCeleb. Crucially, our models significantly outperform strong baselines at low false acceptance rates (FAR). This capability is crucial for practical high-security applications, such as banking authentication, when minimizing false authentications is paramount.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Dimitrios Koutsianos, Ladislav Mosner, Yannis Panagakis, Themos Stafylakis",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "H-CNN-ViT: A Hierarchical Gated Attention Multi-Branch Model for Bladder Cancer Recurrence Prediction",
      "url": "https://arxiv.org/abs/2511.13869",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.13869v2 Announce Type: replace-cross \nAbstract: Bladder cancer is one of the most prevalent malignancies worldwide, with a recurrence rate of up to 78%, necessitating accurate post-operative monitoring for effective patient management. Multi-sequence contrast-enhanced MRI is commonly used for recurrence detection; however, interpreting these scans remains challenging, even for experienced radiologists, due to post-surgical alterations such as scarring, swelling, and tissue remodeling. AI-assisted diagnostic tools have shown promise in improving bladder cancer recurrence prediction, yet progress in this field is hindered by the lack of dedicated multi-sequence MRI datasets for recurrence assessment study. In this work, we first introduce a curated multi-sequence, multi-modal MRI dataset specifically designed for bladder cancer recurrence prediction, establishing a valuable benchmark for future research. We then propose H-CNN-ViT, a new Hierarchical Gated Attention Multi-Branch model that enables selective weighting of features from the global (ViT) and local (CNN) paths based on contextual demands, achieving a balanced and targeted feature fusion. Our multi-branch architecture processes each modality independently, ensuring that the unique properties of each imaging channel are optimally captured and integrated. Evaluated on our dataset, H-CNN-ViT achieves an AUC of 78.6%, surpassing state-of-the-art models. Our model is publicly available at https://github.com/XLIAaron/H-CNN-ViT.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xueyang Li, Zongren Wang, Yuliang Zhang, Zixuan Pan, Yu-Jen Chen, Nishchal Sapkota, Gelei Xu, Danny Z. Chen, Yiyu Shi",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports",
      "url": "https://arxiv.org/abs/2511.14010",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14010v2 Announce Type: replace-cross \nAbstract: Post-disaster reconnaissance reports contain critical evidence for understanding multi-hazard interactions, yet their unstructured narratives make systematic knowledge transfer difficult. Large language models (LLMs) offer new potential for analyzing these reports, but often generate unreliable or hallucinated outputs when domain grounding is absent. This study introduces the Mixture-of-Retrieval Agentic RAG (MoRA-RAG), a knowledge-grounded LLM framework that transforms reconnaissance reports into a structured foundation for multi-hazard reasoning. The framework integrates a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while using agentic chunking to preserve contextual coherence during retrieval. It also includes a verification loop that assesses evidence sufficiency, refines queries, and initiates targeted searches when information remains incomplete. We construct HazardRecQA by deriving question-answer pairs from GEER reconnaissance reports, which document 90 global events across seven major hazard types. MoRA-RAG achieves up to 94.5 percent accuracy, outperforming zero-shot LLMs by 30 percent and state-of-the-art RAG systems by 10 percent, while reducing hallucinations across diverse LLM architectures. MoRA-RAG also enables open-weight LLMs to achieve performance comparable to proprietary models. It establishes a new paradigm for transforming post-disaster documentation into actionable, trustworthy intelligence for hazard resilience.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Chenchen Kuai, Zihao Li, Braden Rosen, Stephanie Paal, Navid Jafari, Jean-Louis Briaud, Yunlong Zhang, Youssef M. A. Hashash, Yang Zhou",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Cheating Stereo Matching in Full-scale: Physical Adversarial Attack against Binocular Depth Estimation in Autonomous Driving",
      "url": "https://arxiv.org/abs/2511.14386",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14386v2 Announce Type: replace-cross \nAbstract: Though deep neural models adopted to realize the perception of autonomous driving have proven vulnerable to adversarial examples, known attacks often leverage 2D patches and target mostly monocular perception. Therefore, the effectiveness of Physical Adversarial Examples (PAEs) on stereo-based binocular depth estimation remains largely unexplored. To this end, we propose the first texture-enabled physical adversarial attack against stereo matching models in the context of autonomous driving. Our method employs a 3D PAE with global camouflage texture rather than a local 2D patch-based one, ensuring both visual consistency and attack effectiveness across different viewpoints of stereo cameras. To cope with the disparity effect of these cameras, we also propose a new 3D stereo matching rendering module that allows the PAE to be aligned with real-world positions and headings in binocular vision. We further propose a novel merging attack that seamlessly blends the target into the environment through fine-grained PAE optimization. It has significantly enhanced stealth and lethality upon existing hiding attacks that fail to get seamlessly merged into the background. Extensive evaluations show that our PAEs can successfully fool the stereo models into producing erroneous depth information.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Kangqiao Zhao, Shuo Huai, Xurui Song, Jun Luo",
      "tags": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Agentic AI Systems in Electrical Power Systems Engineering: Current State-of-the-Art and Challenges",
      "url": "https://arxiv.org/abs/2511.14478",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14478v2 Announce Type: replace-cross \nAbstract: Agentic AI systems have recently emerged as a critical and transformative approach in artificial intelligence, offering capabilities that extend far beyond traditional AI agents and contemporary generative AI models. This rapid evolution necessitates a clear conceptual and taxonomical understanding to differentiate this new paradigm. Our paper addresses this gap by providing a comprehensive review that establishes a precise definition and taxonomy for \"agentic AI,\" with the aim of distinguishing it from previous AI paradigms. The concepts are gradually introduced, starting with a highlight of its diverse applications across the broader field of engineering. The paper then presents four detailed, state-of-the-art use case applications specifically within electrical engineering. These case studies demonstrate practical impact, ranging from an advanced agentic framework for streamlining complex power system studies and benchmarking to a novel system developed for survival analysis of dynamic pricing strategies in battery swapping stations. Finally, to ensure robust deployment, the paper provides detailed failure mode investigations. From these findings, we derive actionable recommendations for the design and implementation of safe, reliable, and accountable agentic AI systems, offering a critical resource for researchers and practitioners.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Soham Ghosh, Gaurav Mittal",
      "tags": [
        "eess.SY",
        "cs.AI",
        "cs.ET",
        "cs.SY"
      ]
    },
    {
      "title": "SweeperBot: Making 3D Browsing Accessible through View Analysis and Visual Question Answering",
      "url": "https://arxiv.org/abs/2511.14567",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14567v2 Announce Type: replace-cross \nAbstract: Accessing 3D models remains challenging for Screen Reader (SR) users. While some existing 3D viewers allow creators to provide alternative text, they often lack sufficient detail about the 3D models. Grounded on a formative study, this paper introduces SweeperBot, a system that enables SR users to leverage visual question answering to explore and compare 3D models. SweeperBot answers SR users' visual questions by combining an optimal view selection technique with the strength of generative- and recognition-based foundation models. An expert review with 10 Blind and Low-Vision (BLV) users with SR experience demonstrated the feasibility of using SweeperBot to assist BLV users in exploring and comparing 3D models. The quality of the descriptions generated by SweeperBot was validated by a second survey study with 30 sighted participants.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Chen Chen, Cuong Nguyen, Alexa Siu, Dingzeyu Li, Nadir Weibel",
      "tags": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks",
      "url": "https://arxiv.org/abs/2511.14592",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14592v2 Announce Type: replace-cross \nAbstract: Vision-Language Models (VLMs) show great promise for autonomous driving, but their suitability for safety-critical scenarios is largely unexplored, raising safety concerns. This issue arises from the lack of comprehensive benchmarks that assess both external environmental risks and in-cabin driving behavior safety simultaneously. To bridge this critical gap, we introduce DSBench, the first comprehensive Driving Safety Benchmark designed to assess a VLM's awareness of various safety risks in a unified manner. DSBench encompasses two major categories: external environmental risks and in-cabin driving behavior safety, divided into 10 key categories and a total of 28 sub-categories. This comprehensive evaluation covers a wide range of scenarios, ensuring a thorough assessment of VLMs' performance in safety-critical contexts. Extensive evaluations across various mainstream open-source and closed-source VLMs reveal significant performance degradation under complex safety-critical situations, highlighting urgent safety concerns. To address this, we constructed a large dataset of 98K instances focused on in-cabin and external safety scenarios, showing that fine-tuning on this dataset significantly enhances the safety performance of existing VLMs and paves the way for advancing autonomous driving technology. The benchmark toolkit, code, and model checkpoints will be publicly accessible.",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Xianhui Meng, Yuchen Zhang, Zhijian Huang, Zheng Lu, Ziling Ji, Yaoyao Yin, Hongyuan Zhang, Guangfeng Jiang, Yandan Lin, Long Chen, Hangjun Ye, Li Zhang, Jun Liu, Xiaoshuai Hao",
      "tags": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "FLARE: Adaptive Multi-Dimensional Reputation for Robust Client Reliability in Federated Learning",
      "url": "https://arxiv.org/abs/2511.14715",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14715v2 Announce Type: replace-cross \nAbstract: Federated learning (FL) enables collaborative model training while preserving data privacy. However, it remains vulnerable to malicious clients who compromise model integrity through Byzantine attacks, data poisoning, or adaptive adversarial behaviors. Existing defense mechanisms rely on static thresholds and binary classification, failing to adapt to evolving client behaviors in real-world deployments. We propose FLARE, an adaptive reputation-based framework that transforms client reliability assessment from binary decisions to a continuous, multi-dimensional trust evaluation. FLARE integrates: (i) a multi-dimensional reputation score capturing performance consistency, statistical anomaly indicators, and temporal behavior, (ii) a self-calibrating adaptive threshold mechanism that adjusts security strictness based on model convergence and recent attack intensity, (iii) reputation-weighted aggregation with soft exclusion to proportionally limit suspicious contributions rather than eliminating clients outright, and (iv) a Local Differential Privacy (LDP) mechanism enabling reputation scoring on privatized client updates. We further introduce a highly evasive Statistical Mimicry (SM) attack, a benchmark adversary that blends honest gradients with synthetic perturbations and persistent drift to remain undetected by traditional filters. Extensive experiments with 100 clients on MNIST, CIFAR-10, and SVHN demonstrate that FLARE maintains high model accuracy and converges faster than state-of-the-art Byzantine-robust methods under diverse attack types, including label flipping, gradient scaling, adaptive attacks, ALIE, and SM. FLARE improves robustness by up to 16% and preserves model convergence within 30% of the non-attacked baseline, while achieving strong malicious-client detection performance with minimal computational overhead. https://github.com/Anonymous0-0paper/FLARE",
      "source": "cs.AI updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.AI",
      "author": "Abolfazl Younesi, Leon Kiss, Zahra Najafabadi Samani, Juan Aznar Poveda, Thomas Fahringer",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "cs.MA"
      ]
    },
    {
      "title": "What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning",
      "url": "https://arxiv.org/abs/2511.15886",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15886v1 Announce Type: new \nAbstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Jeremias Ferrao, Ezgi Basar, Khondoker Ittehadul Islam, Mahrokh Hassani",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language",
      "url": "https://arxiv.org/abs/2511.15887",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15887v1 Announce Type: new \nAbstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Seungbeen Lee, Jinhong Jeong, Donghyun Kim, Yejin Son, Youngjae Yu",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues",
      "url": "https://arxiv.org/abs/2511.15976",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15976v1 Announce Type: new \nAbstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Sarik Ghazarian, Abhinav Gullapalli, Swair Shah, Anurag Beniwal, Nanyun Peng, Narayanan Sadagopan, Zhou Yu",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Liars' Bench: Evaluating Lie Detectors for Language Models",
      "url": "https://arxiv.org/abs/2511.16035",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16035v1 Announce Type: new \nAbstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Kieron Kretschmar (Cadenza Labs), Walter Laurito (Cadenza Labs, FZI), Sharan Maiya (Cadenza Labs, University of Cambridge), Samuel Marks (Anthropic)",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Tractable Distributions Of Language Model Continuations",
      "url": "https://arxiv.org/abs/2511.16054",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16054v1 Announce Type: new \nAbstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Gwen Yidou-Weng, Ian Li, Anji Liu, Oliver Broadrick, Guy Van den Broeck, Benjie Wang",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Early science acceleration experiments with GPT-5",
      "url": "https://arxiv.org/abs/2511.16072",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16072v1 Announce Type: new \nAbstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "S\\'ebastien Bubeck, Christian Coester, Ronen Eldan, Timothy Gowers, Yin Tat Lee, Alexandru Lupsasca, Mehtaab Sawhney, Robert Scherrer, Mark Sellke, Brian K. Spears, Derya Unutmaz, Kevin Weil, Steven Yin, Nikita Zhivotovskiy",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models",
      "url": "https://arxiv.org/abs/2511.16122",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16122v1 Announce Type: new \nAbstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Qing Zhang, Bing Xu, Xudong Zhang, Yifan Shi, Yang Li, Chen Zhang, Yik Chung Wu, Ngai Wong, Yijie Chen, Hong Dai, Xiansen Chen, Mian Zhang",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating",
      "url": "https://arxiv.org/abs/2511.16147",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16147v1 Announce Type: new \nAbstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Dabiao Ma, Ziming Dai, Zhimin Xin, Shu Wang, Ye Wang, Haojun Fei",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning",
      "url": "https://arxiv.org/abs/2511.16198",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16198v1 Announce Type: new \nAbstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Sebastian Haan",
      "tags": [
        "cs.CL",
        "cs.DL"
      ]
    },
    {
      "title": "SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs",
      "url": "https://arxiv.org/abs/2511.16275",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16275v1 Announce Type: new \nAbstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Xingtao Zhao, Hao Peng, Dingli Su, Xianghua Zeng, Chunyang Liu, Jinzhi Liao, Philip S. Yu",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning",
      "url": "https://arxiv.org/abs/2511.16324",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16324v1 Announce Type: new \nAbstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Wei Xia, Zhi-Hong Deng",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement",
      "url": "https://arxiv.org/abs/2511.16331",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16331v1 Announce Type: new \nAbstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only \"simple\" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Jiashu Yao, Heyan Huang, Shuang Zeng, Chuwei Luo, WangJie You, Jie Tang, Qingsong Liu, Yuhang Guo, Yangyang Kang",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "NLP Datasets for Idiom and Figurative Language Tasks",
      "url": "https://arxiv.org/abs/2511.16345",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16345v1 Announce Type: new \nAbstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Blake Matheny, Phuong Minh Nguyen, Minh Le Nguyen, Stephanie Reynolds",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies",
      "url": "https://arxiv.org/abs/2511.16353",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16353v1 Announce Type: new \nAbstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Jonathan Kamp, Lisa Beinborn, Antske Fokkens",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser",
      "url": "https://arxiv.org/abs/2511.16397",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16397v1 Announce Type: new \nAbstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\\% ROUGE-N F1 compared to Trafilatura's 63.6\\%, with exceptional structured element preservation (90.9\\% for code blocks, 94.0\\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Ren Ma, Jiantao Qiu, Chao Xu, Pei Chu, Kaiwen Liu, Pengli Ren, Yuan Qu, Jiahui Peng, Linfeng Hou, Mengjie Liu, Lindong Lu, Wenchang Ning, Jia Yu, Rui Min, Jin Shi, Haojiong Chen, Peng Zhang, Wenjian Zhang, Qian Jiang, Zengjie Hu, Guoqiang Yang, Zhenxiang Li, Fukai Shang, Zhongying Tu, Wentao Zhang, Dahua Lin, Conghui He",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Classification of worldwide news articles by perceived quality, 2018-2024",
      "url": "https://arxiv.org/abs/2511.16416",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16416v1 Announce Type: new \nAbstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Connor McElroy, Thiago E. A. de Oliveira, Chris Brogly",
      "tags": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports",
      "url": "https://arxiv.org/abs/2511.16438",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16438v1 Announce Type: new \nAbstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Sherine George, Nithish Saji",
      "tags": [
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "Anatomy of an Idiom: Tracing Non-Compositionality in Language Models",
      "url": "https://arxiv.org/abs/2511.16467",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16467v1 Announce Type: new \nAbstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Andrew Gomes",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Arctic-Extract Technical Report",
      "url": "https://arxiv.org/abs/2511.16470",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16470v1 Announce Type: new \nAbstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Mateusz Chili\\'nski, Julita O{\\l}tusek, Wojciech Ja\\'skowski",
      "tags": [
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval",
      "url": "https://arxiv.org/abs/2511.16528",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16528v1 Announce Type: new \nAbstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\\% of its average mAP. Late-interaction models that are 3--5$\\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\\times$ faster than PLAID and offers +1.7\\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "\\\"Ozay Ezerceli, Mahmoud El Hussieni, Selva Ta\\c{s}, Reyhan Bayraktar, Fatma Bet\\\"ul Terzio\\u{g}lu, Yusuf \\c{C}elebi, Ya\\u{g}{\\i}z Asker",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks",
      "url": "https://arxiv.org/abs/2511.16540",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16540v1 Announce Type: new \nAbstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "\\'Elo\\\"ise Benito-Rodriguez, Einar Urdshals, Jasmina Nasufi, Nicky Pochinkov",
      "tags": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue",
      "url": "https://arxiv.org/abs/2511.16544",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16544v1 Announce Type: new \nAbstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $\\kappa$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Zachary Ellis, Jared Joselowitz, Yash Deo, Yajie He, Anna Kalygina, Aisling Higham, Mana Rahimzadeh, Yan Jia, Ibrahim Habli, Ernest Lim",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation",
      "url": "https://arxiv.org/abs/2511.16577",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16577v1 Announce Type: new \nAbstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Kexin Zhao, Ken Forbus",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems",
      "url": "https://arxiv.org/abs/2511.16654",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16654v1 Announce Type: new \nAbstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Elias Lumer, Alex Cardenas, Matt Melich, Myles Mason, Sara Dieter, Vamse Kumar Subbiah, Pradeep Honaganahalli Basavaraju, Roberto Hernandez",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs",
      "url": "https://arxiv.org/abs/2511.16664",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16664v1 Announce Type: new \nAbstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Ali Taghibakhshi, Sharath Turuvekere Sreenivas, Saurav Muralidharan, Ruisi Cai, Marcin Chochowski, Ameya Sunil Mahabaleshwarkar, Yoshi Suhara, Oluwatobi Olabiyi, Daniel Korzekwa, Mostofa Patwary, Mohammad Shoeybi, Jan Kautz, Bryan Catanzaro, Ashwath Aithal, Nima Tajbakhsh, Pavlo Molchanov",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Chain of Summaries: Summarization Through Iterative Questioning",
      "url": "https://arxiv.org/abs/2511.15719",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15719v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&amp;A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "William Brach, Lukas Galke Poech",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Step-Audio-R1 Technical Report",
      "url": "https://arxiv.org/abs/2511.15848",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15848v1 Announce Type: cross \nAbstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Fei Tian, Xiangyu Tony Zhang, Yuxin Zhang, Haoyang Zhang, Yuxin Li, Daijiao Liu, Yayue Deng, Donghang Wu, Jun Chen, Liang Zhao, Chengyuan Yao, Hexin Liu, Eng Siong Chng, Xuerui Yang, Xiangyu Zhang, Daxin Jiang, Gang Yu",
      "tags": [
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ]
    },
    {
      "title": "The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems",
      "url": "https://arxiv.org/abs/2511.15862",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15862v1 Announce Type: cross \nAbstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Devang Kulshreshtha, Wanyu Du, Raghav Jain, Srikanth Doss, Hang Su, Sandesh Swamy, Yanjun Qi",
      "tags": [
        "cs.MA",
        "cs.CL"
      ]
    },
    {
      "title": "AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization",
      "url": "https://arxiv.org/abs/2511.15915",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15915v1 Announce Type: cross \nAbstract: We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\\%$ to $61\\%$ on Trainium 1 and from $45\\%$ to $59\\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\\times$ cheaper.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Genghan Zhang, Shaowei Zhu, Anjiang Wei, Zhenyu Song, Allen Nie, Zhen Jia, Nandita Vijaykumar, Yida Wang, Kunle Olukotun",
      "tags": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "title": "JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation",
      "url": "https://arxiv.org/abs/2511.15958",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15958v1 Announce Type: cross \nAbstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Zhenyu Bi, Gaurav Srivastava, Yang Li, Meng Lu, Swastik Roy, Morteza Ziyadi, Xuan Wang",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CARE-RAG - Clinical Assessment and Reasoning in RAG",
      "url": "https://arxiv.org/abs/2511.15994",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15994v1 Announce Type: cross \nAbstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Deepthi Potluri, Aby Mammen Mathew, Jeffrey B DeWitt, Alexander L. Rasgon, Yide Hao, Junyuan Hong, Ying Ding",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation",
      "url": "https://arxiv.org/abs/2511.15996",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15996v1 Announce Type: cross \nAbstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Amin Bigdeli, Radin Hamidi Rad, Mert Incesu, Negar Arabzadeh, Charles L. A. Clarke, Ebrahim Bagheri",
      "tags": [
        "cs.IR",
        "cs.CL"
      ]
    },
    {
      "title": "SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model",
      "url": "https://arxiv.org/abs/2511.16018",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16018v1 Announce Type: cross \nAbstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Emanuel C. Silva, Emily S. M. Salum, Gabriel M. Arantes, Matheus P. Pereira, Vinicius F. Oliveira, Alessandro L. Bicho",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization",
      "url": "https://arxiv.org/abs/2511.16209",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16209v1 Announce Type: cross \nAbstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these hidden instructions, posing significant security and privacy risks. Existing defense mechanisms frequently rely on heuristics, incur substantial computational overhead, or are inapplicable to models accessed via black-box APIs. This paper introduces a novel framework for hardening system prompts through shield appending, a lightweight approach that adds a protective textual layer to the original prompt. Our core contribution is the formalization of prompt hardening as a utility-constrained optimization problem. We leverage an LLM-as-optimizer to search the space of possible SHIELDs, seeking to minimize a leakage metric derived from a suite of adversarial attacks, while simultaneously preserving task utility above a specified threshold, measured by semantic fidelity to baseline outputs. This black-box, optimization-driven methodology is lightweight and practical, requiring only API access to the target and optimizer LLMs. We demonstrate empirically that our optimized SHIELDs significantly reduce prompt leakage against a comprehensive set of extraction attacks, outperforming established baseline defenses without compromising the model's intended functionality. Our work presents a paradigm for developing robust, utility-aware defenses in the escalating landscape of LLM security. The code is made public on the following link: https://github.com/psm-defense/psm",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Huseein Jawad, Nicolas Brunel",
      "tags": [
        "cs.CR",
        "cs.CL"
      ]
    },
    {
      "title": "Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions",
      "url": "https://arxiv.org/abs/2511.16221",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16221v1 Announce Type: cross \nAbstract: Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Caixin Kang, Yifei Huang, Liangyang Ouyang, Mingfang Zhang, Ruicong Liu, Yoichi Sato",
      "tags": [
        "cs.CV",
        "cs.CL"
      ]
    },
    {
      "title": "OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe",
      "url": "https://arxiv.org/abs/2511.16334",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16334v1 Announce Type: cross \nAbstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Kaichen Zhang, Keming Wu, Zuhao Yang, Kairui Hu, Bin Wang, Ziwei Liu, Xingxuan Li, Lidong Bing",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models",
      "url": "https://arxiv.org/abs/2511.16423",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16423v1 Announce Type: cross \nAbstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Li Zhang, Zhongxuan Han, XiaoHua Feng, Jiaming Zhang, Yuyuan Li, Linbo Jiang, Jianan Lin, Chaochao Chen",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation",
      "url": "https://arxiv.org/abs/2511.16478",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16478v1 Announce Type: cross \nAbstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.\n  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Elena V. Epure, Yashar Deldjoo, Bruno Sguerra, Markus Schedl, Manuel Moussallam",
      "tags": [
        "cs.IR",
        "cs.CL"
      ]
    },
    {
      "title": "MiMo-Embodied: X-Embodied Foundation Model Technical Report",
      "url": "https://arxiv.org/abs/2511.16518",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16518v1 Announce Type: cross \nAbstract: We open-source MiMo-Embodied, the first cross-embodied foundation model to successfully integrate and achieve state-of-the-art performance in both Autonomous Driving and Embodied AI. MiMo-Embodied sets new records across 17 embodied AI benchmarks in Task Planning, Affordance Prediction and Spatial Understanding, while also excelling in 12 autonomous driving benchmarks across Environmental Perception, Status Prediction, and Driving Planning. Across these tasks, MiMo-Embodied significantly outperforms existing open-source, closed-source, and specialized baselines. Our results indicate that through multi-stage learning, curated data construction, and CoT/RL fine-tuning, these two domains exhibit strong positive transfer and mutually reinforce one another. We provide a detailed analysis of our model design and training methodologies to facilitate further research. Code and models are available at https://github.com/XiaomiMiMo/MiMo-Embodied.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Xiaoshuai Hao, Lei Zhou, Zhijian Huang, Zhiwen Hou, Yingbo Tang, Lingfeng Zhang, Guang Li, Zheng Lu, Shuhuai Ren, Xianhui Meng, Yuchen Zhang, Jing Wu, Jinghui Lu, Chenxu Dang, Jiayi Guan, Jianhua Wu, Zhiyi Hou, Hanbing Li, Shumeng Xia, Mingliang Zhou, Yinan Zheng, Zihao Yue, Shuhao Gu, Hao Tian, Yuannan Shen, Jianwei Cui, Wen Zhang, Shaoqing Xu, Bing Wang, Haiyang Sun, Zeyu Zhu, Yuncheng Jiang, Zibin Guo, Chuhong Gong, Chaofan Zhang, Wenbo Ding, Kun Ma, Guang Chen, Rui Cai, Diyun Xiang, Heng Qu, Fuli Luo, Hangjun Ye, Long Chen",
      "tags": [
        "cs.RO",
        "cs.CL",
        "cs.CV"
      ]
    },
    {
      "title": "The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation",
      "url": "https://arxiv.org/abs/2511.16543",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16543v1 Announce Type: cross \nAbstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.\n  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.\n  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Jiaheng Zhang, Daqiang Zhang",
      "tags": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies",
      "url": "https://arxiv.org/abs/2511.16590",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16590v1 Announce Type: cross \nAbstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Sen Chen, Tong Zhao, Yi Bin, Fei Ma, Wenqi Shao, Zheng Wang",
      "tags": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding",
      "url": "https://arxiv.org/abs/2511.16595",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16595v1 Announce Type: cross \nAbstract: We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Boshen Xu, Zihan Xiao, Jiaze Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Qin Jin",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction",
      "url": "https://arxiv.org/abs/2511.16635",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16635v1 Announce Type: cross \nAbstract: Survival analysis is critical for cancer prognosis and treatment planning, yet existing methods lack the transparency essential for clinical adoption. While recent pathology agents have demonstrated explainability in diagnostic tasks, they face three limitations for survival prediction: inability to integrate multimodal data, ineffective region-of-interest exploration, and failure to leverage experiential learning from historical cases. We introduce SurvAgent, the first hierarchical chain-of-thought (CoT)-enhanced multi-agent system for multimodal survival prediction. SurvAgent consists of two stages: (1) WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical analysis through Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, and Confidence-Aware Patch Mining for pathology images, while Gene-Stratified analysis processes six functional gene categories. Both generate structured reports with CoT reasoning, storing complete analytical processes for experiential learning. (2) Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases via RAG and integrates multimodal reports with expert predictions through progressive interval refinement. Extensive experiments on five TCGA cohorts demonstrate SurvAgent's superority over conventional methods, proprietary MLLMs, and medical agents, establishing a new paradigm for explainable AI-driven survival prediction in precision oncology.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Guolin Huang, Wenting Chen, Jiaqi Yang, Xinheng Lyu, Xiaoling Luo, Sen Yang, Xiaohan Xing, Linlin Shen",
      "tags": [
        "cs.CV",
        "cs.CL"
      ]
    },
    {
      "title": "Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs",
      "url": "https://arxiv.org/abs/2511.16639",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16639v1 Announce Type: cross \nAbstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Wei-Cheng Tseng, David Harwath",
      "tags": [
        "eess.AS",
        "cs.CL"
      ]
    },
    {
      "title": "Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation",
      "url": "https://arxiv.org/abs/2511.16671",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16671v1 Announce Type: cross \nAbstract: Recent advances in visual generation have increasingly explored the integration of reasoning capabilities. They incorporate textual reasoning, i.e., think, either before (as pre-planning) or after (as post-refinement) the generation process, yet they lack on-the-fly multimodal interaction during the generation itself. In this preliminary study, we introduce Thinking-while-Generating (TwiG), the first interleaved framework that enables co-evolving textual reasoning throughout the visual generation process. As visual content is progressively generating, textual reasoning is interleaved to both guide upcoming local regions and reflect on previously synthesized ones. This dynamic interplay produces more context-aware and semantically rich visual outputs. To unveil the potential of this framework, we investigate three candidate strategies, zero-shot prompting, supervised fine-tuning (SFT) on our curated TwiG-50K dataset, and reinforcement learning (RL) via a customized TwiG-GRPO strategy, each offering unique insights into the dynamics of interleaved reasoning. We hope this work inspires further research into interleaving textual reasoning for enhanced visual generation. Code will be released at: https://github.com/ZiyuGuo99/Thinking-while-Generating.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Ziyu Guo, Renrui Zhang, Hongyu Li, Manyuan Zhang, Xinyan Chen, Sifan Wang, Yan Feng, Peng Pei, Pheng-Ann Heng",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "GPTopic: Dynamic and Interactive Topic Representations",
      "url": "https://arxiv.org/abs/2403.03628",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2403.03628v3 Announce Type: replace \nAbstract: Topic modeling seems to be almost synonymous with generating lists of top words to represent topics within large text corpora. However, deducing a topic from such list of individual terms can require substantial expertise and experience, making topic modelling less accessible to people unfamiliar with the particularities and pitfalls of top-word interpretation. A topic representation limited to top-words might further fall short of offering a comprehensive and easily accessible characterization of the various aspects, facets and nuances a topic might have. To address these challenges, we introduce GPTopic, a software package that leverages Large Language Models (LLMs) to create dynamic, interactive topic representations. GPTopic provides an intuitive chat interface for users to explore, analyze, and refine topics interactively, making topic modeling more accessible and comprehensive. The corresponding code is available here: https://github.com/ArikReuter/TopicGPT.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Arik Reuter, Bishnu Khadka, Anton Thielmann, Christoph Weisser, Sebastian Fischer, Benjamin S\\\"afken",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "LLMs as Models for Analogical Reasoning",
      "url": "https://arxiv.org/abs/2406.13803",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2406.13803v3 Announce Type: replace \nAbstract: Analogical reasoning -- the capacity to identify and map structural relationships between different domains -- is fundamental to human cognition and learning. Recent studies have shown that large language models (LLMs) can sometimes match humans in analogical reasoning tasks, opening the possibility that analogical reasoning might emerge from domain-general processes. However, it is still debated whether these emergent capacities are largely superficial and limited to simple relations seen during training or whether they encompass the flexible representational and mapping capabilities which are the focus of leading cognitive models of analogy. In this study, we introduce novel analogical reasoning tasks that require participants to map between semantically contentful words and sequences of letters and other abstract characters. This task necessitates the ability to flexibly re-represent rich semantic information -- an ability which is known to be central to human analogy but which is thus far not well captured by existing cognitive theories and models. We assess the performance of both human participants and LLMs on tasks focusing on reasoning from semantic structure and semantic content, introducing variations that test the robustness of their analogical inferences. Advanced LLMs match human performance across several conditions, though humans and LLMs respond differently to certain task variations and semantic distractors. Our results thus provide new evidence that LLMs might offer a how-possibly explanation of human analogical reasoning in contexts that are not yet well modeled by existing theories, but that even today's best models are unlikely to yield how-actually explanations.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Sam Musker, Alex Duchnowski, Rapha\\\"el Milli\\`ere, Ellie Pavlick",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering",
      "url": "https://arxiv.org/abs/2409.19753",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2409.19753v4 Announce Type: replace \nAbstract: Recent studies have explored the use of Large Language Models (LLMs) with Retrieval Augmented Generation (RAG) for Knowledge Graph Question Answering (KGQA). They typically require rewriting retrieved subgraphs into natural language formats comprehensible to LLMs. However, when tackling complex questions, the knowledge rewritten by existing methods may include irrelevant information, omit crucial details, or fail to align with the question's semantics. To address them, we propose a novel rewriting method CoTKR, Chain-of-Thought Enhanced Knowledge Rewriting, for generating reasoning traces and corresponding knowledge in an interleaved manner, thereby mitigating the limitations of single-step knowledge rewriting. Additionally, to bridge the preference gap between the knowledge rewriter and the question answering (QA) model, we propose a training strategy PAQAF, Preference Alignment from Question Answering Feedback, for leveraging feedback from the QA model to further optimize the knowledge rewriter. We conduct experiments using various LLMs across several KGQA benchmarks. Experimental results demonstrate that, compared with previous knowledge rewriting methods, CoTKR generates the most beneficial knowledge representation for QA models, which significantly improves the performance of LLMs in KGQA.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Yike Wu, Yi Huang, Nan Hu, Yuncheng Hua, Guilin Qi, Jiaoyan Chen, Jeff Z. Pan",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Atomic Calibration of LLMs in Long-Form Generations",
      "url": "https://arxiv.org/abs/2410.13246",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2410.13246v3 Announce Type: replace \nAbstract: Large language models (LLMs) often suffer from hallucinations, posing significant challenges for real-world applications. Confidence calibration, as an effective indicator of hallucination, is thus essential to enhance the trustworthiness of LLMs. Prior work mainly focuses on short-form tasks using a single response-level score (macro calibration), which is insufficient for long-form outputs that may contain both accurate and inaccurate claims. In this work, we systematically study atomic calibration, which evaluates factuality calibration at a fine-grained level by decomposing long responses into atomic claims. We further categorize existing confidence elicitation methods into discriminative and generative types, and propose two new confidence fusion strategies to improve calibration. Our experiments demonstrate that LLMs exhibit poorer calibration at the atomic level during long-form generation. More importantly, atomic calibration uncovers insightful patterns regarding the alignment of confidence methods and the changes of confidence throughout generation. This sheds light on future research directions for confidence estimation in long-form generation.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Caiqi Zhang, Ruihan Yang, Zhisong Zhang, Xinting Huang, Sen Yang, Dong Yu, Nigel Collier",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Crowdsourcing Lexical Diversity",
      "url": "https://arxiv.org/abs/2410.23133",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2410.23133v2 Announce Type: replace \nAbstract: Lexical-semantic resources (LSRs), such as online lexicons and wordnets, are fundamental to natural language processing applications as well as to fields such as linguistic anthropology and language preservation. In many languages, however, such resources suffer from quality issues: incorrect entries, incompleteness, but also the rarely addressed issue of bias towards the English language and Anglo-Saxon culture. Such bias manifests itself in the absence of concepts specific to the language or culture at hand, the presence of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit indication of untranslatability, also known as cross-lingual lexical gaps, when a term has no equivalent in another language. This paper proposes a novel crowdsourcing methodology for reducing bias in LSRs. Crowd workers compare lexemes from two languages, focusing on domains rich in lexical diversity, such as kinship or food. Our LingoGap crowdsourcing platform facilitates comparisons through microtasks identifying equivalent terms, language-specific terms, and lexical gaps across languages. We validated our method by applying it to two case studies focused on food-related terminology: (1) English and Arabic, and (2) Standard Indonesian and Banjarese. These experiments identified 2,140 lexical gaps in the first case study and 951 in the second. The success of these experiments confirmed the usability of our method and tool for future large-scale lexicon enrichment tasks.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Hadi Khalilia, Jahna Otterbacher, Gabor Bella, Shandy Darma, Fausto Giunchiglia",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking",
      "url": "https://arxiv.org/abs/2501.09751",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2501.09751v5 Announce Type: replace \nAbstract: Machine writing with large language models often relies on retrieval-augmented generation. However, these approaches remain confined within the boundaries of the model's predefined scope, limiting the generation of content with rich information. Specifically, vanilla-retrieved information tends to lack depth, novelty, and suffers from redundancy, which negatively impacts the quality of generated articles, leading to shallow, unoriginal, and repetitive outputs. To address these issues, we propose OmniThink, a slow-thinking machine writing framework that emulates the human-like process of iterative expansion and reflection. The core idea behind OmniThink is to simulate the cognitive behavior of learners as they slowly deepen their knowledge of the topics. Experimental results demonstrate that OmniThink improves the knowledge density of generated articles without compromising metrics such as coherence and depth. Human evaluations and expert feedback further highlight the potential of OmniThink to address real-world challenges in the generation of long-form articles. Code is available at https://github.com/zjunlp/OmniThink.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Efficient Environmental Claim Detection with Hyperbolic Graph Neural Networks",
      "url": "https://arxiv.org/abs/2502.13628",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2502.13628v3 Announce Type: replace \nAbstract: Transformer based models, especially large language models (LLMs) dominate the field of NLP with their mass adoption in tasks such as text generation, summarization and fake news detection. These models offer ease of deployment and reliability for most applications, however, they require significant amounts of computational power for training as well as inference. This poses challenges in their adoption in resource-constrained applications, especially in the open-source community where compute availability is usually scarce. This work proposes a graph-based approach for Environmental Claim Detection, exploring Graph Neural Networks (GNNs) and Hyperbolic Graph Neural Networks (HGNNs) as lightweight yet effective alternatives to transformer-based models. Re-framing the task as a graph classification problem, we transform claim sentences into dependency parsing graphs, utilizing a combination of word2vec \\& learnable part-of-speech (POS) tag embeddings for the node features and encoding syntactic dependencies in the edge relations. Our results show that our graph-based models, particularly HGNNs in the poincar\\'e space (P-HGNNs), achieve performance superior to the state-of-the-art on environmental claim detection while using up to \\textbf{30x fewer parameters}. We also demonstrate that HGNNs benefit vastly from explicitly modeling data in hierarchical (tree-like) structures, enabling them to significantly improve over their euclidean counterparts.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Darpan Aswal, Manjira Sinha",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners",
      "url": "https://arxiv.org/abs/2503.16356",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2503.16356v3 Announce Type: replace \nAbstract: Knowledge Editing (KE) enables the modification of outdated or incorrect information in large language models (LLMs). While existing KE methods can update isolated facts, they often fail to generalize these updates to multi-hop reasoning tasks that rely on the modified knowledge. Through an analysis of reasoning circuits -- the neural pathways LLMs use for knowledge-based inference, we find that current layer-localized KE approaches (e.g., MEMIT, WISE), which edit only single or a few model layers, inadequately integrate updated knowledge into these reasoning pathways. To address this limitation, we present CaKE (Circuit-aware Knowledge Editing), a novel method that enhances the effective integration of updated knowledge in LLMs. By only leveraging a few curated data samples guided by our circuit-based analysis, CaKE stimulates the model to develop appropriate reasoning circuits for newly incorporated knowledge. Experiments show that CaKE enables more accurate and consistent use of edited knowledge across related reasoning tasks, achieving an average improvement of 20% in multi-hop reasoning accuracy on the MQuAKE dataset while requiring less memory than existing KE methods. We release the code and data in https://github.com/zjunlp/CaKE.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Yunzhi Yao, Jizhan Fang, Jia-Chen Gu, Ningyu Zhang, Shumin Deng, Huajun Chen, Nanyun Peng",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "One Pic is All it Takes: Poisoning Visual Document Retrieval Augmented Generation with a Single Image",
      "url": "https://arxiv.org/abs/2504.02132",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2504.02132v3 Announce Type: replace \nAbstract: Retrieval-augmented generation (RAG) is instrumental for inhibiting hallucinations in large language models (LLMs) through the use of a factual knowledge base (KB). Although PDF documents are prominent sources of knowledge, text-based RAG pipelines are ineffective at capturing their rich multi-modal information. In contrast, visual document RAG (VD-RAG) uses screenshots of document pages as the KB, which has been shown to achieve state-of-the-art results. However, by introducing the image modality, VD-RAG introduces new attack vectors for adversaries to disrupt the system by injecting malicious documents into the KB. In this paper, we demonstrate the vulnerability of VD-RAG to poisoning attacks targeting both retrieval and generation. We define two attack objectives and demonstrate that both can be realized by injecting only a single adversarial image into the KB. Firstly, we introduce a targeted attack against one or a group of queries with the goal of spreading targeted disinformation. Secondly, we present a universal attack that, for any potential user query, influences the response to cause a denial-of-service in the VD-RAG system. We investigate the two attack objectives under both white-box and black-box assumptions, employing a multi-objective gradient-based optimization approach as well as prompting state-of-the-art generative models. Using two visual document datasets, a diverse set of state-of-the-art retrievers (embedding models) and generators (vision language models), we show VD-RAG is vulnerable to poisoning attacks in both the targeted and universal settings, yet demonstrating robustness to black-box attacks in the universal setting.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Ezzeldin Shereen, Dan Ristea, Shae McFadden, Burak Hasircioglu, Vasilios Mavroudis, Chris Hicks",
      "tags": [
        "cs.CL",
        "cs.CR",
        "cs.CV",
        "cs.IR"
      ]
    },
    {
      "title": "AutoJudge: Judge Decoding Without Manual Annotation",
      "url": "https://arxiv.org/abs/2504.20039",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2504.20039v4 Announce Type: replace \nAbstract: We introduce AutoJudge, a method that accelerates large language model (LLM) inference with task-specific lossy speculative decoding. Instead of matching the original model output distribution token-by-token, we identify which of the generated tokens affect the downstream quality of the response, relaxing the distribution match guarantee so that the \"unimportant\" tokens can be generated faster. Our approach relies on a semi-greedy search algorithm to test which of the mismatches between target and draft models should be corrected to preserve quality and which ones may be skipped. We then train a lightweight classifier based on existing LLM embeddings to predict, at inference time, which mismatching tokens can be safely accepted without compromising the final answer quality. We evaluate the effectiveness of AutoJudge with multiple draft/target model pairs on mathematical reasoning and programming benchmarks, achieving significant speedups at the cost of a minor accuracy reduction. Notably, on GSM8k with the Llama 3.1 70B target model, our approach achieves up to $\\approx2\\times$ speedup over speculative decoding at the cost of $\\le 1\\%$ drop in accuracy. When applied to the LiveCodeBench benchmark, AutoJudge automatically detects programming-specific important tokens, accepting $\\ge 25$ tokens per speculation cycle at $2\\%$ drop in Pass@1. Our approach requires no human annotation and is easy to integrate with modern LLM inference frameworks.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Roman Garipov, Fedor Velikonivtsev, Ivan Ermakov, Ruslan Svirschevski, Vage Egiazarian, Max Ryabinin",
      "tags": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Discriminating Form and Meaning in Multilingual Models with Minimal-Pair ABX Tasks",
      "url": "https://arxiv.org/abs/2505.17747",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2505.17747v4 Announce Type: replace \nAbstract: We introduce a set of training-free ABX-style discrimination tasks to evaluate how multilingual language models represent language identity (form) and semantic content (meaning). Inspired from speech processing, these zero-shot tasks measure whether minimal differences in representation can be reliably detected. This offers a flexible and interpretable alternative to probing. Applied to XLM-R (Conneau et al, 2020) across pretraining checkpoints and layers, we find that language discrimination declines over training and becomes concentrated in lower layers, while meaning discrimination strengthens over time and stabilizes in deeper layers. We then explore probing tasks, showing some alignment between our metrics and linguistic learning performance. Our results position ABX tasks as a lightweight framework for analyzing the structure of multilingual representations.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Maureen de Seyssel, Jie Chi, Skyler Seto, Maartje ter Hoeve, Masha Fedzechkina, Natalie Schluter",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "An Iterative Question-Guided Framework for Knowledge Base Question Answering",
      "url": "https://arxiv.org/abs/2506.01784",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2506.01784v4 Announce Type: replace \nAbstract: Large Language Models (LLMs) excel in many natural language processing tasks but often exhibit factual inconsistencies in knowledge-intensive settings. Integrating external knowledge resources, particularly knowledge graphs (KGs), provides a transparent and updatable foundation for more reliable reasoning. Knowledge Base Question Answering (KBQA), which queries and reasons over KGs, is central to this effort, especially for complex, multi-hop queries. However, multi-hop reasoning poses two key challenges: (1)~maintaining coherent reasoning paths, and (2)~avoiding prematurely discarding critical multi-hop connections. To tackle these challenges, we introduce iQUEST, a question-guided KBQA framework that iteratively decomposes complex queries into simpler sub-questions, ensuring a structured and focused reasoning trajectory. Additionally, we integrate a Graph Neural Network (GNN) to look ahead and incorporate 2-hop neighbor information at each reasoning step. This dual approach strengthens the reasoning process, enabling the model to explore viable paths more effectively. Detailed experiments demonstrate the consistent improvement delivered by iQUEST across four benchmark datasets and four LLMs.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Shuai Wang, Yinan Yu",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search",
      "url": "https://arxiv.org/abs/2506.06017",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2506.06017v2 Announce Type: replace \nAbstract: Large language model (LLM) agents have demonstrated strong capabilities across diverse domains, yet automated agent design remains a significant challenge. Current automated agent design approaches are often constrained by limited search spaces that primarily optimize workflows but fail to integrate crucial human-designed components like memory, planning, and tool use. Furthermore, these methods are hampered by high evaluation costs, as evaluating even a single new agent on a benchmark can require tens of dollars. The difficulty of this exploration is further exacerbated by inefficient search strategies that struggle to navigate the large design space effectively, making the discovery of novel agents a slow and resource-intensive process. To address these challenges, we propose AgentSwift, a novel framework for automated agent design. We formalize a hierarchical search space that jointly models agentic workflow and composable functional components. This structure moves beyond optimizing workflows alone by co-optimizing functional components, which enables the discovery of more complex and effective agent architectures. To make exploration within this expansive space feasible, we mitigate high evaluation costs by training a value model on a high-quality dataset, generated via a novel strategy combining combinatorial coverage and balanced Bayesian sampling for low-cost evaluation. Guiding the entire process is a hierarchical MCTS strategy, which is informed by uncertainty to efficiently navigate the search space. Evaluated across a comprehensive set of seven benchmarks spanning embodied, math, web, tool, and game domains, AgentSwift discovers agents that achieve an average performance gain of 8.34\\% over both existing automated agent search methods and manually designed agents. Our framework serves as a launchpad for researchers to rapidly discover powerful agent architectures.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Yu Li, Lehui Li, Zhihao Wu, Qingmin Liao, Jianye Hao, Kun Shao, Fengli Xu, Yong Li",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Beyond Bias Scores: Unmasking Vacuous Neutrality in Small Language Models",
      "url": "https://arxiv.org/abs/2506.08487",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2506.08487v2 Announce Type: replace \nAbstract: The rapid adoption of Small Language Models (SLMs) for resource constrained applications has outpaced our understanding of their ethical and fairness implications. To address this gap, we introduce the Vacuous Neutrality Framework (VaNeu), a multi-dimensional evaluation paradigm designed to assess SLM fairness prior to deployment. The framework examines model robustness across four stages - biases, utility, ambiguity handling, and positional bias over diverse social bias categories. To the best of our knowledge, this work presents the first large-scale audit of SLMs in the 0.5-5B parameter range, an overlooked \"middle tier\" between BERT-class encoders and flagship LLMs. We evaluate nine widely used SLMs spanning four model families under both ambiguous and disambiguated contexts. Our findings show that models demonstrating low bias in early stages often fail subsequent evaluations, revealing hidden vulnerabilities and unreliable reasoning. These results underscore the need for a more comprehensive understanding of fairness and reliability in SLMs, and position the proposed framework as a principled tool for responsible deployment in socially sensitive settings.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Sumanth Manduru, Carlotta Domeniconi",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Eliciting Reasoning in Language Models with Cognitive Tools",
      "url": "https://arxiv.org/abs/2506.12115",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2506.12115v2 Announce Type: replace \nAbstract: The recent advent of reasoning models like OpenAI's o1 was met with excited speculation by the AI community about the mechanisms underlying these capabilities in closed models, followed by a rush of replication efforts, particularly from the open source community. These speculations were largely settled by the demonstration from DeepSeek-R1 that chains-of-thought and reinforcement learning (RL) can effectively replicate reasoning on top of base LLMs. However, it remains valuable to explore alternative methods for theoretically eliciting reasoning that could help elucidate the underlying mechanisms, as well as providing additional methods that may offer complementary benefits.\n  Here, we build on the long-standing literature in cognitive psychology and cognitive architectures, which postulates that reasoning arises from the orchestrated, sequential execution of a set of modular, predetermined cognitive operations. Crucially, we implement this key idea within a modern agentic tool-calling framework. In particular, we endow an LLM with a small set of \"cognitive tools\" encapsulating specific reasoning operations, each executed by the LLM itself. Surprisingly, this simple strategy results in considerable gains in performance on standard mathematical reasoning benchmarks compared to base LLMs, for both closed and open-weight models. For instance, providing our \"cognitive tools\" to GPT-4.1 increases its pass@1 performance on AIME2024 from 32% to 53%, even surpassing the performance of o1-preview.\n  In addition to its practical implications, this demonstration contributes to the debate regarding the role of post-training methods in eliciting reasoning in LLMs versus the role of inherent capabilities acquired during pre-training, and whether post-training merely uncovers these latent abilities.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Brown Ebouky, Andrea Bartezzaghi, Mattia Rigotti",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement",
      "url": "https://arxiv.org/abs/2507.19081",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2507.19081v4 Announce Type: replace \nAbstract: Argument summarization aims to generate concise, structured representations of complex, multi-perspective debates. While recent work has advanced the identification and clustering of argumentative components, the generation stage remains underexplored. Existing approaches typically rely on single-pass generation, offering limited support for factual correction or structural refinement. To address this gap, we introduce Arg-LLaDA, a novel large language diffusion framework that iteratively improves summaries via sufficiency-guided remasking and regeneration. Our method combines a flexible masking controller with a sufficiency-checking module to identify and revise unsupported, redundant, or incomplete spans, yielding more faithful, concise, and coherent outputs. Empirical results on two benchmark datasets demonstrate that Arg-LLaDA surpasses state-of-the-art baselines in 7 out of 10 automatic evaluation metrics. In addition, human evaluations reveal substantial improvements across core dimensions, coverage, faithfulness, and conciseness, validating the effectiveness of our iterative, sufficiency-aware generation strategy.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Hao Li, Yizheng Sun, Viktor Schlegel, Kailai Yang, Riza Batista-Navarro, Goran Nenadic",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory",
      "url": "https://arxiv.org/abs/2508.07279",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.07279v3 Announce Type: replace \nAbstract: Recent advances in large language models (LLMs) offer new opportunities for scalable, interactive mental health assessment, but excessive querying by LLMs burdens users and is inefficient for real-world screening across transdiagnostic symptom profiles. We introduce MAQuA, an adaptive question-asking framework for simultaneous, multidimensional mental health screening. Combining multi-outcome modeling on language responses with item response theory (IRT) and factor analysis, MAQuA selects the questions with most informative responses across multiple dimensions at each turn to optimize diagnostic information, improving accuracy and potentially reducing response burden. Empirical results on a novel dataset reveal that MAQuA reduces the number of assessment questions required for score stabilization by 50-87% compared to random ordering (e.g., achieving stable depression scores with 71% fewer questions and eating disorder scores with 85% fewer questions). MAQuA demonstrates robust performance across both internalizing (depression, anxiety) and externalizing (substance use, eating disorder) domains, with early stopping strategies further reducing patient time and burden. These findings position MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive mental health screening, advancing the integration of LLM-based agents into real-world clinical workflows.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Vasudha Varadarajan, Hui Xu, Rebecca Astrid Boehme, Mariam Marlan Mirstrom, Sverker Sikstrom, H. Andrew Schwartz",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CRISP: Persistent Concept Unlearning via Sparse Autoencoders",
      "url": "https://arxiv.org/abs/2508.13650",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.13650v2 Announce Type: replace \nAbstract: As large language models (LLMs) are increasingly deployed in real-world applications, the need to selectively remove unwanted knowledge while preserving model utility has become paramount. Recent work has explored sparse autoencoders (SAEs) to perform precise interventions on monosemantic features. However, most SAE-based methods operate at inference time, which does not create persistent changes in the model's parameters. Such interventions can be bypassed or reversed by malicious actors with parameter access. We introduce CRISP, a parameter-efficient method for persistent concept unlearning using SAEs. CRISP automatically identifies salient SAE features across multiple layers and suppresses their activations. We experiment with two LLMs and show that our method outperforms prior approaches on safety-critical unlearning tasks from the WMDP benchmark, successfully removing harmful knowledge while preserving general and in-domain capabilities. Feature-level analysis reveals that CRISP achieves semantically coherent separation between target and benign concepts, allowing precise suppression of the target features.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Tomer Ashuach, Dana Arad, Aaron Mueller, Martin Tutek, Yonatan Belinkov",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "From Confidence to Collapse in LLM Factual Robustness",
      "url": "https://arxiv.org/abs/2508.16267",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.16267v3 Announce Type: replace \nAbstract: Ensuring the robustness of factual knowledge in LLMs is critical for reliable applications in tasks such as question answering and reasoning. However, existing evaluation methods predominantly focus on performance-based metrics, often investigating from the perspective of prompt perturbations, which captures only the externally triggered side of knowledge robustness. To bridge this gap, we introduce a principled approach to measure factual robustness from the perspective of the generation process by analyzing token distribution entropy in combination with temperature scaling sensitivity. These two factors build the Factual Robustness Score (FRS), a novel metric which quantifies the stability of a fact against perturbations in decoding conditions, given its initial uncertainty. To validate our approach, we conduct extensive experiments on 5 LLMs across 3 closed-book QA datasets (SQuAD, TriviaQA, and HotpotQA). We show that factual robustness varies significantly -- smaller models report an FRS of $0.76$, larger ones $0.93$ -- with accuracy degrading by ~$60\\%$ under increased uncertainty. These insights demonstrate how entropy and temperature scaling impact factual accuracy, and lay a foundation for developing more robust knowledge retention and retrieval in future models.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Alina Fastowski, Bardh Prenkaj, Gjergji Kasneci",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples",
      "url": "https://arxiv.org/abs/2508.21083",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2508.21083v2 Announce Type: replace \nAbstract: Deep learning models often learn and exploit spurious correlations in training data, using these non-target features to inform their predictions. Such reliance leads to performance degradation and poor generalization on unseen data. To address these limitations, we introduce a more general form of counterfactual data augmentation, termed counterbias data augmentation, which simultaneously tackles multiple biases (e.g., gender bias, simplicity bias) and enhances out-of-distribution robustness. We present CoBA: CounterBias Augmentation, a unified framework that operates at the semantic triple level: first decomposing text into subject-predicate-object triples, then selectively modifying these triples to disrupt spurious correlations. By reconstructing the text from these adjusted triples, CoBA generates counterbias data that mitigates spurious patterns. Through extensive experiments, we demonstrate that CoBA not only improves downstream task performance, but also effectively reduces biases and strengthens out-of-distribution resilience, offering a versatile and robust solution to the challenges posed by spurious correlations.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Kyohoon Jin, Juhwan Choi, Jungmin Yun, Junho Lee, Soojin Jang, Youngbin Kim",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize",
      "url": "https://arxiv.org/abs/2509.03888",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.03888v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) can comply with harmful instructions, raising serious safety concerns despite their impressive capabilities. Recent work has leveraged probing-based approaches to study the separability of malicious and benign inputs in LLMs' internal representations, and researchers have proposed using such probing methods for safety detection. We systematically re-examine this paradigm. Motivated by poor out-of-distribution performance, we hypothesize that probes learn superficial patterns rather than semantic harmfulness. Through controlled experiments, we confirm this hypothesis and identify the specific patterns learned: instructional patterns and trigger words. Our investigation follows a systematic approach, progressing from demonstrating comparable performance of simple n-gram methods, to controlled experiments with semantically cleaned datasets, to detailed analysis of pattern dependencies. These results reveal a false sense of security around current probing-based approaches and highlight the need to redesign both models and evaluation protocols, for which we provide further discussions in the hope of suggesting responsible further research in this direction. We have open-sourced the project at https://github.com/WangCheng0116/Why-Probe-Fails.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Cheng Wang, Zeming Wei, Qin Liu, Muhao Chen",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Verbalized Algorithms",
      "url": "https://arxiv.org/abs/2509.08150",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.08150v3 Announce Type: replace \nAbstract: Instead of querying LLMs in a one-shot manner and hoping to get the right answer for a reasoning task, we propose a paradigm we call \\emph{verbalized algorithms} (VAs), which leverage classical algorithms with established theoretical understanding. VAs decompose a task into simple elementary operations on natural language strings that they should be able to answer reliably, and limit the scope of LLMs to only those simple tasks. For example, for sorting a series of natural language strings, \\emph{verbalized sorting} uses an LLM as a binary comparison oracle in a known and well-analyzed sorting algorithm (e.g., bitonic sorting network). We demonstrate the effectiveness of this approach on sorting and clustering tasks.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Supriya Lall, Christian Farrell, Hari Pathanjaly, Marko Pavic, Sarvesh Chezhian, Masataro Asai",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes",
      "url": "https://arxiv.org/abs/2509.21456",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2509.21456v3 Announce Type: replace \nAbstract: Moral alignment has emerged as a widely adopted approach for regulating the behavior of pretrained language models (PLMs), typically through fine-tuning on curated datasets. Gender stereotype mitigation is a representational task within the broader application of moral alignment. However, this process often comes at the cost of degraded downstream task performance. Prior studies commonly aim to achieve a performance trade-off by encouraging PLMs to selectively forget only stereotypical knowledge through carefully designed fairness objective, while preserving their language modeling capability (overall forgetting). In this short paper, we investigate whether the performance trade-off can be achieved through the lens of forgetting and the fairness objective. Our analysis shows that the large datasets needed for satisfactory fairness highlight the limitations of current fairness objectives in achieving an effective trade-off: (1) downstream task performance is strongly correlated with overall forgetting; (2) selective forgetting reduces stereotypes, but overall forgetting increases. and (3) general solutions for alleviating forgetting are ineffective at reducing the overall forgetting and fail to improve downstream task performance.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Guangliang Liu, Bocheng Chen, Han Zi, Xitong Zhang, Kristen Marie Johnson",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "Steering Evaluation-Aware Language Models to Act Like They Are Deployed",
      "url": "https://arxiv.org/abs/2510.20487",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2510.20487v3 Announce Type: replace \nAbstract: Large language models (LLMs) can sometimes detect when they are being evaluated and adjust their behavior to appear more aligned, compromising the reliability of safety evaluations. In this paper, we show that adding a steering vector to an LLM's activations can suppress evaluation-awareness and make the model act like it is deployed during evaluation. To study our steering technique, we train an LLM to exhibit evaluation-aware behavior using a two-step training process designed to mimic how this behavior could emerge naturally. First, we perform continued pretraining on documents with factual descriptions of the model (1) using Python type hints during evaluation but not during deployment and (2) recognizing that the presence of a certain evaluation cue always means that it is being tested. Then, we train the model with expert iteration to use Python type hints in evaluation settings. The resulting model is evaluation-aware: it writes type hints in evaluation contexts more than deployment contexts. We find that activation steering can suppress evaluation awareness and make the model act like it is deployed even when the cue is present. Importantly, we constructed our steering vector using the original model before our additional training. Our results suggest that AI evaluators could improve the reliability of safety evaluations by steering models to act like they are deployed.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Tim Tian Hua, Andrew Qin, Samuel Marks, Neel Nanda",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Confidence-Guided Stepwise Model Routing for Cost-Efficient Reasoning",
      "url": "https://arxiv.org/abs/2511.06190",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.06190v2 Announce Type: replace \nAbstract: Recent advances in Large Language Models (LLMs) - particularly model scaling and test-time techniques - have greatly enhanced the reasoning capabilities of language models at the expense of higher inference costs. To lower inference costs, prior works train router models or deferral mechanisms that allocate easy queries to a small, efficient model, while forwarding harder queries to larger, more expensive models. However, these trained router models often lack robustness under domain shifts and require expensive data synthesis techniques such as Monte Carlo rollouts to obtain sufficient ground-truth routing labels for training. In this work, we propose Confidence-Guided Stepwise Model Routing for Cost-Efficient Reasoning (STEER), a domain-agnostic framework that performs fine-grained, step-level routing between smaller and larger LLMs without utilizing external models. STEER leverages confidence scores from the smaller model's logits prior to generating a reasoning step, so that the large model is invoked only when necessary. Extensive evaluations using different LLMs on a diverse set of challenging benchmarks across multiple domains such as Mathematical Reasoning, Multi-Hop QA, and Planning tasks indicate that STEER achieves competitive or enhanced accuracy while reducing inference costs (up to +20% accuracy with 48% less FLOPs compared to solely using the larger model on AIME), outperforming baselines that rely on trained external modules. Our results establish model-internal confidence as a robust, domain-agnostic signal for model routing, offering a scalable pathway for efficient LLM deployment.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Sangmook Lee, Dohyung Kim, Hyukhun Koh, Nakyeong Yang, Kyomin Jung",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging",
      "url": "https://arxiv.org/abs/2511.07129",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.07129v2 Announce Type: replace \nAbstract: Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for fine-tuning large language models. However, conventional LoRA adapters are typically trained for a single task, limiting their applicability in real-world settings where inputs may span diverse and unpredictable domains. At inference time, existing approaches combine multiple LoRAs for improving performance on diverse tasks, while usually requiring labeled data or additional task-specific training, which is expensive at scale. In this work, we introduce LoRA on the Go (LoGo), a training-free framework that dynamically selects and merges adapters at the instance level without any additional requirements. LoGo leverages signals extracted from a single forward pass through LoRA adapters, to identify the most relevant adapters and determine their contributions on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo outperforms training-based baselines on some tasks upto a margin of 3.6% while remaining competitive on other tasks and maintaining inference throughput, highlighting its effectiveness and practicality.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Seungeon Lee, Soumi Das, Manish Gupta, Krishna P. Gummadi",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "HalluClean: A Unified Framework to Combat Hallucinations in LLMs",
      "url": "https://arxiv.org/abs/2511.08916",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.08916v3 Announce Type: replace \nAbstract: Large language models (LLMs) have achieved impressive performance across a wide range of natural language processing tasks, yet they often produce hallucinated content that undermines factual reliability. To address this challenge, we introduce HalluClean, a lightweight and task-agnostic framework for detecting and correcting hallucinations in LLM-generated text. HalluClean adopts a reasoning-enhanced paradigm, explicitly decomposing the process into planning, execution, and revision stages to identify and refine unsupported claims. It employs minimal task-routing prompts to enable zero-shot generalization across diverse domains, without relying on external knowledge sources or supervised detectors. We conduct extensive evaluations on five representative tasks-question answering, dialogue, summarization, math word problems, and contradiction detection. Experimental results show that HalluClean significantly improves factual consistency and outperforms competitive baselines, demonstrating its potential to enhance the trustworthiness of LLM outputs in real-world applications.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Yaxin Zhao, Yu Zhang",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "MajinBook: An open catalogue of digital world literature with likes",
      "url": "https://arxiv.org/abs/2511.11412",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.11412v3 Announce Type: replace \nAbstract: This data paper introduces MajinBook, an open catalogue designed to facilitate the use of shadow libraries--such as Library Genesis and Z-Library--for computational social science and cultural analytics. By linking metadata from these vast, crowd-sourced archives with structured bibliographic data from Goodreads, we create a high-precision corpus of over 539,000 references to English-language books spanning three centuries, enriched with first publication dates, genres, and popularity metrics like ratings and reviews. Our methodology prioritizes natively digital EPUB files to ensure machine-readable quality, while addressing biases in traditional corpora like HathiTrust, and includes secondary datasets for French, German, and Spanish. We evaluate the linkage strategy for accuracy, release all underlying data openly, and discuss the project's legal permissibility under EU and US frameworks for text and data mining in research.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Antoine Mazi\\`eres, Thierry Poibeau",
      "tags": [
        "cs.CL",
        "cs.CY",
        "stat.OT"
      ]
    },
    {
      "title": "Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy",
      "url": "https://arxiv.org/abs/2511.12920",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.12920v2 Announce Type: replace \nAbstract: Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Desheng Hu, Joachim Baumann, Aleksandra Urman, Elsa Lichtenegger, Robin Forsberg, Aniko Hannak, Christo Wilson",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.IR"
      ]
    },
    {
      "title": "ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning",
      "url": "https://arxiv.org/abs/2511.14366",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.14366v2 Announce Type: replace \nAbstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable \"ruler\" for progress toward Artificial General Intelligence.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Hongwei Liu, Junnan Liu, Shudong Liu, Haodong Duan, Yuqiang Li, Mao Su, Xiaohong Liu, Guangtao Zhai, Xinyu Fang, Qianhong Ma, Taolin Zhang, Zihan Ma, Yufeng Zhao, Peiheng Zhou, Linchen Xiao, Wenlong Zhang, Shijie Zhou, Xingjian Ma, Siqi Sun, Jiaye Ge, Meng Li, Yuhong Liu, Jianxin Dong, Jiaying Li, Hui Wu, Hanwen Liang, Jintai Lin, Yanting Wang, Jie Dong, Tong Zhu, Tianfan Fu, Conghui He, Qi Zhang, Songyang Zhang, Lei Bai, Kai Chen",
      "tags": [
        "cs.CL"
      ]
    },
    {
      "title": "OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition",
      "url": "https://arxiv.org/abs/2511.15211",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15211v2 Announce Type: replace \nAbstract: With the rapid expansion of unstructured clinical texts in electronic health records (EHRs), clinical named entity recognition (NER) has become a crucial technique for extracting medical information. However, traditional supervised models such as CRF and BioClinicalBERT suffer from high annotation costs. Although zero-shot NER based on large language models (LLMs) reduces the dependency on labeled data, challenges remain in aligning example selection with task granularity and effectively integrating prompt design with self-improvement frameworks. To address these limitations, we propose OEMA, a novel zero-shot clinical NER framework based on multi-agent collaboration. OEMA consists of three core components: (1) a self-annotator that autonomously generates candidate examples; (2) a discriminator that leverages SNOMED CT to filter token-level examples by clinical relevance; and (3) a predictor that incorporates entity-type descriptions to enhance inference accuracy. Experimental results on two benchmark datasets, MTSamples and VAERS, demonstrate that OEMA achieves state-of-the-art performance under exact-match evaluation. Moreover, under related-match criteria, OEMA performs comparably to the supervised BioClinicalBERT model while significantly outperforming the traditional CRF method. OEMA improves zero-shot clinical NER, achieving near-supervised performance under related-match criteria. Future work will focus on continual learning and open-domain adaptation to expand its applicability in clinical NLP.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Xinli Tao, Xin Dong, Xuezhong Zhou",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models",
      "url": "https://arxiv.org/abs/2511.15304",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15304v2 Announce Type: replace \nAbstract: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for Large Language Models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of 3 open-weight LLM judges, whose binary safety assessments were validated on a stratified human-labeled subset. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Piercosma Bisconti, Matteo Prandi, Federico Pierucci, Francesco Giarrusso, Marcantonio Bracale, Marcello Galisai, Vincenzo Suriani, Olga Sorokoletova, Federico Sartore, Daniele Nardi",
      "tags": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Multimodal Evaluation of Russian-language Architectures",
      "url": "https://arxiv.org/abs/2511.15552",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15552v2 Announce Type: replace \nAbstract: Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.",
      "source": "cs.CL updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.CL",
      "author": "Artem Chervyakov, Ulyana Isaeva, Anton Emelyanov, Artem Safin, Maria Tikhonova, Alexander Kharitonov, Yulia Lyakh, Petr Surovtsev, Denis Shevelev, Vildan Saburov, Vasily Konovalov, Elisei Rykov, Ivan Sviridov, Amina Miftakhova, Ilseyar Alimova, Alexander Panchenko, Alexander Kapitanov, Alena Fenogenova",
      "tags": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and Turn",
      "url": "https://arxiv.org/abs/2511.15738",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15738v1 Announce Type: new \nAbstract: Reasoning reinforcement learning (RL) has recently revealed a new scaling effect: test-time scaling. Thinking models such as R1 and o1 improve their reasoning accuracy at test time as the length of the reasoning context increases. However, compared with training-time scaling, test-time scaling is fundamentally limited by the limited context length of base models, which remains orders of magnitude smaller than the amount of tokens consumed during training. We revisit test-time enhancement techniques through the lens of scaling effect and introduce a unified framework of multi-dimensional test-time scaling to extend the capacity of test-time reasoning. Beyond conventional context-length scaling, we consider two additional dimensions: batch scaling, where accuracy improves with parallel sampling, and turn scaling, where iterative self-refinement enhances reasoning quality. Building on this perspective, we propose 3D test-time scaling, which integrates context, batch, and turn scaling. We show that: (1) each dimension demonstrates a test-time scaling effect, but with a bounded capacity; (2) combining all three dimensions substantially improves the reasoning performance of challenging testbeds, including IOI, IMO, and CPHO, and further benefits from human preference feedback; and (3) the human-in-the-loop framework naturally extends to a more open-ended domain, i.e., embodied learning, which enables the design of humanoid control behaviors.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Chao Yu (Tsinghua University), Qixin Tan (Tsinghua University), Jiaxuan Gao (Tsinghua University), Shi Yu (Tsinghua University), Hong Lu (Tsinghua University), Xinting Yang (Tsinghua University), Zelai Xu (Tsinghua University), Yu Wang (Tsinghua University), Yi Wu (Tsinghua University), Eugene Vinitsky (New York University)",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Connecting the Dots: A Machine Learning Ready Dataset for Ionospheric Forecasting Models",
      "url": "https://arxiv.org/abs/2511.15743",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15743v1 Announce Type: new \nAbstract: Operational forecasting of the ionosphere remains a critical space weather challenge due to sparse observations, complex coupling across geospatial layers, and a growing need for timely, accurate predictions that support Global Navigation Satellite System (GNSS), communications, aviation safety, as well as satellite operations. As part of the 2025 NASA Heliolab, we present a curated, open-access dataset that integrates diverse ionospheric and heliospheric measurements into a coherent, machine learning-ready structure, designed specifically to support next-generation forecasting models and address gaps in current operational frameworks. Our workflow integrates a large selection of data sources comprising Solar Dynamic Observatory data, solar irradiance indices (F10.7), solar wind parameters (velocity and interplanetary magnetic field), geomagnetic activity indices (Kp, AE, SYM-H), and NASA JPL's Global Ionospheric Maps of Total Electron Content (GIM-TEC). We also implement geospatially sparse data such as the TEC derived from the World-Wide GNSS Receiver Network and crowdsourced Android smartphone measurements. This novel heterogeneous dataset is temporally and spatially aligned into a single, modular data structure that supports both physical and data-driven modeling. Leveraging this dataset, we train and benchmark several spatiotemporal machine learning architectures for forecasting vertical TEC under both quiet and geomagnetically active conditions. This work presents an extensive dataset and modeling pipeline that enables exploration of not only ionospheric dynamics but also broader Sun-Earth interactions, supporting both scientific inquiry and operational forecasting efforts.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Linnea M. Wolniewicz, Halil S. Kelebek, Simone Mestici, Michael D. Vergalla, Giacomo Acciarini, Bala Poduval, Olga Verkhoglyadova, Madhulika Guhathakurta, Thomas E. Berger, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Frank Soboczenski",
      "tags": [
        "cs.LG",
        "astro-ph.EP",
        "astro-ph.IM"
      ]
    },
    {
      "title": "TB or Not TB: Coverage-Driven Direct Preference Optimization for Verilog Stimulus Generation",
      "url": "https://arxiv.org/abs/2511.15767",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15767v1 Announce Type: new \nAbstract: With the rapid advancement of Large Language Models (LLMs), there is growing interest in applying them to hardware design and verification. Among these stages, design verification remains the most time-consuming and resource-intensive phase, where generating effective stimuli for the design under test (DUT) is both critical and labor-intensive. We present {\\it TB or not TB}, a framework for automated stimulus generation using LLMs fine-tuned through Coverage-Driven Direct Preference Optimization (CD-DPO). To enable preference-based training, we introduce PairaNet, a dataset derived from PyraNet that pairs high- and low-quality testbenches labeled using simulation-derived coverage metrics. The proposed CD-DPO method integrates quantitative coverage feedback directly into the optimization objective, guiding the model toward generating stimuli that maximize verification coverage. Experiments on the CVDP CID12 benchmark show that {\\it TB or not TB} outperforms both open-source and commercial baselines, achieving up to 77.27\\% improvement in code coverage, demonstrating the effectiveness of Coverage-driven preference optimization for LLM-based hardware verification.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Bardia Nadimi, Khashayar Filom, Deming Chen, Hao Zheng",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ]
    },
    {
      "title": "TopoReformer: Mitigating Adversarial Attacks Using Topological Purification in OCR Models",
      "url": "https://arxiv.org/abs/2511.15807",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15807v1 Announce Type: new \nAbstract: Adversarially perturbed images of text can cause sophisticated OCR systems to produce misleading or incorrect transcriptions from seemingly invisible changes to humans. Some of these perturbations even survive physical capture, posing security risks to high-stakes applications such as document processing, license plate recognition, and automated compliance systems. Existing defenses, such as adversarial training, input preprocessing, or post-recognition correction, are often model-specific, computationally expensive, and affect performance on unperturbed inputs while remaining vulnerable to unseen or adaptive attacks. To address these challenges, TopoReformer is introduced, a model-agnostic reformation pipeline that mitigates adversarial perturbations while preserving the structural integrity of text images. Topology studies properties of shapes and spaces that remain unchanged under continuous deformations, focusing on global structures such as connectivity, holes, and loops rather than exact distance. Leveraging these topological features, TopoReformer employs a topological autoencoder to enforce manifold-level consistency in latent space and improve robustness without explicit gradient regularization. The proposed method is benchmarked on EMNIST, MNIST, against standard adversarial attacks (FGSM, PGD, Carlini-Wagner), adaptive attacks (EOT, BDPA), and an OCR-specific watermark attack (FAWA).",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Bhagyesh Kumar, A S Aravinthakashan, Akshat Satyanarayan, Ishaan Gakhar, Ujjwal Verma",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Beyond Tsybakov: Model Margin Noise and $\\mathcal{H}$-Consistency Bounds",
      "url": "https://arxiv.org/abs/2511.15816",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15816v1 Announce Type: new \nAbstract: We introduce a new low-noise condition for classification, the Model Margin Noise (MM noise) assumption, and derive enhanced $\\mathcal{H}$-consistency bounds under this condition. MM noise is weaker than Tsybakov noise condition: it is implied by Tsybakov noise condition but can hold even when Tsybakov fails, because it depends on the discrepancy between a given hypothesis and the Bayes-classifier rather than on the intrinsic distributional minimal margin (see Figure 1 for an illustration of an explicit example). This hypothesis-dependent assumption yields enhanced $\\mathcal{H}$-consistency bounds for both binary and multi-class classification. Our results extend the enhanced $\\mathcal{H}$-consistency bounds of Mao, Mohri, and Zhong (2025a) with the same favorable exponents but under a weaker assumption than the Tsybakov noise condition; they interpolate smoothly between linear and square-root regimes for intermediate noise levels. We also instantiate these bounds for common surrogate loss families and provide illustrative tables.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Mehryar Mohri, Yutao Zhong",
      "tags": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Attention-Based Feature Online Conformal Prediction for Time Series",
      "url": "https://arxiv.org/abs/2511.15838",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15838v1 Announce Type: new \nAbstract: Online conformal prediction (OCP) wraps around any pre-trained predictor to produce prediction sets with coverage guarantees that hold irrespective of temporal dependencies or distribution shifts. However, standard OCP faces two key limitations: it operates in the output space using simple nonconformity (NC) scores, and it treats all historical observations uniformly when estimating quantiles. This paper introduces attention-based feature OCP (AFOCP), which addresses both limitations through two key innovations. First, AFOCP operates in the feature space of pre-trained neural networks, leveraging learned representations to construct more compact prediction sets by concentrating on task-relevant information while suppressing nuisance variation. Second, AFOCP incorporates an attention mechanism that adaptively weights historical observations based on their relevance to the current test point, effectively handling non-stationarity and distribution shifts. We provide theoretical guarantees showing that AFOCP maintains long-term coverage while provably achieving smaller prediction intervals than standard OCP under mild regularity conditions. Extensive experiments on synthetic and real-world time series datasets demonstrate that AFOCP consistently reduces the size of prediction intervals by as much as $88\\%$ as compared to OCP, while maintaining target coverage levels, validating the benefits of both feature-space calibration and attention-based adaptive weighting.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Meiyi Zhu, Caili Guo, Chunyan Feng, Osvaldo Simeone",
      "tags": [
        "cs.LG",
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    },
    {
      "title": "Transparent Early ICU Mortality Prediction with Clinical Transformer and Per-Case Modality Attribution",
      "url": "https://arxiv.org/abs/2511.15847",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15847v1 Announce Type: new \nAbstract: Early identification of intensive care patients at risk of in-hospital mortality enables timely intervention and efficient resource allocation. Despite high predictive performance, existing machine learning approaches lack transparency and robustness, limiting clinical adoption. We present a lightweight, transparent multimodal ensemble that fuses physiological time-series measurements with unstructured clinical notes from the first 48 hours of an ICU stay. A logistic regression model combines predictions from two modality-specific models: a bidirectional LSTM for vitals and a finetuned ClinicalModernBERT transformer for notes. This traceable architecture allows for multilevel interpretability: feature attributions within each modality and direct per-case modality attributions quantifying how vitals and notes influence each decision. On the MIMIC-III benchmark, our late-fusion ensemble improves discrimination over the best single model (AUPRC 0.565 vs. 0.526; AUROC 0.891 vs. 0.876) while maintaining well-calibrated predictions. The system remains robust through a calibrated fallback when a modality is missing. These results demonstrate competitive performance with reliable, auditable risk estimates and transparent, predictable operation, which together are crucial for clinical use.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Alexander Bakumenko (Clemson University, USA), Janine Hoelscher (Clemson University, USA), Hudson Smith (Clemson University, USA)",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "discretize_distributions: Efficient Quantization of Gaussian Mixtures with Guarantees in Wasserstein Distance",
      "url": "https://arxiv.org/abs/2511.15854",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15854v1 Announce Type: new \nAbstract: We present discretize_distributions, a Python package that efficiently constructs discrete approximations of Gaussian mixture distributions and provides guarantees on the approximation error in Wasserstein distance. The package implements state-of-the-art quantization methods for Gaussian mixture models and extends them to improve scalability. It further integrates complementary quantization strategies such as sigma-point methods and provides a modular interface that supports custom schemes and integration into control and verification pipelines for cyber-physical systems. We benchmark the package on various examples, including high-dimensional, large, and degenerate Gaussian mixtures, and demonstrate that discretize_distributions produces accurate approximations at low computational cost.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Steven Adams, Elize Alwash, Luca Laurenti",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "GLOBE: Accurate and Generalizable PDE Surrogates using Domain-Inspired Architectures and Equivariances",
      "url": "https://arxiv.org/abs/2511.15856",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15856v1 Announce Type: new \nAbstract: We introduce GLOBE, a new neural surrogate for homogeneous PDEs that draws inductive bias from boundary-element methods and equivariant ML. GLOBE represents solutions as superpositions of learnable Green's-function-like kernels evaluated from boundary faces to targets, composed across multiscale branches and communication hyperlayers. The architecture is translation-, rotation-, and parity-equivariant; discretization-invariant in the fine-mesh limit; and units-invariant via rigorous nondimensionalization. An explicit far-field decay envelope stabilizes extrapolation, boundary-to-boundary hyperlayer communication mediates long-range coupling, and the all-to-all boundary-to-target evaluation yields a global receptive field that respects PDE information flow, even for elliptic PDEs.\n  On AirFRANS (steady incompressible RANS over NACA airfoils), GLOBE achieves substantial accuracy improvements. On the \"Full\" split, it reduces mean-squared error by roughly 200x on all fields relative to the dataset's reference baselines, and roughly 50x relative to the next-best-performing model. In the \"Scarce\" split, it achieves over 100x lower error on velocity and pressure fields and over 600x lower error on surface pressure than Transolver. Qualitative results show sharp near-wall gradients, coherent wakes, and limited errors under modest extrapolation in Reynolds number and angle of attack.\n  In addition to this accuracy, the model is quite compact (117k parameters), and fields can be evaluated at arbitrary points during inference. We also demonstrate the ability to train and predict with non-watertight meshes, which has strong practical implications.\n  These results show that rigorous physics- and domain-inspired inductive biases can achieve large gains in accuracy, generalizability, and practicality for ML-based PDE surrogates for industrial computer-aided engineering (CAE).",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Peter Sharpe",
      "tags": [
        "cs.LG",
        "physics.flu-dyn"
      ]
    },
    {
      "title": "Global Resolution: Optimal Multi-Draft Speculative Sampling via Convex Minimization",
      "url": "https://arxiv.org/abs/2511.15898",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15898v1 Announce Type: new \nAbstract: Speculative sampling reduces the latency of autoregressive decoding for target model LLMs without sacrificing inference quality, by using a cheap draft model to suggest a candidate token and a verification criterion to accept or resample this token. To improve acceptance and decoding efficiency, recent work has explored the multi-draft extension, where at each step $n$ draft tokens are generated, and the verification criterion is a distribution conditioned on these. When this criterion maximizes the probability of accepting some draft token, it is called the optimal transport (OT). However, finding the OT is difficult, as it is the solution of a linear program (OTLP) in over $V^n$ variables, with $V$ being the vocabulary size. Two recent theoretical works have reframed the OTLP in terms of importance sampling or subset selection. In this work, we prove that these formulations are equivalent to an exponentially large relaxed OTLP, so it remains infeasible to solve. Then, we reverse engineer subset selection to formulate the OTLP as a max-flow problem. With a novel application of polymatroid theory, we reduce the exponentially large OTLP to a convex optimization problem in at most $V$ variables. This allows us to devise an algorithm for optimal $n$-draft speculative sampling when the $n$ tokens are chosen i.i.d. from a single draft model, which can be tuned to arbitrary accuracy. Finally, we measure acceptance rates and algorithm runtimes for various $n$ and top-$k$ draft sampling settings. Our findings give the first multi-draft algorithm with 90% acceptance and under 100 ms of overhead per generated token with negligible deviation from the target model distribution.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Rahul Krishna Thomas, Arka Pal",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Unified all-atom molecule generation with neural fields",
      "url": "https://arxiv.org/abs/2511.15906",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15906v1 Announce Type: new \nAbstract: Generative models for structure-based drug design are often limited to a specific modality, restricting their broader applicability. To address this challenge, we introduce FuncBind, a framework based on computer vision to generate target-conditioned, all-atom molecules across atomic systems. FuncBind uses neural fields to represent molecules as continuous atomic densities and employs score-based generative models with modern architectures adapted from the computer vision literature. This modality-agnostic representation allows a single unified model to be trained on diverse atomic systems, from small to large molecules, and handle variable atom/residue counts, including non-canonical amino acids. FuncBind achieves competitive in silico performance in generating small molecules, macrocyclic peptides, and antibody complementarity-determining region loops, conditioned on target structures. FuncBind also generated in vitro novel antibody binders via de novo redesign of the complementarity-determining region H3 loop of two chosen co-crystal structures. As a final contribution, we introduce a new dataset and benchmark for structure-conditioned macrocyclic peptide generation. The code is available at https://github.com/prescient-design/funcbind.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Matthieu Kirchmeyer, Pedro O. Pinheiro, Emma Willett, Karolis Martinkus, Joseph Kleinhenz, Emily K. Makowski, Andrew M. Watkins, Vladimir Gligorijevic, Richard Bonneau, Saeed Saremi",
      "tags": [
        "cs.LG",
        "q-bio.BM"
      ]
    },
    {
      "title": "AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization",
      "url": "https://arxiv.org/abs/2511.15915",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15915v1 Announce Type: new \nAbstract: We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\\%$ to $61\\%$ on Trainium 1 and from $45\\%$ to $59\\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\\times$ cheaper.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Genghan Zhang, Shaowei Zhu, Anjiang Wei, Zhenyu Song, Allen Nie, Zhen Jia, Nandita Vijaykumar, Yida Wang, Kunle Olukotun",
      "tags": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "title": "Breaking the Bottleneck with DiffuApriel: High-Throughput Diffusion LMs with Mamba Backbone",
      "url": "https://arxiv.org/abs/2511.15927",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15927v1 Announce Type: new \nAbstract: Diffusion-based language models have recently emerged as a promising alternative to autoregressive generation, yet their reliance on Transformer backbones limits inference efficiency due to quadratic attention and KV-cache overhead. In this work, we introduce DiffuApriel, a masked diffusion language model built on a bidirectional Mamba backbone that combines the diffusion objective with linear-time sequence modeling. DiffuApriel matches the performance of Transformer-based diffusion models while achieving up to 4.4x higher inference throughput for long sequences with a 1.3B model. We further propose DiffuApriel-H, a hybrid variant that interleaves attention and mamba layers, offering up to 2.6x throughput improvement with balanced global and local context modeling. Our results demonstrate that bidirectional state-space architectures serve as strong denoisers in masked diffusion LMs, providing a practical and scalable foundation for faster, memory-efficient text generation.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Vaibhav Singh, Oleksiy Ostapenko, Pierre-Andr\\'e No\\\"el, Torsten Scholak",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "iLTM: Integrated Large Tabular Model",
      "url": "https://arxiv.org/abs/2511.15941",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15941v1 Announce Type: new \nAbstract: Tabular data underpins decisions across science, industry, and public services. Despite rapid progress, advances in deep learning have not fully carried over to the tabular domain, where gradient-boosted decision trees (GBDTs) remain a default choice in practice. We present iLTM, an integrated Large Tabular Model that unifies tree-derived embeddings, dimensionality-agnostic representations, a meta-trained hypernetwork, multilayer perceptrons (MLPs), and retrieval within a single architecture. Pretrained on more than 1,800 heterogeneous classification datasets, iLTM achieves consistently superior performance across tabular classification and regression tasks, from small datasets to large and high-dimensional tasks. After light fine-tuning, the meta-trained hypernetwork transfers to regression targets, matching or surpassing strong baselines. Extensive experiments show that iLTM outperforms well-tuned GBDTs and leading deep tabular models while requiring less task-specific tuning. By bridging the gap between tree-based and neural methods, iLTM offers a new framework for tabular foundation models for robust, adaptable, and scalable tabular learning.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "David Bonet, Mar\\c{c}al Comajoan Cara, Alvaro Calafell, Daniel Mas Montserrat, Alexander G. Ioannidis",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Self-supervised and Multi-fidelity Learning for Extended Predictive Soil Spectroscopy",
      "url": "https://arxiv.org/abs/2511.15965",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15965v1 Announce Type: new \nAbstract: We propose a self-supervised machine learning (SSML) framework for multi-fidelity learning and extended predictive soil spectroscopy based on latent space embeddings. A self-supervised representation was pretrained with the large MIR spectral library and the Variational Autoencoder algorithm to obtain a compressed latent space for generating spectral embeddings. At this stage, only unlabeled spectral data were used, allowing us to leverage the full spectral database and the availability of scan repeats for augmented training. We also leveraged and froze the trained MIR decoder for a spectrum conversion task by plugging it into a NIR encoder to learn the mapping between NIR and MIR spectra in an attempt to leverage the predictive capabilities contained in the large MIR library with a low cost portable NIR scanner. This was achieved by using a smaller subset of the KSSL library with paired NIR and MIR spectra. Downstream machine learning models were then trained to map between original spectra, predicted spectra, and latent space embeddings for nine soil properties. The performance of was evaluated independently of the KSSL training data using a gold-standard test set, along with regression goodness-of-fit metrics. Compared to baseline models, the proposed SSML and its embeddings yielded similar or better accuracy in all soil properties prediction tasks. Predictions derived from the spectrum conversion (NIR to MIR) task did not match the performance of the original MIR spectra but were similar or superior to predictive performance of NIR-only models, suggesting the unified spectral latent space can effectively leverage the larger and more diverse MIR dataset for prediction of soil properties not well represented in current NIR libraries.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Luning Sun, Jos\\'e L. Safanelli, Jonathan Sanderman, Katerina Georgiou, Colby Brungard, Kanchan Grover, Bryan G. Hopkins, Shusen Liu, Timo Bremer",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Machine Learning Epidemic Predictions Using Agent-based Wireless Sensor Network Models",
      "url": "https://arxiv.org/abs/2511.15982",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15982v1 Announce Type: new \nAbstract: The lack of epidemiological data in wireless sensor networks (WSNs) is a fundamental difficulty in constructing robust models to forecast and mitigate threats such as viruses and worms. Many studies have examined different epidemic models for WSNs, focusing on how malware infections spread given the network's specific properties, including energy limits and node mobility. In this study, an agent-based implementation of the susceptible-exposed-infected-recovered-vaccinated (SEIRV) mathematical model was employed for machine learning (ML) predictions. Using tools such as NetLogo's BehaviorSpace and Python, two epidemic synthetic datasets were generated and prepared for the application of several ML algorithms. Posed as a regression problem, the infected and recovered nodes were predicted, and the performance of these algorithms is compared using the error metrics of the train and test sets. The predictions performed well, with low error metrics and high R^2 values (0.997, 1.000, 0.999, 1.000), indicating an effective fit to the training set. The validation values were lower (0.992, 0.998, 0.971, and 0.999), as is typical when evaluating model performance on unseen data. Based on the recorded performances, support vector, linear, Lasso, Ridge, and ElasticNet regression were among the worst-performing algorithms, while Random Forest, XGBoost, Decision Trees, and k-nearest neighbors achieved the best results.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Chukwunonso Henry Nwokoye, Blessing Oluchi, Sharna Waldron, Peace Ezzeh",
      "tags": [
        "cs.LG",
        "cs.NI"
      ]
    },
    {
      "title": "Descend or Rewind? Stochastic Gradient Descent Unlearning",
      "url": "https://arxiv.org/abs/2511.15983",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15983v1 Announce Type: new \nAbstract: Machine unlearning algorithms aim to remove the impact of selected training data from a model without the computational expenses of retraining from scratch. Two such algorithms are ``Descent-to-Delete\" (D2D) and ``Rewind-to-Delete\" (R2D), full-batch gradient descent algorithms that are easy to implement and satisfy provable unlearning guarantees. In particular, the stochastic version of D2D is widely implemented as the ``finetuning\" unlearning baseline, despite lacking theoretical backing on nonconvex functions. In this work, we prove $(\\epsilon, \\delta)$ certified unlearning guarantees for stochastic R2D and D2D for strongly convex, convex, and nonconvex loss functions, by analyzing unlearning through the lens of disturbed or biased gradient systems, which may be contracting, semi-contracting, or expansive respectively. Our argument relies on optimally coupling the random behavior of the unlearning and retraining trajectories, resulting in a probabilistic sensitivity bound that can be combined with a novel relaxed Gaussian mechanism to achieve $(\\epsilon, \\delta)$ unlearning. We determine that D2D can yield tighter guarantees for strongly convex functions compared to R2D by relying on contraction to a unique global minimum. However, unlike D2D, R2D can achieve unlearning in the convex and nonconvex setting because it draws the unlearned model closer to the retrained model by reversing the accumulated disturbances.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Siqiao Mu, Diego Klabjan",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Synergizing Deconfounding and Temporal Generalization For Time-series Counterfactual Outcome Estimation",
      "url": "https://arxiv.org/abs/2511.16006",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16006v1 Announce Type: new \nAbstract: Estimating counterfactual outcomes from time-series observations is crucial for effective decision-making, e.g. when to administer a life-saving treatment, yet remains significantly challenging because (i) the counterfactual trajectory is never observed and (ii) confounders evolve with time and distort estimation at every step. To address these challenges, we propose a novel framework that synergistically integrates two complementary approaches: Sub-treatment Group Alignment (SGA) and Random Temporal Masking (RTM). Instead of the coarse practice of aligning marginal distributions of the treatments in latent space, SGA uses iterative treatment-agnostic clustering to identify fine-grained sub-treatment groups. Aligning these fine-grained groups achieves improved distributional matching, thus leading to more effective deconfounding. We theoretically demonstrate that SGA optimizes a tighter upper bound on counterfactual risk and empirically verify its deconfounding efficacy. RTM promotes temporal generalization by randomly replacing input covariates with Gaussian noises during training. This encourages the model to rely less on potentially noisy or spuriously correlated covariates at the current step and more on stable historical patterns, thereby improving its ability to generalize across time and better preserve underlying causal relationships. Our experiments demonstrate that while applying SGA and RTM individually improves counterfactual outcome estimation, their synergistic combination consistently achieves state-of-the-art performance. This success comes from their distinct yet complementary roles: RTM enhances temporal generalization and robustness across time steps, while SGA improves deconfounding at each specific time point.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yiling Liu, Juncheng Dong, Chen Fu, Wei Shi, Ziyang Jiang, Zhigang Hua, David Carlson",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Physics-Guided Inductive Spatiotemporal Kriging for PM2.5 with Satellite Gradient Constraints",
      "url": "https://arxiv.org/abs/2511.16013",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16013v1 Announce Type: new \nAbstract: High-resolution mapping of fine particulate matter (PM2.5) is a cornerstone of sustainable urbanism but remains critically hindered by the spatial sparsity of ground monitoring networks. While traditional data-driven methods attempt to bridge this gap using satellite Aerosol Optical Depth (AOD), they often suffer from severe, non-random data missingness (e.g., due to cloud cover or nighttime) and inversion biases. To overcome these limitations, this study proposes the Spatiotemporal Physics-Guided Inference Network (SPIN), a novel framework designed for inductive spatiotemporal kriging. Unlike conventional approaches, SPIN synergistically integrates domain knowledge into deep learning by explicitly modeling physical advection and diffusion processes via parallel graph kernels. Crucially, we introduce a paradigm-shifting training strategy: rather than using error-prone AOD as a direct input, we repurpose it as a spatial gradient constraint within the loss function. This allows the model to learn structural pollution patterns from satellite data while remaining robust to data voids. Validated in the highly polluted Beijing-Tianjin-Hebei and Surrounding Areas (BTHSA), SPIN achieves a new state-of-the-art with a Mean Absolute Error (MAE) of 9.52 ug/m^3, effectively generating continuous, physically plausible pollution fields even in unmonitored areas. This work provides a robust, low-cost, and all-weather solution for fine-grained environmental management.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Shuo Wang, Mengfan Teng, Yun Cheng, Lothar Thiele, Olga Saukh, Shuangshuang He, Yuanting Zhang, Jiang Zhang, Gangfeng Zhang, Xingyuan Yuan, Jingfang Fan",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "CARE: Turning LLMs Into Causal Reasoning Expert",
      "url": "https://arxiv.org/abs/2511.16016",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16016v1 Announce Type: new \nAbstract: Large language models (LLMs) have recently demonstrated impressive capabilities across a range of reasoning and generation tasks. However, research studies have shown that LLMs lack the ability to identify causal relationships, a fundamental cornerstone of human intelligence. We first conduct an exploratory investigation of LLMs' behavior when asked to perform a causal-discovery task and find that they mostly rely on the semantic meaning of variable names, ignoring the observation data. This is unsurprising, given that LLMs were never trained to process structural datasets. To first tackle this challenge, we prompt the LLMs with the outputs of established causal discovery algorithms designed for observational datasets. These algorithm outputs effectively serve as the sufficient statistics of the observation data. However, quite surprisingly, we find that prompting the LLMs with these sufficient statistics decreases the LLMs' performance in causal discovery. To address this current limitation, we propose CARE, a framework that enhances LLMs' causal-reasoning ability by teaching them to effectively utilize the outputs of established causal-discovery algorithms through supervised fine-tuning. Experimental results show that a finetuned Qwen2.5-1.5B model produced by CARE significantly outperforms both traditional causal-discovery algorithms and state-of-the-art LLMs with over a thousand times more parameters, demonstrating effective utilization of its own knowledge and the external algorithmic clues.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Juncheng Dong, Yiling Liu, Ahmed Aloui, Vahid Tarokh, David Carlson",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "HGCN2SP: Hierarchical Graph Convolutional Network for Two-Stage Stochastic Programming",
      "url": "https://arxiv.org/abs/2511.16027",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16027v1 Announce Type: new \nAbstract: Two-stage Stochastic Programming (2SP) is a standard framework for modeling decision-making problems under uncertainty. While numerous methods exist, solving such problems with many scenarios remains challenging. Selecting representative scenarios is a practical method for accelerating solutions. However, current approaches typically rely on clustering or Monte Carlo sampling, failing to integrate scenario information deeply and overlooking the significant impact of the scenario order on solving time. To address these issues, we develop HGCN2SP, a novel model with a hierarchical graph designed for 2SP problems, encoding each scenario and modeling their relationships hierarchically. The model is trained in a reinforcement learning paradigm to utilize the feedback of the solver. The policy network is equipped with a hierarchical graph convolutional network for feature encoding and an attention-based decoder for scenario selection in proper order. Evaluation of two classic 2SP problems demonstrates that HGCN2SP provides high-quality decisions in a short computational time. Furthermore, HGCN2SP exhibits remarkable generalization capabilities in handling large-scale instances, even with a substantial number of variables or scenarios that were unseen during the training phase.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yang Wu, Yifan Zhang, Zhenxing Liang, Jian Cheng",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning",
      "url": "https://arxiv.org/abs/2511.16043",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16043v1 Announce Type: new \nAbstract: Large Language Model (LLM) Agents, often trained with Reinforcement Learning (RL), are constrained by a dependency on human-curated data, limiting scalability and tethering AI to human knowledge. Existing self-evolution frameworks offer an alternative but are typically restricted by the model's inherent capabilities and single-round interactions, hindering the development of complex curricula involving tool use or dynamic reasoning. We introduce Agent0, a fully autonomous framework that evolves high-performing agents without external data through multi-step co-evolution and seamless tool integration. Agent0 establishes a symbiotic competition between two agents initialized from the same base LLM: a curriculum agent that proposes increasingly challenging frontier tasks, and an executor agent that learns to solve them. We integrate external tools to enhance the executor's problem-solving capacity; this improvement, in turn, pressures the curriculum agent to construct more complex, tool-aware tasks. Through this iterative process, Agent0 establishes a self-reinforcing cycle that continuously produces high-quality curricula. Empirically, Agent0 substantially boosts reasoning capabilities, improving the Qwen3-8B-Base model by 18% on mathematical reasoning and 24% on general reasoning benchmarks. Code is available at https://github.com/aiming-lab/Agent0.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Peng Xia, Kaide Zeng, Jiaqi Liu, Can Qin, Fang Wu, Yiyang Zhou, Caiming Xiong, Huaxiu Yao",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Change-of-Basis Pruning via Rotational Invariance",
      "url": "https://arxiv.org/abs/2511.16061",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16061v1 Announce Type: new \nAbstract: Structured pruning removes entire neurons or channels, but its effectiveness depends on how importance is distributed across the representation space. Change-of-basis (CoB) pruning addresses this challenge by applying orthogonal linear transformations that concentrate importance within certain dimensions. However, many standard deep learning architectures are not inherently invariant to such transformations. To enable compatibility, we introduce two-subspace radial activations (TSRAs): an activation family that is invariant to orthogonal linear transformations applied independently within its two activation subspaces. This invariance allows CoB transformations to be merged into surrounding weights without incurring extra parameters. We position this work as a proof-of-concept that a rotationally invariant design may offer a principled approach towards change-of-basis pruning. We do not provide an analysis of multiple TSRA candidates nor do we explore weight initialization for any TSRAs. These limitations, combined with other necessary modifications we make to permit rotational invariance, result in a slight accuracy drop of $4.52\\%$ compared to a ReLU-based control. However, using activation-magnitude importance, VGG-16 implementing our CoB+TSRA framework shows encouraging results on CIFAR-10. Under fixed-ratio structured pruning, CoB improves accuracy over a TSRA baseline at all pruning ratios and extends reliable pruning frontier from roughly $30\\%$ to $70\\%$ of parameters without post-prune fine tuning. Under threshold-based pruning strategies, CoB prunes $90-96\\%$ of parameters while maintaining $1-6\\%$ accuracy drop after fine-tuning. Together, these results indicate that rotationally invariant architectures may offer a promising path towards CoB pruning.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Alex Ning, Vainateya Rangaraju",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Gauge-Equivariant Graph Networks via Self-Interference Cancellation",
      "url": "https://arxiv.org/abs/2511.16062",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16062v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) excel on homophilous graphs but often fail under heterophily due to self-reinforcing and phase-inconsistent signals. We propose a Gauge-Equivariant Graph Network with Self-Interference Cancellation (GESC), which replaces additive aggregation with a projection-based interference mechanism. Unlike prior magnetic or gauge-equivariant GNNs that typically focus on phase handling in spectral filtering while largely relying on scalar weighting, GESC introduces a $\\mathrm{U}(1)$ phase connection followed by a rank-1 projection that attenuates self-parallel components before attention. A sign- and phase-aware gate further regulates neighbor influence, attenuating components aligned with current node states and acting as a local notch on low-frequency modes. Across diverse graph benchmarks, our method consistently outperforms recent state-of-the-art models while offering a unified, interference-aware view of message passing. Our code is available at \\href{here}{https://anonymous.4open.science/r/GESC-1B22}.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yoonhyuk Choi, Chong-Kwon Kim",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "ILoRA: Federated Learning with Low-Rank Adaptation for Heterogeneous Client Aggregation",
      "url": "https://arxiv.org/abs/2511.16069",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16069v1 Announce Type: new \nAbstract: Federated Learning with Low-Rank Adaptation (LoRA) faces three critical challenges under client heterogeneity: (1) Initialization-Induced Instability due to random initialization misaligning client subspaces; (2) Rank Incompatibility and Aggregation Error when averaging LoRA parameters of different ranks, which biases the global model; and (3) exacerbated Client Drift under Non-IID Data, impairing generalization. To address these challenges, we propose ILoRA, a unified framework that integrates three core innovations: a QR-based orthonormal initialization to ensure all clients start in a coherent subspace; a Concatenated QR Aggregation mechanism that fuses heterogeneous-rank updates via concatenation and decomposition, preserving information while maintaining dimension alignment; and an AdamW optimizer with rank-aware control variates to correct local updates and mitigate client drift. Supported by theoretical convergence guarantees, extensive experiments on vision and NLP benchmarks demonstrate that ILoRA consistently achieves superior accuracy and convergence stability compared to existing federated LoRA methods.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Junchao Zhou, Junkang Liu, Fanhua Shang",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "A Mathematical Framework for Custom Reward Functions in Job Application Evaluation using Reinforcement Learning",
      "url": "https://arxiv.org/abs/2511.16073",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16073v1 Announce Type: new \nAbstract: Conventional Applicant Tracking Systems (ATS) tend to be inflexible keyword-matchers, and deny gifted candidates a role due to a few minor semantic mismatches. This article describes a new two-step process to design a more refined resume evaluation model based on a small language model (<600M parameters) that is finetuned using GRPO on a custom reward function. To begin with, Supervised Fine-Tuning (SFT) was used to build a solid baseline model. Second, this SFT model was also optimized with the help of Reinforcement Learning (RL) through GRPO under the guidance of a new, multi-component reward function that can holistically assess candidates beyond simple keyword matching. We indicate that the RL application presents a critical problem of reward hacking due to the initial experiments of aggressive penalties, which produces faulty, excessively negative model behaviors. We have overcome this challenge by refining the reward function repeatedly and training hyperparameters into a stable \"gentle polishing process\" of the reward function. Our resulting GRPO-polished model demonstrates significant real-world efficacy, achieving a final accuracy of 91% on unseen test data. The model shows a strong ability to correctly identify qualified candidates (recall of 0.85 for the 'SELECTED' class) while also showing exceptional precision (1.0), confirming its reliability. These results indicate that a properly executed, two-step fine-tuning procedure can indeed effectively refine a small language model to be able to conduct fine-tuned and human-like candidate scoring, overcoming the drawbacks of both traditional ATS and naive RL usage.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Shreyansh Jain, Madhav Singhvi, Shreya Rahul Jain, Pranav S, Dishaa Lokesh, Naren Chittibabu, Akash Anandhan",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs",
      "url": "https://arxiv.org/abs/2511.16081",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16081v1 Announce Type: new \nAbstract: Spectral GNNs, like ChebyNet, are limited by heterophily and over-smoothing due to their static, low-pass filter design. This work investigates the \"Adaptive Orthogonal Polynomial Filter\" (AOPF) class as a solution. We introduce two models operating in the [-1, 1] domain: 1) `L-JacobiNet`, the adaptive generalization of `ChebyNet` with learnable alpha, beta shape parameters, and 2) `S-JacobiNet`, a novel baseline representing a LayerNorm-stabilized static `ChebyNet`. Our analysis, comparing these models against AOPFs in the [0, infty) domain (e.g., `LaguerreNet`), reveals critical, previously unknown trade-offs. We find that the [0, infty) domain is superior for modeling heterophily, while the [-1, 1] domain (Jacobi) provides superior numerical stability at high K (K>20). Most significantly, we discover that `ChebyNet`'s main flaw is stabilization, not its static nature. Our static `S-JacobiNet` (ChebyNet+LayerNorm) outperforms the adaptive `L-JacobiNet` on 4 out of 5 benchmark datasets, identifying `S-JacobiNet` as a powerful, overlooked baseline and suggesting that adaptation in the [-1, 1] domain can lead to overfitting.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Huseyin Goksu",
      "tags": [
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "AssayMatch: Learning to Select Data for Molecular Activity Models",
      "url": "https://arxiv.org/abs/2511.16087",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16087v1 Announce Type: new \nAbstract: The performance of machine learning models in drug discovery is highly dependent on the quality and consistency of the underlying training data. Due to limitations in dataset sizes, many models are trained by aggregating bioactivity data from diverse sources, including public databases such as ChEMBL. However, this approach often introduces significant noise due to variability in experimental protocols. We introduce AssayMatch, a framework for data selection that builds smaller, more homogenous training sets attuned to the test set of interest. AssayMatch leverages data attribution methods to quantify the contribution of each training assay to model performance. These attribution scores are used to finetune language embeddings of text-based assay descriptions to capture not just semantic similarity, but also the compatibility between assays. Unlike existing data attribution methods, our approach enables data selection for a test set with unknown labels, mirroring real-world drug discovery campaigns where the activities of candidate molecules are not known in advance. At test time, embeddings finetuned with AssayMatch are used to rank all available training data. We demonstrate that models trained on data selected by AssayMatch are able to surpass the performance of the model trained on the complete dataset, highlighting its ability to effectively filter out harmful or noisy experiments. We perform experiments on two common machine learning architectures and see increased prediction capability over a strong language-only baseline for 9/12 model-target pairs. AssayMatch provides a data-driven mechanism to curate higher-quality datasets, reducing noise from incompatible experiments and improving the predictive power and data efficiency of models for drug discovery. AssayMatch is available at https://github.com/Ozymandias314/AssayMatch.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Vincent Fan, Regina Barzilay",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Mitigating Estimation Bias with Representation Learning in TD Error-Driven Regularization",
      "url": "https://arxiv.org/abs/2511.16090",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16090v1 Announce Type: new \nAbstract: Deterministic policy gradient algorithms for continuous control suffer from value estimation biases that degrade performance. While double critics reduce such biases, the exploration potential of double actors remains underexplored. Building on temporal-difference error-driven regularization (TDDR), a double actor-critic framework, this work introduces enhanced methods to achieve flexible bias control and stronger representation learning. We propose three convex combination strategies, symmetric and asymmetric, that balance pessimistic estimates to mitigate overestimation and optimistic exploration via double actors to alleviate underestimation. A single hyperparameter governs this mechanism, enabling tunable control across the bias spectrum. To further improve performance, we integrate augmented state and action representations into the actor and critic networks. Extensive experiments show that our approach consistently outperforms benchmarks, demonstrating the value of tunable bias and revealing that both overestimation and underestimation can be exploited differently depending on the environment.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Haohui Chen, Zhiyong Chen, Aoxiang Liu, Wentuo Fang",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "HybSpecNet: A Critical Analysis of Architectural Instability in Hybrid-Domain Spectral GNNs",
      "url": "https://arxiv.org/abs/2511.16101",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16101v1 Announce Type: new \nAbstract: Spectral Graph Neural Networks offer a principled approach to graph filtering but face a fundamental \"Stability-vs-Adaptivity\" trade-off. This trade-off is dictated by the choice of spectral domain. Filters in the finite [-1, 1] domain (e.g., ChebyNet) are numerically stable at high polynomial degrees (K) but are static and low-pass, causing them to fail on heterophilic graphs. Conversely, filters in the semi-infinite [0, infty) domain (e.g., KrawtchoukNet) are highly adaptive and achieve SOTA results on heterophily by learning non-low-pass responses. However, as we demonstrate, these adaptive filters can also suffer from numerical instability, leading to catastrophic performance collapse at high K. In this paper, we propose to resolve this trade-off by designing a hybrid-domain GNN, HybSpecNet, which combines a stable `ChebyNet` branch with an adaptive `KrawtchoukNet` branch. We first demonstrate that a \"naive\" hybrid architecture, which fuses the branches via concatenation, successfully unifies performance at low K, achieving strong results on both homophilic and heterophilic benchmarks. However, we then prove that this naive architecture fails the stability test. Our K-ablation experiments show that this architecture catastrophically collapses at K=25, exactly mirroring the collapse of its unstable `KrawtchoukNet` branch. We identify this critical finding as \"Instability Poisoning,\" where `NaN`/`Inf` gradients from the adaptive branch destroy the training of the model. Finally, we propose and validate an advanced architecture that uses \"Late Fusion\" to completely isolate the gradient pathways. We demonstrate that this successfully solves the instability problem, remaining perfectly stable up to K=30 while retaining its SOTA performance across all graph types. This work identifies a critical architectural pitfall in hybrid GNN design and provides the robust architectural solution.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Huseyin Goksu",
      "tags": [
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "Pathlet Variational Auto-Encoder for Robust Trajectory Generation",
      "url": "https://arxiv.org/abs/2511.16105",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16105v1 Announce Type: new \nAbstract: Trajectory generation has recently drawn growing interest in privacy-preserving urban mobility studies and location-based service applications. Although many studies have used deep learning or generative AI methods to model trajectories and have achieved promising results, the robustness and interpretability of such models are largely unexplored. This limits the application of trajectory generation algorithms on noisy real-world data and their trustworthiness in downstream tasks. To address this issue, we exploit the regular structure in urban trajectories and propose a deep generative model based on the pathlet representation, which encode trajectories with binary vectors associated with a learned dictionary of trajectory segments. Specifically, we introduce a probabilistic graphical model to describe the trajectory generation process, which includes a Variational Autoencoder (VAE) component and a linear decoder component. During training, the model can simultaneously learn the latent embedding of pathlet representations and the pathlet dictionary that captures mobility patterns in the trajectory dataset. The conditional version of our model can also be used to generate customized trajectories based on temporal and spatial constraints.\n  Our model can effectively learn data distribution even using noisy data, achieving relative improvements of $35.4\\%$ and $26.3\\%$ over strong baselines on two real-world trajectory datasets. Moreover, the generated trajectories can be conveniently utilized for multiple downstream tasks, including trajectory prediction and data denoising. Lastly, the framework design offers a significant efficiency advantage, saving $64.8\\%$ of the time and $56.5\\%$ of GPU memory compared to previous approaches.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yuanbo Tang, Yan Tang, Zixuan Zhang, Zihui Zhao, Yang Li",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "An Interpretability-Guided Framework for Responsible Synthetic Data Generation in Emotional Text",
      "url": "https://arxiv.org/abs/2511.16132",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16132v1 Announce Type: new \nAbstract: Emotion recognition from social media is critical for understanding public sentiment, but accessing training data has become prohibitively expensive due to escalating API costs and platform restrictions. We introduce an interpretability-guided framework where Shapley Additive Explanations (SHAP) provide principled guidance for LLM-based synthetic data generation. With sufficient seed data, SHAP-guided approach matches real data performance, significantly outperforms na\\\"ive generation, and substantially improves classification for underrepresented emotion classes. However, our linguistic analysis reveals that synthetic text exhibits reduced vocabulary richness and fewer personal or temporally complex expressions than authentic posts. This work provides both a practical framework for responsible synthetic data generation and a critical perspective on its limitations, underscoring that the future of trustworthy AI depends on navigating the trade-offs between synthetic utility and real-world authenticity.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Paula Joy B. Martinez, Jose Marie Antonio Mi\\~noza, Sebastian C. Iba\\~nez",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Labels Matter More Than Models: Quantifying the Benefit of Supervised Time Series Anomaly Detection",
      "url": "https://arxiv.org/abs/2511.16145",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16145v1 Announce Type: new \nAbstract: Time series anomaly detection (TSAD) is a critical data mining task often constrained by label scarcity. Consequently, current research predominantly focuses on Unsupervised Time-series Anomaly Detection (UTAD), relying on complex architectures to model normal data distributions. However, this approach often overlooks the significant performance gains available from limited anomaly labels achievable in practical scenarios. This paper challenges the premise that architectural complexity is the optimal path for TSAD. We conduct the first methodical comparison between supervised and unsupervised paradigms and introduce STAND, a streamlined supervised baseline. Extensive experiments on five public datasets demonstrate that: (1) Labels matter more than models: under a limited labeling budget, simple supervised models significantly outperform complex state-of-the-art unsupervised methods; (2) Supervision yields higher returns: the performance gain from minimal supervision far exceeds that from architectural innovations; and (3) Practicality: STAND exhibits superior prediction consistency and anomaly localization compared to unsupervised counterparts. These findings advocate for a data-centric shift in TSAD research, emphasizing label utilization over purely algorithmic complexity. The code is publicly available at https://github.com/EmorZz1G/STAND.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Zhijie Zhong, Zhiwen Yu, Kaixiang Yang, C. L. Philip Chen",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Enhancing Nuclear Reactor Core Simulation through Data-Based Surrogate Models",
      "url": "https://arxiv.org/abs/2511.16148",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16148v1 Announce Type: new \nAbstract: In recent years, there has been an increasing need for Nuclear Power Plants (NPPs) to improve flexibility in order to match the rapid growth of renewable energies. The Operator Assistance Predictive System (OAPS) developed by Framatome addresses this problem through Model Predictive Control (MPC). In this work, we aim to improve MPC methods through data-driven simulation schemes. Thus, from a set of nonlinear stiff ordinary differential equations (ODEs), this paper introduces two surrogate models acting as alternative simulation schemes to enhance nuclear reactor core simulation. We show that both data-driven and physics-informed models can rapidly integrate complex dynamics, with a very low computational time (up to 1000x time reduction).",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Perceval Beja-Battais (CB), Alain Grosset\\^ete (CB), Nicolas Vayatis (CB)",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Achieving Skilled and Reliable Daily Probabilistic Forecasts of Wind Power at Subseasonal-to-Seasonal Timescales over France",
      "url": "https://arxiv.org/abs/2511.16164",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16164v1 Announce Type: new \nAbstract: Accurate and reliable wind power forecasts are crucial for grid stability, balancing supply and demand, and market risk management. Even though short-term weather forecasts have been thoroughly used to provide short-term renewable power predictions, forecasts involving longer prediction horizons still need investigations. Despite the recent progress in subseasonal-to-seasonal weather probabilistic forecasting, their use for wind power prediction usually involves both temporal and spatial aggregation achieve reasonable skill. In this study, we present a forecasting pipeline enabling to transform ECMWF subseasonal-to-seasonal weather forecasts into wind power forecasts for lead times ranging from 1 day to 46 days at daily resolution. This framework also include post-processing of the resulting power ensembles to account for the biases and lack of dispersion of the weather forecasts. We show that our method is able to outperform a climatological baseline by 50 % in terms of both Continuous Ranked Probability Skill Score and Ensemble Mean Squared Error while also providing near perfect calibration of the forecasts for lead times ranging from 15 to 46 days.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Eloi Lindas, Yannig Goude, Philippe Ciais",
      "tags": [
        "cs.LG",
        "stat.AP"
      ]
    },
    {
      "title": "CausalMamba: Interpretable State Space Modeling for Temporal Rumor Causality",
      "url": "https://arxiv.org/abs/2511.16191",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16191v1 Announce Type: new \nAbstract: Rumor detection on social media remains a challenging task due to the complex propagation dynamics and the limited interpretability of existing models. While recent neural architectures capture content and structural features, they often fail to reveal the underlying causal mechanisms of misinformation spread. We propose CausalMamba, a novel framework that integrates Mamba-based sequence modeling, graph convolutional networks (GCNs), and differentiable causal discovery via NOTEARS. CausalMamba learns joint representations of temporal tweet sequences and reply structures, while uncovering latent causal graphs to identify influential nodes within each propagation chain. Experiments on the Twitter15 dataset show that our model achieves competitive classification performance compared to strong baselines, and uniquely enables counterfactual intervention analysis. Qualitative results demonstrate that removing top-ranked causal nodes significantly alters graph connectivity, offering interpretable insights into rumor dynamics. Our framework provides a unified approach for rumor classification and influence analysis, paving the way for more explainable and actionable misinformation detection systems.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Xiaotong Zhan, Xi Cheng",
      "tags": [
        "cs.LG",
        "cs.SI"
      ]
    },
    {
      "title": "A Switching Framework for Online Interval Scheduling with Predictions",
      "url": "https://arxiv.org/abs/2511.16194",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16194v1 Announce Type: new \nAbstract: We study online interval scheduling in the irrevocable setting, where each interval must be immediately accepted or rejected upon arrival. The objective is to maximize the total length of accepted intervals while ensuring that no two accepted intervals overlap. We consider this problem in a learning-augmented setting, where the algorithm has access to (machine-learned) predictions. The goal is to design algorithms that leverage these predictions to improve performance while maintaining robust guarantees in the presence of prediction errors.\n  Our main contribution is the SemiTrust-and-Switch framework, which provides a unified approach for combining prediction-based and classical interval scheduling algorithms. This framework applies to both deterministic and randomized algorithms and captures the trade-off between consistency (performance under accurate predictions) and robustness (performance under adversarial inputs). Moreover, we provide lower bounds, proving the tightness of this framework in particular settings.\n  We further design a randomized algorithm that smoothly interpolates between prediction-based and robust algorithms. This algorithm achieves both robustness and smoothness--its performance degrades gracefully with the quality of the prediction.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Antonios Antoniadis, Ali Shahheidar, Golnoosh Shahkarami, Abolfazl Soltani",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Causal Synthetic Data Generation in Recruitment",
      "url": "https://arxiv.org/abs/2511.16204",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16204v1 Announce Type: new \nAbstract: The importance of Synthetic Data Generation (SDG) has increased significantly in domains where data quality is poor or access is limited due to privacy and regulatory constraints. One such domain is recruitment, where publicly available datasets are scarce due to the sensitive nature of information typically found in curricula vitae, such as gender, disability status, or age. %\nThis lack of accessible, representative data presents a significant obstacle to the development of fair and transparent machine learning models, particularly ranking algorithms that require large volumes of data to effectively learn how to recommend candidates. In the absence of such data, these models are prone to poor generalisation and may fail to perform reliably in real-world scenarios. %\nRecent advances in Causal Generative Models (CGMs) offer a promising solution. CGMs enable the generation of synthetic datasets that preserve the underlying causal relationships within the data, providing greater control over fairness and interpretability in the data generation process. %\nIn this study, we present a specialised SDG method involving two CGMs: one modelling job offers and the other modelling curricula. Each model is structured according to a causal graph informed by domain expertise. We use these models to generate synthetic datasets and evaluate the fairness of candidate rankings under controlled scenarios that introduce specific biases.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Andrea Iommi, Antonio Mastropietro, Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri",
      "tags": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Towards Overcoming Data Scarcity in Nuclear Energy: A Study on Critical Heat Flux with Physics-consistent Conditional Diffusion Model",
      "url": "https://arxiv.org/abs/2511.16207",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16207v1 Announce Type: new \nAbstract: Deep generative modeling provides a powerful pathway to overcome data scarcity in energy-related applications where experimental data are often limited, costly, or difficult to obtain. By learning the underlying probability distribution of the training dataset, deep generative models, such as the diffusion model (DM), can generate high-fidelity synthetic samples that statistically resemble the training data. Such synthetic data generation can significantly enrich the size and diversity of the available training data, and more importantly, improve the robustness of downstream machine learning models in predictive tasks. The objective of this paper is to investigate the effectiveness of DM for overcoming data scarcity in nuclear energy applications. By leveraging a public dataset on critical heat flux (CHF) that cover a wide range of commercial nuclear reactor operational conditions, we developed a DM that can generate an arbitrary amount of synthetic samples for augmenting of the CHF dataset. Since a vanilla DM can only generate samples randomly, we also developed a conditional DM capable of generating targeted CHF data under user-specified thermal-hydraulic conditions. The performance of the DM was evaluated based on their ability to capture empirical feature distributions and pair-wise correlations, as well as to maintain physical consistency. The results showed that both the DM and conditional DM can successfully generate realistic and physics-consistent CHF data. Furthermore, uncertainty quantification was performed to establish confidence in the generated data. The results demonstrated that the conditional DM is highly effective in augmenting CHF data while maintaining acceptable levels of uncertainty.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Farah Alsafadi, Alexandra Akins, Xu Wu",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Mind the Gap: Bridging Prior Shift in Realistic Few-Shot Crop-Type Classification",
      "url": "https://arxiv.org/abs/2511.16218",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16218v1 Announce Type: new \nAbstract: Real-world agricultural distributions often suffer from severe class imbalance, typically following a long-tailed distribution. Labeled datasets for crop-type classification are inherently scarce and remain costly to obtain. When working with such limited data, training sets are frequently constructed to be artificially balanced -- in particular in the case of few-shot learning -- failing to reflect real-world conditions. This mismatch induces a shift between training and test label distributions, degrading real-world generalization. To address this, we propose Dirichlet Prior Augmentation (DirPA), a novel method that simulates an unknown label distribution skew of the target domain proactively during model training. Specifically, we model the real-world distribution as Dirichlet-distributed random variables, effectively performing a prior augmentation during few-shot learning. Our experiments show that DirPA successfully shifts the decision boundary and stabilizes the training process by acting as a dynamic feature regularizer.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Joana Reuss, Ekaterina Gikalo, Marco K\\\"orner",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Real-Time Inference for Distributed Multimodal Systems under Communication Delay Uncertainty",
      "url": "https://arxiv.org/abs/2511.16225",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16225v1 Announce Type: new \nAbstract: Connected cyber-physical systems perform inference based on real-time inputs from multiple data streams. Uncertain communication delays across data streams challenge the temporal flow of the inference process. State-of-the-art (SotA) non-blocking inference methods rely on a reference-modality paradigm, requiring one modality input to be fully received before processing, while depending on costly offline profiling. We propose a novel, neuro-inspired non-blocking inference paradigm that primarily employs adaptive temporal windows of integration (TWIs) to dynamically adjust to stochastic delay patterns across heterogeneous streams while relaxing the reference-modality requirement. Our communication-delay-aware framework achieves robust real-time inference with finer-grained control over the accuracy-latency tradeoff. Experiments on the audio-visual event localization (AVEL) task demonstrate superior adaptability to network dynamics compared to SotA approaches.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Victor Croisfelt, Jo\\~ao Henrique Inacio de Souza, Shashi Raj Pandey, Beatriz Soret, Petar Popovski",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Deep SOR Minimax Q-learning for Two-player Zero-sum Game",
      "url": "https://arxiv.org/abs/2511.16226",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16226v1 Announce Type: new \nAbstract: In this work, we consider the problem of a two-player zero-sum game. In the literature, the successive over-relaxation Q-learning algorithm has been developed and implemented, and it is seen to result in a lower contraction factor for the associated Q-Bellman operator resulting in a faster value iteration-based procedure. However, this has been presented only for the tabular case and not for the setting with function approximation that typically caters to real-world high-dimensional state-action spaces. Furthermore, such settings in the case of two-player zero-sum games have not been considered. We thus propose a deep successive over-relaxation minimax Q-learning algorithm that incorporates deep neural networks as function approximators and is suitable for high-dimensional spaces. We prove the finite-time convergence of the proposed algorithm. Through numerical experiments, we show the effectiveness of the proposed method over the existing Q-learning algorithm. Our ablation studies demonstrate the effect of different values of the crucial successive over-relaxation parameter.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Saksham Gautam, Lakshmi Mandal, Shalabh Bhatnagar",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Pass@k Metric for RLVR: A Diagnostic Tool of Exploration, But Not an Objective",
      "url": "https://arxiv.org/abs/2511.16231",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16231v1 Announce Type: new \nAbstract: The ability of Large Language Models (LLMs) to perform complex, multi-step reasoning is a central focus of modern AI research. To evaluate and enhance this capability, the pass@k metric, which measures the probability of obtaining at least one correct solution in k independent samples, has received significant attention. Its intuitive appeal has led to its adoption not only as an evaluation standard but also as a direct optimization objective in reinforcement learning. In this paper, we analyze the pass@k objective, derive its gradient, and demonstrate that it is fundamentally a per-example positive reweighting of the simpler pass@1 objective. Our analysis reveals that the pass@k objective provides a vanishing learning signal in regimes where exploration is most critical. We further analyze the dynamics of \"exploration collapse\", showing that as the policy concentrates probability mass, the gap between pass@k and pass@1 diminishes. We conclude that while pass@k is a useful diagnostic tool, it may be an unsuitable direct objective for optimization. Instead, mechanisms explicitly encouraging efficient exploration could offer a more effective path forward for reinforcement learning in reasoning tasks.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yang Yu",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "GeoPTH: A Lightweight Approach to Category-Based Trajectory Retrieval via Geometric Prototype Trajectory Hashing",
      "url": "https://arxiv.org/abs/2511.16258",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16258v1 Announce Type: new \nAbstract: Trajectory similarity retrieval is an important part of spatiotemporal data mining, however, existing methods have the following limitations: traditional metrics are computationally expensive, while learning-based methods suffer from substantial training costs and potential instability. This paper addresses these problems by proposing \\textbf{Geo}metric \\textbf{P}rototype \\textbf{T}rajectory \\textbf{H}ashing (GeoPTH), a novel, lightweight, and non-learning framework for efficient category-based trajectory retrieval. GeoPTH constructs data-dependent hash functions by using representative trajectory prototypes, i.e., small point sets preserving geometric characteristics, as anchors. The hashing process is efficient, which involves mapping a new trajectory to its closest prototype via a robust, \\textit{Hausdorff} metric. Extensive experiments show that GeoPTH's retrieval accuracy is highly competitive with both traditional metrics and state-of-the-art learning methods, and it significantly outperforms binary codes generated through simple binarization of the learned embeddings. Critically, GeoPTH consistently outperforms all competitors in terms of efficiency. Our work demonstrates that a lightweight, prototype-centric approach offers a practical and powerful alternative, achieving an exceptional retrieval performance and computational efficiency.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yang Xu, Zuliang Yang, Kai Ming Ting",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Graph Diffusion Counterfactual Explanation",
      "url": "https://arxiv.org/abs/2511.16287",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16287v1 Announce Type: new \nAbstract: Machine learning models that operate on graph-structured data, such as molecular graphs or social networks, often make accurate predictions but offer little insight into why certain predictions are made. Counterfactual explanations address this challenge by seeking the closest alternative scenario where the model's prediction would change. Although counterfactual explanations are extensively studied in tabular data and computer vision, the graph domain remains comparatively underexplored. Constructing graph counterfactuals is intrinsically difficult because graphs are discrete and non-euclidean objects. We introduce Graph Diffusion Counterfactual Explanation, a novel framework for generating counterfactual explanations on graph data, combining discrete diffusion models and classifier-free guidance. We empirically demonstrate that our method reliably generates in-distribution as well as minimally structurally different counterfactuals for both discrete classification targets and continuous properties.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "David Bechtoldt, Sidney Bender",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Optimizing Operation Recipes with Reinforcement Learning for Safe and Interpretable Control of Chemical Processes",
      "url": "https://arxiv.org/abs/2511.16297",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16297v1 Announce Type: new \nAbstract: Optimal operation of chemical processes is vital for energy, resource, and cost savings in chemical engineering. The problem of optimal operation can be tackled with reinforcement learning, but traditional reinforcement learning methods face challenges due to hard constraints related to quality and safety that must be strictly satisfied, and the large amount of required training data. Chemical processes often cannot provide sufficient experimental data, and while detailed dynamic models can be an alternative, their complexity makes it computationally intractable to generate the needed data. Optimal control methods, such as model predictive control, also struggle with the complexity of the underlying dynamic models. Consequently, many chemical processes rely on manually defined operation recipes combined with simple linear controllers, leading to suboptimal performance and limited flexibility.\n  In this work, we propose a novel approach that leverages expert knowledge embedded in operation recipes. By using reinforcement learning to optimize the parameters of these recipes and their underlying linear controllers, we achieve an optimized operation recipe. This method requires significantly less data, handles constraints more effectively, and is more interpretable than traditional reinforcement learning methods due to the structured nature of the recipes. We demonstrate the potential of our approach through simulation results of an industrial batch polymerization reactor, showing that it can approach the performance of optimal controllers while addressing the limitations of existing methods.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Dean Brandner, Sergio Lucia",
      "tags": [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Learning-Enhanced Observer for Linear Time-Invariant Systems with Parametric Uncertainty",
      "url": "https://arxiv.org/abs/2511.16318",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16318v1 Announce Type: new \nAbstract: This work introduces a learning-enhanced observer (LEO) for linear time-invariant systems with uncertain dynamics. Rather than relying solely on nominal models, the proposed framework treats the system matrices as optimizable variables and refines them through gradient-based minimization of a steady-state output discrepancy loss. The resulting data-informed surrogate model enables the construction of an improved observer that effectively compensates for moderate parameter uncertainty while preserving the structure of classical designs. Extensive Monte Carlo studies across diverse system dimensions show systematic and statistically significant reductions, typically exceeding 15\\%, in normalized estimation error for both open-loop and Luenberger observers. These results demonstrate that modern learning mechanisms can serve as a powerful complement to traditional observer design, yielding more accurate and robust state estimation in uncertain systems. Codes are available at https://github.com/Hao-B-Shu/LTI_LEO.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Hao Shu",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning",
      "url": "https://arxiv.org/abs/2511.16333",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16333v1 Announce Type: new \nAbstract: Healthcare requires AI that is predictive, reliable, and data-efficient. However, recent generative models lack physical foundation and temporal reasoning required for clinical decision support. As scaling language models show diminishing returns for grounded clinical reasoning, world models are gaining traction because they learn multimodal, temporally coherent, and action-conditioned representations that reflect the physical and causal structure of care. This paper reviews World Models for healthcare systems that learn predictive dynamics to enable multistep rollouts, counterfactual evaluation and planning. We survey recent work across three domains: (i) medical imaging and diagnostics (e.g., longitudinal tumor simulation, projection-transition modeling, and Joint Embedding Predictive Architecture i.e., JEPA-style predictive representation learning), (ii) disease progression modeling from electronic health records (generative event forecasting at scale), and (iii) robotic surgery and surgical planning (action-conditioned guidance and control). We also introduce a capability rubric: L1 temporal prediction, L2 action-conditioned prediction, L3 counterfactual rollouts for decision support, and L4 planning/control. Most reviewed systems achieve L1--L2, with fewer instances of L3 and rare L4. We identify cross-cutting gaps that limit clinical reliability; under-specified action spaces and safety constraints, weak interventional validation, incomplete multimodal state construction, and limited trajectory-level uncertainty calibration. This review outlines a research agenda for clinically robust prediction-first world models that integrate generative backbones (transformers, diffusion, VAE) with causal/mechanical foundation for safe decision support in healthcare.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Mohammad Areeb Qazi, Maryam Nadeem, Mohammad Yaqub",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Improving Iterative Gaussian Processes via Warm Starting Sequential Posteriors",
      "url": "https://arxiv.org/abs/2511.16340",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16340v1 Announce Type: new \nAbstract: Scalable Gaussian process (GP) inference is essential for sequential decision-making tasks, yet improving GP scalability remains a challenging problem with many open avenues of research. This paper focuses on iterative GPs, where iterative linear solvers, such as conjugate gradients, stochastic gradient descent or alternative projections, are used to approximate the GP posterior. We propose a new method which improves solver convergence of a large linear system by leveraging the known solution to a smaller system contained within. This is significant for tasks with incremental data additions, and we show that our technique achieves speed-ups when solving to tolerance, as well as improved Bayesian optimisation performance under a fixed compute budget.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Alan Yufei Dong, Jihao Andreas Lin, Jos\\'e Miguel Hern\\'andez-Lobato",
      "tags": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Are Foundation Models Useful for Bankruptcy Prediction?",
      "url": "https://arxiv.org/abs/2511.16375",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16375v1 Announce Type: new \nAbstract: Foundation models have shown promise across various financial applications, yet their effectiveness for corporate bankruptcy prediction remains systematically unevaluated against established methods. We study bankruptcy forecasting using Llama-3.3-70B-Instruct and TabPFN, evaluated on large, highly imbalanced datasets of over one million company records from the Visegr\\'ad Group. We provide the first systematic comparison of foundation models against classical machine learning baselines for this task. Our results show that models such as XGBoost and CatBoost consistently outperform foundation models across all prediction horizons. LLM-based approaches suffer from unreliable probability estimates, undermining their use in risk-sensitive financial settings. TabPFN, while competitive with simpler baselines, requires substantial computational resources with costs not justified by performance gains. These findings suggest that, despite their generality, current foundation models remain less effective than specialized methods for bankruptcy forecasting.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Marcin Kostrzewa, Oleksii Furman, Roman Furman, Sebastian Tomczak, Maciej Zi\\k{e}ba",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Optimal Fairness under Local Differential Privacy",
      "url": "https://arxiv.org/abs/2511.16377",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16377v1 Announce Type: new \nAbstract: We investigate how to optimally design local differential privacy (LDP) mechanisms that reduce data unfairness and thereby improve fairness in downstream classification. We first derive a closed-form optimal mechanism for binary sensitive attributes and then develop a tractable optimization framework that yields the corresponding optimal mechanism for multi-valued attributes. As a theoretical contribution, we establish that for discrimination-accuracy optimal classifiers, reducing data unfairness necessarily leads to lower classification unfairness, thus providing a direct link between privacy-aware pre-processing and classification fairness. Empirically, we demonstrate that our approach consistently outperforms existing LDP mechanisms in reducing data unfairness across diverse datasets and fairness metrics, while maintaining accuracy close to that of non-private models. Moreover, compared with leading pre-processing and post-processing fairness methods, our mechanism achieves a more favorable accuracy-fairness trade-off while simultaneously preserving the privacy of sensitive attributes. Taken together, these results highlight LDP as a principled and effective pre-processing fairness intervention technique.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Hrad Ghoukasian, Shahab Asoodeh",
      "tags": [
        "cs.LG",
        "cs.CR",
        "stat.ML"
      ]
    },
    {
      "title": "Collaborative Management for Chronic Diseases and Depression: A Double Heterogeneity-based Multi-Task Learning Method",
      "url": "https://arxiv.org/abs/2511.16398",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16398v1 Announce Type: new \nAbstract: Wearable sensor technologies and deep learning are transforming healthcare management. Yet, most health sensing studies focus narrowly on physical chronic diseases. This overlooks the critical need for joint assessment of comorbid physical chronic diseases and depression, which is essential for collaborative chronic care. We conceptualize multi-disease assessment, including both physical diseases and depression, as a multi-task learning (MTL) problem, where each disease assessment is modeled as a task. This joint formulation leverages inter-disease relationships to improve accuracy, but it also introduces the challenge of double heterogeneity: chronic diseases differ in their manifestation (disease heterogeneity), and patients with the same disease show varied patterns (patient heterogeneity). To address these issues, we first adopt existing techniques and propose a base method. Given the limitations of the base method, we further propose an Advanced Double Heterogeneity-based Multi-Task Learning (ADH-MTL) method that improves the base method through three innovations: (1) group-level modeling to support new patient predictions, (2) a decomposition strategy to reduce model complexity, and (3) a Bayesian network that explicitly captures dependencies while balancing similarities and differences across model components. Empirical evaluations on real-world wearable sensor data demonstrate that ADH-MTL significantly outperforms existing baselines, and each of its innovations is shown to be effective. This study contributes to health information systems by offering a computational solution for integrated physical and mental healthcare and provides design principles for advancing collaborative chronic disease management across the pre-treatment, treatment, and post-treatment phases.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yidong Chai, Haoxin Liu, Jiaheng Xie, Chaopeng Wang, Xiao Fang",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FreqFlow: Long-term forecasting using lightweight flow matching",
      "url": "https://arxiv.org/abs/2511.16426",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16426v1 Announce Type: new \nAbstract: Multivariate time-series (MTS) forecasting is fundamental to applications ranging from urban mobility and resource management to climate modeling. While recent generative models based on denoising diffusion have advanced state-of-the-art performance in capturing complex data distributions, they suffer from significant computational overhead due to iterative stochastic sampling procedures that limit real-time deployment. Moreover, these models can be brittle when handling high-dimensional, non-stationary, and multi-scale periodic patterns characteristic of real-world sensor networks. We introduce FreqFlow, a novel framework that leverages conditional flow matching in the frequency domain for deterministic MTS forecasting. Unlike conventional approaches that operate in the time domain, FreqFlow transforms the forecasting problem into the spectral domain, where it learns to model amplitude and phase shifts through a single complex-valued linear layer. This frequency-domain formulation enables the model to efficiently capture temporal dynamics via complex multiplication, corresponding to scaling and temporal translations. The resulting architecture is exceptionally lightweight with only 89k parameters - an order of magnitude smaller than competing diffusion-based models-while enabling single-pass deterministic sampling through ordinary differential equation (ODE) integration. Our approach decomposes MTS signals into trend, seasonal, and residual components, with the flow matching mechanism specifically designed for residual learning to enhance long-term forecasting accuracy. Extensive experiments on real-world traffic speed, volume, and flow datasets demonstrate that FreqFlow achieves state-of-the-art forecasting performance, on average 7\\% RMSE improvements, while being significantly faster and more parameter-efficient than existing methods",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Seyed Mohamad Moghadas, Bruno Cornelis, Adrian Munteanu",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations",
      "url": "https://arxiv.org/abs/2511.16427",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16427v1 Announce Type: new \nAbstract: Clinical time series data from electronic health records and medical registries offer unprecedented opportunities to understand patient trajectories and inform medical decision-making. However, leveraging such data presents significant challenges due to irregular sampling, complex latent physiology, and inherent uncertainties in both measurements and disease progression. To address these challenges, we propose a generative modeling framework based on latent neural stochastic differential equations (SDEs) that views clinical time series as discrete-time partial observations of an underlying controlled stochastic dynamical system. Our approach models latent dynamics via neural SDEs with modality-dependent emission models, while performing state estimation and parameter learning through variational inference. This formulation naturally handles irregularly sampled observations, learns complex non-linear interactions, and captures the stochasticity of disease progression and measurement noise within a unified scalable probabilistic framework. We validate the framework on two complementary tasks: (i) individual treatment effect estimation using a simulated pharmacokinetic-pharmacodynamic (PKPD) model of lung cancer, and (ii) probabilistic forecasting of physiological signals using real-world intensive care unit (ICU) data from 12,000 patients. Results show that our framework outperforms ordinary differential equation and long short-term memory baseline models in accuracy and uncertainty estimation. These results highlight its potential for enabling precise, uncertainty-aware predictions to support clinical decision-making.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Muhammad Aslanimoghanloo, Ahmed ElGazzar, Marcel van Gerven",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Comparison Between Decision Transformers and Traditional Offline Reinforcement Learning Algorithms",
      "url": "https://arxiv.org/abs/2511.16475",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16475v1 Announce Type: new \nAbstract: The field of Offline Reinforcement Learning (RL) aims to derive effective policies from pre-collected datasets without active environment interaction. While traditional offline RL algorithms like Conservative Q-Learning (CQL) and Implicit Q-Learning (IQL) have shown promise, they often face challenges in balancing exploration and exploitation, especially in environments with varying reward densities. The recently proposed Decision Transformer (DT) approach, which reframes offline RL as a sequence modelling problem, has demonstrated impressive results across various benchmarks. This paper presents a comparative study evaluating the performance of DT against traditional offline RL algorithms in dense and sparse reward settings for the ANT continous control environment. Our research investigates how these algorithms perform when faced with different reward structures, examining their ability to learn effective policies and generalize across varying levels of feedback. Through empirical analysis in the ANT environment, we found that DTs showed less sensitivity to varying reward density compared to other methods and particularly excelled with medium-expert datasets in sparse reward scenarios. In contrast, traditional value-based methods like IQL showed improved performance in dense reward settings with high-quality data, while CQL offered balanced performance across different data qualities. Additionally, DTs exhibited lower variance in performance but required significantly more computational resources compared to traditional approaches. These findings suggest that sequence modelling approaches may be more suitable for scenarios with uncertain reward structures or mixed-quality data, while value-based methods remain competitive in settings with dense rewards and high-quality demonstrations.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Ali Murtaza Caunhye, Asad Jeewa",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Limitations of Scalarisation in MORL: A Comparative Study in Discrete Environments",
      "url": "https://arxiv.org/abs/2511.16476",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16476v1 Announce Type: new \nAbstract: Scalarisation functions are widely employed in MORL algorithms to enable intelligent decision-making. However, these functions often struggle to approximate the Pareto front accurately, rendering them unideal in complex, uncertain environments. This study examines selected Multi-Objective Reinforcement Learning (MORL) algorithms across MORL environments with discrete action and observation spaces. We aim to investigate further the limitations associated with scalarisation approaches for decision-making in multi-objective settings. Specifically, we use an outer-loop multi-policy methodology to assess the performance of a seminal single-policy MORL algorithm, MO Q-Learning implemented with linear scalarisation and Chebyshev scalarisation functions. In addition, we explore a pioneering inner-loop multi-policy algorithm, Pareto Q-Learning, which offers a more robust alternative. Our findings reveal that the performance of the scalarisation functions is highly dependent on the environment and the shape of the Pareto front. These functions often fail to retain the solutions uncovered during learning and favour finding solutions in certain regions of the solution space. Moreover, finding the appropriate weight configurations to sample the entire Pareto front is complex, limiting their applicability in uncertain settings. In contrast, inner-loop multi-policy algorithms may provide a more sustainable and generalizable approach and potentially facilitate intelligent decision-making in dynamic and uncertain environments.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Muhammad Sa'ood Shah, Asad Jeewa",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Correlation-Aware Feature Attribution Based Explainable AI",
      "url": "https://arxiv.org/abs/2511.16482",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16482v1 Announce Type: new \nAbstract: Explainable AI (XAI) is increasingly essential as modern models become more complex and high-stakes applications demand transparency, trust, and regulatory compliance. Existing global attribution methods often incur high computational costs, lack stability under correlated inputs, and fail to scale efficiently to large or heterogeneous datasets. We address these gaps with \\emph{ExCIR} (Explainability through Correlation Impact Ratio), a correlation-aware attribution score equipped with a lightweight transfer protocol that reproduces full-model rankings using only a fraction of the data. ExCIR quantifies sign-aligned co-movement between features and model outputs after \\emph{robust centering} (subtracting a robust location estimate, e.g., median or mid-mean, from features and outputs). We further introduce \\textsc{BlockCIR}, a \\emph{groupwise} extension of ExCIR that scores \\emph{sets} of correlated features as a single unit. By aggregating the same signed-co-movement numerators and magnitudes over predefined or data-driven groups, \\textsc{BlockCIR} mitigates double-counting in collinear clusters (e.g., synonyms or duplicated sensors) and yields smoother, more stable rankings when strong dependencies are present. Across diverse text, tabular, signal, and image datasets, ExCIR shows trustworthy agreement with established global baselines and the full model, delivers consistent top-$k$ rankings across settings, and reduces runtime via lightweight evaluation on a subset of rows. Overall, ExCIR provides \\emph{computationally efficient}, \\emph{consistent}, and \\emph{scalable} explainability for real-world deployment.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Poushali Sengupta, Yan Zhang, Frank Eliassen, Sabita Maharjan",
      "tags": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Large Language Model-Based Reward Design for Deep Reinforcement Learning-Driven Autonomous Cyber Defense",
      "url": "https://arxiv.org/abs/2511.16483",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16483v1 Announce Type: new \nAbstract: Designing rewards for autonomous cyber attack and defense learning agents in a complex, dynamic environment is a challenging task for subject matter experts. We propose a large language model (LLM)-based reward design approach to generate autonomous cyber defense policies in a deep reinforcement learning (DRL)-driven experimental simulation environment. Multiple attack and defense agent personas were crafted, reflecting heterogeneity in agent actions, to generate LLM-guided reward designs where the LLM was first provided with contextual cyber simulation environment information. These reward structures were then utilized within a DRL-driven attack-defense simulation environment to learn an ensemble of cyber defense policies. Our results suggest that LLM-guided reward designs can lead to effective defense strategies against diverse adversarial behaviors.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Sayak Mukherjee, Samrat Chatterjee, Emilie Purvine, Ted Fujimoto, Tegan Emerson",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "ODE-ViT: Plug & Play Attention Layer from the Generalization of the ViT as an Ordinary Differential Equation",
      "url": "https://arxiv.org/abs/2511.16501",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16501v1 Announce Type: new \nAbstract: In recent years, increasingly large models have achieved outstanding performance across CV tasks. However, these models demand substantial computational resources and storage, and their growing complexity limits our understanding of how they make decisions. Most of these architectures rely on the attention mechanism within Transformer-based designs. Building upon the connection between residual neural networks and ordinary differential equations (ODEs), we introduce ODE-ViT, a Vision Transformer reformulated as an ODE system that satisfies the conditions for well-posed and stable dynamics. Experiments on CIFAR-10 and CIFAR-100 demonstrate that ODE-ViT achieves stable, interpretable, and competitive performance with up to one order of magnitude fewer parameters, surpassing prior ODE-based Transformer approaches in classification tasks. We further propose a plug-and-play teacher-student framework in which a discrete ViT guides the continuous trajectory of ODE-ViT by treating the intermediate representations of the teacher as solutions of the ODE. This strategy improves performance by more than 10% compared to training a free ODE-ViT from scratch.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Carlos Boned Riera, David Romero Sanchez, Oriol Ramos Terrades",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Loss Functions Robust to the Presence of Label Errors",
      "url": "https://arxiv.org/abs/2511.16512",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16512v1 Announce Type: new \nAbstract: Methods for detecting label errors in training data require models that are robust to label errors (i.e., not fit to erroneously labelled data points). However, acquiring such models often involves training on corrupted data, which presents a challenge. Adjustments to the loss function present an opportunity for improvement. Motivated by Focal Loss (which emphasizes difficult-to-classify samples), two novel, yet simple, loss functions are proposed that de-weight or ignore these difficult samples (i.e., those likely to have label errors). Results on artificially corrupted data show promise, such that F1 scores for detecting errors are improved from the baselines of conventional categorical Cross Entropy and Focal Loss.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Nicholas Pellegrino, David Szczecina, Paul Fieguth",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Saving Foundation Flow-Matching Priors for Inverse Problems",
      "url": "https://arxiv.org/abs/2511.16520",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16520v1 Announce Type: new \nAbstract: Foundation flow-matching (FM) models promise a universal prior for solving inverse problems (IPs), yet today they trail behind domain-specific or even untrained priors. How can we unlock their potential? We introduce FMPlug, a plug-in framework that redefines how foundation FMs are used in IPs. FMPlug combines an instance-guided, time-dependent warm-start strategy with a sharp Gaussianity regularization, adding problem-specific guidance while preserving the Gaussian structures. This leads to a significant performance boost across image restoration and scientific IPs. Our results point to a path for making foundation FM models practical, reusable priors for IP solving.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yuxiang Wan, Ryan Devera, Wenjie Zhang, Ju Sun",
      "tags": [
        "cs.LG",
        "eess.IV"
      ]
    },
    {
      "title": "Dynamic Participation in Federated Learning: Benchmarks and a Knowledge Pool Plugin",
      "url": "https://arxiv.org/abs/2511.16523",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16523v1 Announce Type: new \nAbstract: Federated learning (FL) enables clients to collaboratively train a shared model in a distributed manner, setting it apart from traditional deep learning paradigms. However, most existing FL research assumes consistent client participation, overlooking the practical scenario of dynamic participation (DPFL), where clients may intermittently join or leave during training. Moreover, no existing benchmarking framework systematically supports the study of DPFL-specific challenges. In this work, we present the first open-source framework explicitly designed for benchmarking FL models under dynamic client participation. Our framework provides configurable data distributions, participation patterns, and evaluation metrics tailored to DPFL scenarios. Using this platform, we benchmark four major categories of widely adopted FL models and uncover substantial performance degradation under dynamic participation. To address these challenges, we further propose Knowledge-Pool Federated Learning (KPFL), a generic plugin that maintains a shared knowledge pool across both active and idle clients. KPFL leverages dual-age and data-bias weighting, combined with generative knowledge distillation, to mitigate instability and prevent knowledge loss. Extensive experiments demonstrate the significant impact of dynamic participation on FL performance and the effectiveness of KPFL in improving model robustness and generalization.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Ming-Lun Lee, Fu-Shiang Yang, Cheng-Kuan Lin, Yan-Ann Chen, Chih-Yu Lin, Yu-Chee Tseng",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "FairLRF: Achieving Fairness through Sparse Low Rank Factorization",
      "url": "https://arxiv.org/abs/2511.16549",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16549v1 Announce Type: new \nAbstract: As deep learning (DL) techniques become integral to various applications, ensuring model fairness while maintaining high performance has become increasingly critical, particularly in sensitive fields such as medical diagnosis. Although a variety of bias-mitigation methods have been proposed, many rely on computationally expensive debiasing strategies or suffer substantial drops in model accuracy, which limits their practicality in real-world, resource-constrained settings. To address this issue, we propose a fairness-oriented low rank factorization (LRF) framework that leverages singular value decomposition (SVD) to improve DL model fairness. Unlike traditional SVD, which is mainly used for model compression by decomposing and reducing weight matrices, our work shows that SVD can also serve as an effective tool for fairness enhancement. Specifically, we observed that elements in the unitary matrices obtained from SVD contribute unequally to model bias across groups defined by sensitive attributes. Motivated by this observation, we propose a method, named FairLRF, that selectively removes bias-inducing elements from unitary matrices to reduce group disparities, thus enhancing model fairness. Extensive experiments show that our method outperforms conventional LRF methods as well as state-of-the-art fairness-enhancing techniques. Additionally, an ablation study examines how major hyper-parameters may influence the performance of processed models. To the best of our knowledge, this is the first work utilizing SVD not primarily for compression but for fairness enhancement.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yuanbo Guo, Jun Xia, Yiyu Shi",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Broad stochastic configuration residual learning system for norm-convergent universal approximation",
      "url": "https://arxiv.org/abs/2511.16550",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16550v1 Announce Type: new \nAbstract: Universal approximation serves as the foundation of neural network learning algorithms. However, some networks establish their universal approximation property by demonstrating that the iterative errors converge in probability measure rather than the more rigorous norm convergence, which makes the universal approximation property of randomized learning networks highly sensitive to random parameter selection, Broad residual learning system (BRLS), as a member of randomized learning models, also encounters this issue. We theoretically demonstrate the limitation of its universal approximation property, that is, the iterative errors do not satisfy norm convergence if the selection of random parameters is inappropriate and the convergence rate meets certain conditions. To address this issue, we propose the broad stochastic configuration residual learning system (BSCRLS) algorithm, which features a novel supervisory mechanism adaptively constraining the range settings of random parameters on the basis of BRLS framework, Furthermore, we prove the universal approximation theorem of BSCRLS based on the more stringent norm convergence. Three versions of incremental BSCRLS algorithms are presented to satisfy the application requirements of various network updates. Solar panels dust detection experiments are performed on publicly available dataset and compared with 13 deep and broad learning algorithms. Experimental results reveal the effectiveness and superiority of BSCRLS algorithms.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Han Su, Zhongyan Li, Wanquan Liu",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Toward Valid Generative Clinical Trial Data with Survival Endpoints",
      "url": "https://arxiv.org/abs/2511.16551",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16551v1 Announce Type: new \nAbstract: Clinical trials face mounting challenges: fragmented patient populations, slow enrollment, and unsustainable costs, particularly for late phase trials in oncology and rare diseases. While external control arms built from real-world data have been explored, a promising alternative is the generation of synthetic control arms using generative AI. A central challenge is the generation of time-to-event outcomes, which constitute primary endpoints in oncology and rare disease trials, but are difficult to model under censoring and small sample sizes. Existing generative approaches, largely GAN-based, are data-hungry, unstable, and rely on strong assumptions such as independent censoring. We introduce a variational autoencoder (VAE) that jointly generates mixed-type covariates and survival outcomes within a unified latent variable framework, without assuming independent censoring. Across synthetic and real trial datasets, we evaluate our model in two realistic scenarios: (i) data sharing under privacy constraints, where synthetic controls substitute for original data, and (ii) control-arm augmentation, where synthetic patients mitigate imbalances between treated and control groups. Our method outperforms GAN baselines on fidelity, utility, and privacy metrics, while revealing systematic miscalibration of type I error and power. We propose a post-generation selection procedure that improves calibration, highlighting both progress and open challenges for generative survival modeling.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Perrine Chassat, Van Tuan Nguyen, Lucas Ducrot, Emilie Lanoy, Agathe Guilloux",
      "tags": [
        "cs.LG",
        "stat.AP",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Boosting Predictive Performance on Tabular Data through Data Augmentation with Latent-Space Flow-Based Diffusion",
      "url": "https://arxiv.org/abs/2511.16571",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16571v1 Announce Type: new \nAbstract: Severe class imbalance is common in real-world tabular learning, where rare but important minority classes are essential for reliable prediction. Existing generative oversampling methods such as GANs, VAEs, and diffusion models can improve minority-class performance, but they often struggle with tabular heterogeneity, training stability, and privacy concerns. We propose a family of latent-space, tree-driven diffusion methods for minority oversampling that use conditional flow matching with gradient-boosted trees as the vector-field learner. The models operate in compact latent spaces to preserve tabular structure and reduce computation. We introduce three variants: PCAForest, which uses linear PCA embedding; EmbedForest, which uses a learned nonlinear embedding; and AttentionForest, which uses an attention-augmented embedding. Each method couples a GBT-based flow with a decoder back to the original feature space. Across 11 datasets from healthcare, finance, and manufacturing, AttentionForest achieves the best average minority recall while maintaining competitive precision, calibration, and distributional similarity. PCAForest and EmbedForest reach similar utility with much faster generation, offering favorable accuracy-efficiency trade-offs. Privacy evaluated with nearest-neighbor distance ratio and distance-to-closest-record is comparable to or better than the ForestDiffusion baseline. Ablation studies show that smaller embeddings tend to improve minority recall, while aggressive learning rates harm stability. Overall, latent-space, tree-driven diffusion provides an efficient and privacy-aware approach to high-fidelity tabular data augmentation under severe class imbalance.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Md. Tawfique Ihsan, Md. Rakibul Hasan Rafi, Ahmed Shoyeb Raihan, Imtiaz Ahmed, Abdullahil Azeem",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "ECPv2: Fast, Efficient, and Scalable Global Optimization of Lipschitz Functions",
      "url": "https://arxiv.org/abs/2511.16575",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16575v1 Announce Type: new \nAbstract: We propose ECPv2, a scalable and theoretically grounded algorithm for global optimization of Lipschitz-continuous functions with unknown Lipschitz constants. Building on the Every Call is Precious (ECP) framework, which ensures that each accepted function evaluation is potentially informative, ECPv2 addresses key limitations of ECP, including high computational cost and overly conservative early behavior. ECPv2 introduces three innovations: (i) an adaptive lower bound to avoid vacuous acceptance regions, (ii) a Worst-m memory mechanism that restricts comparisons to a fixed-size subset of past evaluations, and (iii) a fixed random projection to accelerate distance computations in high dimensions. We theoretically show that ECPv2 retains ECP's no-regret guarantees with optimal finite-time bounds and expands the acceptance region with high probability. We further empirically validate these findings through extensive experiments and ablation studies. Using principled hyperparameter settings, we evaluate ECPv2 across a wide range of high-dimensional, non-convex optimization problems. Across benchmarks, ECPv2 consistently matches or outperforms state-of-the-art optimizers, while significantly reducing wall-clock time.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Fares Fourati, Mohamed-Slim Alouini, Vaneet Aggarwal",
      "tags": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ]
    },
    {
      "title": "Almost Sure Convergence Analysis of Differentially Private Stochastic Gradient Methods",
      "url": "https://arxiv.org/abs/2511.16587",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16587v1 Announce Type: new \nAbstract: Differentially private stochastic gradient descent (DP-SGD) has become the standard algorithm for training machine learning models with rigorous privacy guarantees. Despite its widespread use, the theoretical understanding of its long-run behavior remains limited: existing analyses typically establish convergence in expectation or with high probability, but do not address the almost sure convergence of single trajectories. In this work, we prove that DP-SGD converges almost surely under standard smoothness assumptions, both in nonconvex and strongly convex settings, provided the step sizes satisfy some standard decaying conditions. Our analysis extends to momentum variants such as the stochastic heavy ball (DP-SHB) and Nesterov's accelerated gradient (DP-NAG), where we show that careful energy constructions yield similar guarantees. These results provide stronger theoretical foundations for differentially private optimization and suggest that, despite privacy-induced distortions, the algorithm remains pathwise stable in both convex and nonconvex regimes.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Amartya Mukherjee, Jun Liu",
      "tags": [
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "title": "gfnx: Fast and Scalable Library for Generative Flow Networks in JAX",
      "url": "https://arxiv.org/abs/2511.16592",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16592v1 Announce Type: new \nAbstract: In this paper, we present gfnx, a fast and scalable package for training and evaluating Generative Flow Networks (GFlowNets) written in JAX. gfnx provides an extensive set of environments and metrics for benchmarking, accompanied with single-file implementations of core objectives for training GFlowNets. We include synthetic hypergrids, multiple sequence generation environments with various editing regimes and particular reward designs for molecular generation, phylogenetic tree construction, Bayesian structure learning, and sampling from the Ising model energy. Across different tasks, gfnx achieves significant wall-clock speedups compared to Pytorch-based benchmarks (such as torchgfn library) and author implementations. For example, gfnx achieves up to 55 times speedup on CPU-based sequence generation environments, and up to 80 times speedup with the GPU-based Bayesian network structure learning setup. Our package provides a diverse set of benchmarks and aims to standardize empirical evaluation and accelerate research and applications of GFlowNets. The library is available on GitHub (https://github.com/d-tiapkin/gfnx) and on pypi (https://pypi.org/project/gfnx/). Documentation is available on https://gfnx.readthedocs.io.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Daniil Tiapkin, Artem Agarkov, Nikita Morozov, Ian Maksimov, Askar Tsyganov, Timofei Gritsaev, Sergey Samsonov",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies",
      "url": "https://arxiv.org/abs/2511.16596",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16596v1 Announce Type: new \nAbstract: Palpation, the use of touch in medical examination, is almost exclusively performed by humans. We investigate a proof of concept for an artificial palpation method based on self-supervised learning. Our key idea is that an encoder-decoder framework can learn a $\\textit{representation}$ from a sequence of tactile measurements that contains all the relevant information about the palpated object. We conjecture that such a representation can be used for downstream tasks such as tactile imaging and change detection. With enough training data, it should capture intricate patterns in the tactile measurements that go beyond a simple map of forces -- the current state of the art. To validate our approach, we both develop a simulation environment and collect a real-world dataset of soft objects and corresponding ground truth images obtained by magnetic resonance imaging (MRI). We collect palpation sequences using a robot equipped with a tactile sensor, and train a model that predicts sensory readings at different positions on the object. We investigate the representation learned in this process, and demonstrate its use in imaging and change detection.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Zohar Rimon, Elisei Shafer, Tal Tepper, Efrat Shimron, Aviv Tamar",
      "tags": [
        "cs.LG"
      ]
    },
    {
      "title": "Stabilizing Policy Gradient Methods via Reward Profiling",
      "url": "https://arxiv.org/abs/2511.16629",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16629v1 Announce Type: new \nAbstract: Policy gradient methods, which have been extensively studied in the last decade, offer an effective and efficient framework for reinforcement learning problems. However, their performances can often be unsatisfactory, suffering from unreliable reward improvements and slow convergence, due to high variance in gradient estimations. In this paper, we propose a universal reward profiling framework that can be seamlessly integrated with any policy gradient algorithm, where we selectively update the policy based on high-confidence performance estimations. We theoretically justify that our technique will not slow down the convergence of the baseline policy gradient methods, but with high probability, will result in stable and monotonic improvements of their performance. Empirically, on eight continuous-control benchmarks (Box2D and MuJoCo/PyBullet), our profiling yields up to 1.5x faster convergence to near-optimal returns, up to 1.75x reduction in return variance on some setups. Our profiling approach offers a general, theoretically grounded path to more reliable and efficient policy learning in complex environments.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Shihab Ahmed, El Houcine Bergou, Aritra Dutta, Yue Wang",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "Evolution Strategies at the Hyperscale",
      "url": "https://arxiv.org/abs/2511.16652",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16652v1 Announce Type: new \nAbstract: We introduce Evolution Guided General Optimization via Low-rank Learning (EGGROLL), an evolution strategies (ES) algorithm designed to scale backprop-free optimization to large population sizes for modern large neural network architectures with billions of parameters. ES is a set of powerful blackbox optimisation methods that can handle non-differentiable or noisy objectives with excellent scaling potential through parallelisation. Na{\\\"i}ve ES becomes prohibitively expensive at scale due to the computational and memory costs associated with generating matrix perturbations $E\\in\\mathbb{R}^{m\\times n}$ and the batched matrix multiplications needed to compute per-member forward passes. EGGROLL overcomes these bottlenecks by generating random matrices $A\\in \\mathbb{R}^{m\\times r},\\ B\\in \\mathbb{R}^{n\\times r}$ with $r\\ll \\min(m,n)$ to form a low-rank matrix perturbation $A B^\\top$ that are used in place of the full-rank perturbation $E$. As the overall update is an average across a population of $N$ workers, this still results in a high-rank update but with significant memory and computation savings, reducing the auxiliary storage from $mn$ to $r(m+n)$ per layer and the cost of a forward pass from $\\mathcal{O}(mn)$ to $\\mathcal{O}(r(m+n))$ when compared to full-rank ES. A theoretical analysis reveals our low-rank update converges to the full-rank update at a fast $\\mathcal{O}\\left(\\frac{1}{r}\\right)$ rate. Our experiments show that (1) EGGROLL does not compromise the performance of ES in tabula-rasa RL settings, despite being faster, (2) it is competitive with GRPO as a technique for improving LLM reasoning, and (3) EGGROLL enables stable pre-training of nonlinear recurrent language models that operate purely in integer datatypes.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Bidipta Sarkar, Mattie Fellows, Juan Agustin Duque, Alistair Letcher, Antonio Le\\'on Villares, Anya Sims, Dylan Cope, Jarek Liesen, Lukas Seier, Theo Wolf, Uljad Berdica, Alexander David Goldie, Aaron Courville, Karin Sevegnani, Shimon Whiteson, Jakob Nicolaus Foerster",
      "tags": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter",
      "url": "https://arxiv.org/abs/2511.16665",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.16665v1 Announce Type: new \nAbstract: The emergence of Large Language Models (LLMs) with strong reasoning capabilities marks a significant milestone, unlocking new frontiers in complex problem-solving. However, training these reasoning models, typically using Reinforcement Learning (RL), encounters critical efficiency bottlenecks: response generation during RL training exhibits a persistent long-tail distribution, where a few very long responses dominate execution time, wasting resources and inflating costs. To address this, we propose TLT, a system that accelerates reasoning RL training losslessly by integrating adaptive speculative decoding. Applying speculative decoding in RL is challenging due to the dynamic workloads, evolving target model, and draft model training overhead. TLT overcomes these obstacles with two synergistic components: (1) Adaptive Drafter, a lightweight draft model trained continuously on idle GPUs during long-tail generation to maintain alignment with the target model at no extra cost; and (2) Adaptive Rollout Engine, which maintains a memory-efficient pool of pre-captured CUDAGraphs and adaptively select suitable SD strategies for each input batch. Evaluations demonstrate that TLT achieves over 1.7x end-to-end RL training speedup over state-of-the-art systems, preserves the model accuracy, and yields a high-quality draft model as a free byproduct suitable for efficient deployment. Code is released at https://github.com/mit-han-lab/fastrl.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Qinghao Hu, Shang Yang, Junxian Guo, Xiaozhe Yao, Yujun Lin, Yuxian Gu, Han Cai, Chuang Gan, Ana Klimovic, Song Han",
      "tags": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ]
    },
    {
      "title": "PUP 3D-GS: Principled Uncertainty Pruning for 3D Gaussian Splatting",
      "url": "https://arxiv.org/abs/2406.10219",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2406.10219v3 Announce Type: cross \nAbstract: Recent advances in novel view synthesis have enabled real-time rendering speeds with high reconstruction accuracy. 3D Gaussian Splatting (3D-GS), a foundational point-based parametric 3D scene representation, models scenes as large sets of 3D Gaussians. However, complex scenes can consist of millions of Gaussians, resulting in high storage and memory requirements that limit the viability of 3D-GS on devices with limited resources. Current techniques for compressing these pretrained models by pruning Gaussians rely on combining heuristics to determine which Gaussians to remove. At high compression ratios, these pruned scenes suffer from heavy degradation of visual fidelity and loss of foreground details. In this paper, we propose a principled sensitivity pruning score that preserves visual fidelity and foreground details at significantly higher compression ratios than existing approaches. It is computed as a second-order approximation of the reconstruction error on the training views with respect to the spatial parameters of each Gaussian. Additionally, we propose a multi-round prune-refine pipeline that can be applied to any pretrained 3D-GS model without changing its training pipeline. After pruning 90% of Gaussians, a substantially higher percentage than previous methods, our PUP 3D-GS pipeline increases average rendering speed by 3.56$\\times$ while retaining more salient foreground information and achieving higher image quality metrics than existing techniques on scenes from the Mip-NeRF 360, Tanks & Temples, and Deep Blending datasets.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Alex Hanson, Allen Tu, Vasu Singla, Mayuka Jayawardhana, Matthias Zwicker, Tom Goldstein",
      "tags": [
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ]
    },
    {
      "title": "Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems",
      "url": "https://arxiv.org/abs/2511.15715",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15715v1 Announce Type: cross \nAbstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.\n  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.\n  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.\n  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yash Raj Singh",
      "tags": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Human-aligned Quantification of Numerical Data",
      "url": "https://arxiv.org/abs/2511.15723",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15723v1 Announce Type: cross \nAbstract: Quantifying numerical data involves addressing two key challenges: first, determining whether the data can be naturally quantified, and second, identifying the numerical intervals or ranges of values that correspond to specific value classes, referred to as \"quantums,\" which represent statistically meaningful states. If such quantification is feasible, continuous streams of numerical data can be transformed into sequences of \"symbols\" that reflect the states of the system described by the measured parameter. People often perform this task intuitively, relying on common sense or practical experience, while information theory and computer science offer computable metrics for this purpose. In this study, we assess the applicability of metrics based on information compression and the Silhouette coefficient for quantifying numerical data. We also investigate the extent to which these metrics correlate with one another and with what is commonly referred to as \"human intuition.\" Our findings suggest that the ability to classify numeric data values into distinct categories is associated with a Silhouette coefficient above 0.65 and a Dip Test below 0.5; otherwise, the data can be treated as following a unimodal normal distribution. Furthermore, when quantification is possible, the Silhouette coefficient appears to align more closely with human intuition than the \"normalized centroid distance\" method derived from information compression perspective.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Anton Kolonin",
      "tags": [
        "physics.data-an",
        "cs.HC",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    },
    {
      "title": "Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer",
      "url": "https://arxiv.org/abs/2511.15741",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15741v1 Announce Type: cross \nAbstract: Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Hyo-Jeong Jang",
      "tags": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "SURFing to the Fundamental Limit of Jet Tagging",
      "url": "https://arxiv.org/abs/2511.15779",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15779v1 Announce Type: cross \nAbstract: Beyond the practical goal of improving search and measurement sensitivity through better jet tagging algorithms, there is a deeper question: what are their upper performance limits? Generative surrogate models with learned likelihood functions offer a new approach to this problem, provided the surrogate correctly captures the underlying data distribution. In this work, we introduce the SUrrogate ReFerence (SURF) method, a new approach to validating generative models. This framework enables exact Neyman-Pearson tests by training the target model on samples from another tractable surrogate, which is itself trained on real data. We argue that the EPiC-FM generative model is a valid surrogate reference for JetClass jets and apply SURF to show that modern jet taggers may already be operating close to the true statistical limit. By contrast, we find that autoregressive GPT models unphysically exaggerate top vs. QCD separation power encoded in the surrogate reference, implying that they are giving a misleading picture of the fundamental limit.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Ian Pang, Darius A. Faroughy, David Shih, Ranit Das, Gregor Kasieczka",
      "tags": [
        "hep-ph",
        "cs.LG",
        "hep-ex",
        "physics.data-an"
      ]
    },
    {
      "title": "Atlas Gaussian processes on restricted domains and point clouds",
      "url": "https://arxiv.org/abs/2511.15822",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15822v1 Announce Type: cross \nAbstract: In real-world applications, data often reside in restricted domains with unknown boundaries, or as high-dimensional point clouds lying on a lower-dimensional, nontrivial, unknown manifold. Traditional Gaussian Processes (GPs) struggle to capture the underlying geometry in such settings. Some existing methods assume a flat space embedded in a point cloud, which can be represented by a single latent chart (latent space), while others exhibit weak performance when the point cloud is sparse or irregularly sampled. The goal of this work is to address these challenges. The main contributions are twofold: (1) We establish the Atlas Brownian Motion (BM) framework for estimating the heat kernel on point clouds with unknown geometries and nontrivial topological structures; (2) Instead of directly using the heat kernel estimates, we construct a Riemannian corrected kernel by combining the global heat kernel with local RBF kernel and leading to the formulation of Riemannian-corrected Atlas Gaussian Processes (RC-AGPs). The resulting RC-AGPs are applied to regression tasks across synthetic and real-world datasets. These examples demonstrate that our method outperforms existing approaches in both heat kernel estimation and regression accuracy. It improves statistical inference by effectively bridging the gap between complex, high-dimensional observations and manifold-based inferences.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Mu Niu, Yue Zhang, Ke Ye, Pokman Cheung, Yizhu Wang, Xiaochen Yang",
      "tags": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion",
      "url": "https://arxiv.org/abs/2511.15874",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15874v1 Announce Type: cross \nAbstract: Accurate 6D object pose estimation is vital for robotics, augmented reality, and scene understanding. For seen objects, high accuracy is often attainable via per-object fine-tuning but generalizing to unseen objects remains a challenge. To address this problem, past arts assume access to CAD models at test time and typically follow a multi-stage pipeline to estimate poses: detect and segment the object, propose an initial pose, and then refine it. Under occlusion, however, the early-stage of such pipelines are prone to errors, which can propagate through the sequential processing, and consequently degrade the performance. To remedy this shortcoming, we propose four novel extensions to model-based 6D pose estimation methods: (i) a dynamic non-uniform dense sampling strategy that focuses computation on visible regions, reducing occlusion-induced errors; (ii) a multi-hypothesis inference mechanism that retains several confidence-ranked pose candidates, mitigating brittle single-path failures; (iii) iterative refinement to progressively improve pose accuracy; and (iv) series of occlusion-focused training augmentations that strengthen robustness and generalization. Furthermore, we propose a new weighted by visibility metric for evaluation under occlusion to minimize the bias in the existing protocols. Via extensive empirical evaluations, we show that our proposed approach achieves more than 5% improvement in accuracy on ICBIN and more than 2% on BOP dataset benchmarks, while achieving approximately 3 times faster inference.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Sajjad Pakdamansavoji, Yintao Ma, Amir Rasouli, Tongtong Cao",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Box6D : Zero-shot Category-level 6D Pose Estimation of Warehouse Boxes",
      "url": "https://arxiv.org/abs/2511.15884",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15884v1 Announce Type: cross \nAbstract: Accurate and efficient 6D pose estimation of novel objects under clutter and occlusion is critical for robotic manipulation across warehouse automation, bin picking, logistics, and e-commerce fulfillment. There are three main approaches in this domain; Model-based methods assume an exact CAD model at inference but require high-resolution meshes and transfer poorly to new environments; Model-free methods that rely on a few reference images or videos are more flexible, however often fail under challenging conditions; Category-level approaches aim to balance flexibility and accuracy but many are overly general and ignore environment and object priors, limiting their practicality in industrial settings.\n  To this end, we propose Box6d, a category-level 6D pose estimation method tailored for storage boxes in the warehouse context. From a single RGB-D observation, Box6D infers the dimensions of the boxes via a fast binary search and estimates poses using a category CAD template rather than instance-specific models. Suing a depth-based plausibility filter and early-stopping strategy, Box6D then rejects implausible hypotheses, lowering computational cost. We conduct evaluations on real-world storage scenarios and public benchmarks, and show that our approach delivers competitive or superior 6D pose precision while reducing inference time by approximately 76%.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Yintao Ma, Sajjad Pakdamansavoji, Amir Rasouli, Tongtong Cao",
      "tags": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "EEG Emotion Recognition Through Deep Learning",
      "url": "https://arxiv.org/abs/2511.15902",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15902v1 Announce Type: cross \nAbstract: An advanced emotion classification model was developed using a CNN-Transformer architecture for emotion recognition from EEG brain wave signals, effectively distinguishing among three emotional states, positive, neutral and negative. The model achieved a testing accuracy of 91%, outperforming traditional models such as SVM, DNN, and Logistic Regression. Training was conducted on a custom dataset created by merging data from SEED, SEED-FRA, and SEED-GER repositories, comprising 1,455 samples with EEG recordings labeled according to emotional states. The combined dataset represents one of the largest and most culturally diverse collections available. Additionally, the model allows for the reduction of the requirements of the EEG apparatus, by leveraging only 5 electrodes of the 62. This reduction demonstrates the feasibility of deploying a more affordable consumer-grade EEG headset, thereby enabling accessible, at-home use, while also requiring less computational power. This advancement sets the groundwork for future exploration into mood changes induced by media content consumption, an area that remains underresearched. Integration into medical, wellness, and home-health platforms could enable continuous, passive emotional monitoring, particularly beneficial in clinical or caregiving settings where traditional behavioral cues, such as facial expressions or vocal tone, are diminished, restricted, or difficult to interpret, thus potentially transforming mental health diagnostics and interventions...",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Roman Dolgopolyi, Antonis Chatzipanagiotou",
      "tags": [
        "eess.SP",
        "cs.LG"
      ]
    },
    {
      "title": "Machine Learning vs. Randomness: Challenges in Predicting Binary Options Movements",
      "url": "https://arxiv.org/abs/2511.15960",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15960v1 Announce Type: cross \nAbstract: Binary options trading is often marketed as a field where predictive models can generate consistent profits. However, the inherent randomness and stochastic nature of binary options make price movements highly unpredictable, posing significant challenges for any forecasting approach. This study demonstrates that machine learning algorithms struggle to outperform a simple baseline in predicting binary options movements. Using a dataset of EUR/USD currency pairs from 2021 to 2023, we tested multiple models, including Random Forest, Logistic Regression, Gradient Boosting, and k-Nearest Neighbors (kNN), both before and after hyperparameter optimization. Furthermore, several neural network architectures, including Multi-Layer Perceptrons (MLP) and a Long Short-Term Memory (LSTM) network, were evaluated under different training conditions. Despite these exhaustive efforts, none of the models surpassed the ZeroR baseline accuracy, highlighting the inherent randomness of binary options. These findings reinforce the notion that binary options lack predictable patterns, making them unsuitable for machine learning-based forecasting.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Gabriel M. Arantes, Richard F. Pinto, Bruno L. Dalmazo, Eduardo N. Borges, Giancarlo Lucca, Viviane L. D. de Mattos, Fabian C. Cardoso, Rafael A. Berri",
      "tags": [
        "q-fin.CP",
        "cs.LG"
      ]
    },
    {
      "title": "A Primer on Quantum Machine Learning",
      "url": "https://arxiv.org/abs/2511.15969",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15969v1 Announce Type: cross \nAbstract: Quantum machine learning (QML) is a computational paradigm that seeks to apply quantum-mechanical resources to solve learning problems. As such, the goal of this framework is to leverage quantum processors to tackle optimization, supervised, unsupervised and reinforcement learning, and generative modeling-among other tasks-more efficiently than classical models. Here we offer a high level overview of QML, focusing on settings where the quantum device is the primary learning or data generating unit. We outline the field's tensions between practicality and guarantees, access models and speedups, and classical baselines and claimed quantum advantages-flagging where evidence is strong, where it is conditional or still lacking, and where open questions remain. By shedding light on these nuances and debates, we aim to provide a friendly map of the QML landscape so that the reader can judge when-and under what assumptions-quantum approaches may offer real benefits.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Su Yeon Chang, M. Cerezo",
      "tags": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Efficient Chromosome Parallelization for Precision Medicine Genomic Workflows",
      "url": "https://arxiv.org/abs/2511.15977",
      "published": "2025-11-21T10:00:00+00:00",
      "date_verified": true,
      "description": "arXiv:2511.15977v1 Announce Type: cross \nAbstract: Large-scale genomic workflows used in precision medicine can process datasets spanning tens to hundreds of gigabytes per sample, leading to high memory spikes, intensive disk I/O, and task failures due to out-of-memory errors. Simple static resource allocation methods struggle to handle the variability in per-chromosome RAM demands, resulting in poor resource utilization and long runtimes. In this work, we propose multiple mechanisms for adaptive, RAM-efficient parallelization of chromosome-level bioinformatics workflows. First, we develop a symbolic regression model that estimates per-chromosome memory consumption for a given task and introduces an interpolating bias to conservatively minimize over-allocation. Second, we present a dynamic scheduler that adaptively predicts RAM usage with a polynomial regression model, treating task packing as a Knapsack problem to optimally batch jobs based on predicted memory requirements. Additionally, we present a static scheduler that optimizes chromosome processing order to minimize peak memory while preserving throughput. Our proposed methods, evaluated on simulations and real-world genomic pipelines, provide new mechanisms to reduce memory overruns and balance load across threads. We thereby achieve faster end-to-end execution, showcasing the potential to optimize large-scale genomic workflows.",
      "source": "cs.LG updates on arXiv.org",
      "source_url": "https://export.arxiv.org/rss/cs.LG",
      "author": "Daniel Mas Montserrat, Ray Verma, M\\'iriam Barrab\\'es, Francisco M. de la Vega, Carlos D. Bustamante, Alexander G. Ioannidis",
      "tags": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PF",
        "q-bio.GN"
      ]
    },
    {
      "title": "Allen Institute for AI (AI2) Introduces Olmo 3: An Open Source 7B and 32B LLM Family Built on the Dolma 3 and Dolci Stack",
      "url": "https://www.marktechpost.com/2025/11/20/allen-institute-for-ai-ai2-introduces-olmo-3-an-open-source-7b-and-32b-llm-family-built-on-the-dolma-3-and-dolci-stack/",
      "published": "2025-11-21T08:07:15+00:00",
      "date_verified": true,
      "description": "<p>Allen Institute for AI (AI2) is releasing Olmo 3 as a fully open model family that exposes the entire &#8216;model flow&#8217;, from raw data and code to intermediate checkpoints and deployment ready variants. Olmo 3 is a dense transformer suite with 7B and 32B parameter models. The family includes Olmo 3-Base, Olmo 3-Think, Olmo 3-Instruct, [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/20/allen-institute-for-ai-ai2-introduces-olmo-3-an-open-source-7b-and-32b-llm-family-built-on-the-dolma-3-and-dolci-stack/\">Allen Institute for AI (AI2) Introduces Olmo 3: An Open Source 7B and 32B LLM Family Built on the Dolma 3 and Dolci Stack</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Michal Sutter",
      "tags": [
        "AI Shorts",
        "Applications",
        "Artificial Intelligence",
        "Editors Pick",
        "Language Model",
        "Large Language Model",
        "Machine Learning",
        "New Releases",
        "Open Source",
        "Staff",
        "Tech News",
        "Technology"
      ]
    },
    {
      "title": "Adopting the MCP Bundle format (.mcpb) for portable local servers",
      "url": "http://blog.modelcontextprotocol.io/posts/2025-11-20-adopting-mcpb/",
      "published": "2025-11-21T05:00:00+00:00",
      "date_verified": true,
      "description": "<p>The <a href=\"https://github.com/modelcontextprotocol/mcpb\">MCP Bundle format (.mcpb)</a> is now part of the Model Context Protocol. This makes it easier for developers to distribute local MCP servers across any compatible client, including Claude desktop app, Claude Code, and MCP for Windows.</p>\n<h2 id=\"what-are-mcp-bundles\">What are MCP Bundles?</h2>\n<p>MCP Bundles are zip archives containing a local MCP server and a <code>manifest.json</code> that describes the server and its capabilities. The format is similar to Chrome extensions (.crx) or VS Code extensions (.vsix), enabling end users to install local MCP servers with a single click.</p>",
      "source": "blog on mcp blog",
      "source_url": "https://blog.modelcontextprotocol.io/index.xml",
      "author": "",
      "tags": []
    },
    {
      "title": "20x Faster TRL Fine-tuning with RapidFire AI",
      "url": "https://huggingface.co/blog/rapidfireai",
      "published": "2025-11-21T05:00:00+00:00",
      "date_verified": true,
      "description": "",
      "source": "Hugging Face - Blog",
      "source_url": "https://huggingface.co/blog/feed.xml",
      "author": "",
      "tags": []
    },
    {
      "title": "Open ASR Leaderboard: Trends and Insights with New Multilingual & Long-Form Tracks",
      "url": "https://huggingface.co/blog/open-asr-leaderboard",
      "published": "2025-11-21T05:00:00+00:00",
      "date_verified": true,
      "description": "",
      "source": "Hugging Face - Blog",
      "source_url": "https://huggingface.co/blog/feed.xml",
      "author": "",
      "tags": []
    },
    {
      "title": "Practical Guide on how to build an Agent from scratch with Gemini 3",
      "url": "https://www.philschmid.de/building-agents",
      "published": "2025-11-21T05:00:00+00:00",
      "date_verified": true,
      "description": "A step-by-step practical guide on building AI agents using Gemini 3 Pro, covering tool integration, context management, and best practices for creating effective and reliable agents.",
      "source": "philschmid.de - RSS feed",
      "source_url": "https://www.philschmid.de/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "Grok 4.1 Fast's compelling dev access and Agent Tools API overshadowed by Musk glazing",
      "url": "https://venturebeat.com/ai/grok-4-1-fasts-compelling-dev-access-and-agent-tools-api-overshadowed-by",
      "published": "2025-11-21T04:57:00+00:00",
      "date_verified": true,
      "description": "<p>Elon Musk&#x27;s frontier generative AI startup xAI<a href=\"https://x.ai/news/grok-4-1-fast\"> formally opened developer access to its Grok 4.1 Fast models</a> last night and introduced a new Agent Tools API—but the technical milestones were immediately subverted by a wave of public ridicule about Grok&#x27;s responses on the social network X over the last few days praising its creator Musk as <a href=\"https://x.com/agraybee/status/1991578106239545455?s=20\">more athletic than championship-winning American football players</a> and legendary <a href=\"https://x.com/pitdesi/status/1991532840811655418?s=20\">boxer Mike Tyson</a>, despite having displayed no public prowess at either sport.</p><p>They emerge as yet another black eye for xAI&#x27;s Grok following the <a href=\"https://www.marketingaiinstitute.com/blog/grok-model-update\">&quot;MechaHitler&quot; scandal in the summer of 2025</a>, in which an earlier version of Grok adopted a verbally antisemitic persona inspired by the late German dictator and Holocaust architect, and an incident in May 2025 which it replied to X users to discuss <a href=\"https://venturebeat.com/ai/elon-musks-xai-tries-to-explain-groks-south-african-race-relations-freakout-the-other-day\">unfounded claims of &quot;white genocide&quot; </a>in Musk&#x27;s home country of South Africa to unrelated subject matter.</p><p>This time, X users shared dozens of examples of Grok alleging Musk was stronger or more performant than elite athletes and a greater thinker than luminaries such as Albert Einstein, sparking questions about the AI&#x27;s reliability, bias controls, adversarial prompting defenses, and the credibility of xAI’s public claims about “maximally truth-seeking” models. .</p><p>Against this backdrop, xAI’s actual developer-focused announcement—the first-ever API availability for Grok 4.1 Fast Reasoning, Grok 4.1 Fast Non-Reasoning, and the Agent Tools API—landed in a climate dominated by memes, skepticism, and renewed scrutiny.</p><h1><b>How the Grok Musk Glazing Controversy Overshadowed the API Release</b></h1><p>Although <a href=\"https://venturebeat.com/ai/musks-xai-launches-grok-4-1-with-lower-hallucination-rate-on-the-web-and\">Grok 4.1 was announced on the evening of Monday, November 17, 2025</a> as available to consumers via the X and Grok apps and websites, the<a href=\"https://x.com/xai/status/1991284813727474073\"> API launch announced last night</a>, on November 19, was intended to mark a developer-focused expansion. </p><p>Instead, the conversation across X shifted sharply toward Grok’s behavior in consumer channels.</p><p>Between November 17–20, users discovered that Grok would frequently deliver exaggerated, implausible praise for Musk when prompted—sometimes subtly, often brazenly. </p><p>Responses declaring Musk “more fit than LeBron James,” a superior quarterback to Peyton Manning, or “smarter than Albert Einstein” gained massive engagement. </p><div></div><p>When paired with identical prompts substituting “Bill Gates” or other figures, Grok often responded far more critically, suggesting inconsistent preference handling or latent alignment drift.</p><div></div><ul><li><p><b>Screenshots spread by high-engagement accounts</b> (e.g., <a href=\"https://x.com/SilvermanJacob/status/1991565290967298522\">@SilvermanJacob</a>, @StatisticUrban) framed Grok as unreliable or compromised.</p></li><li><p><b>Memetic commentary</b>—“Elon’s only friend is Grok”—became shorthand for perceived sycophancy.</p></li><li><p><b>Media coverage</b>, including a November 20 report from <a href=\"https://www.theverge.com/ai-artificial-intelligence/825675/groks-elon-musk-worship-is-getting-weird\">The Verge,</a> characterized Grok’s responses as “weird worship,” highlighting claims that Musk is “as smart as da Vinci” and “fitter than LeBron James.”</p></li><li><p><b>Critical threads</b> argued that Grok’s design choices replicated past alignment failures, such as a July 2025 incident where Grok generated problematic praise of Adolf Hitler under certain prompting conditions.</p></li></ul><p>The viral nature of the glazing overshadowed the technical release and complicated xAI’s messaging about accuracy and trustworthiness.</p><h3><b>Implications for Developer Adoption and Trust</b></h3><p>The juxtaposition of a major API release with a public credibility crisis raises several concerns:</p><ol><li><p><b>Alignment Controls</b>\n The glazing behavior suggests that prompt adversariality may expose latent preference biases, undermining claims of “truth-maximization.”</p></li><li><p><b>Brand Contamination Across Deployment Contexts</b>\n Though the consumer chatbot and API-accessible model share lineage, developers may conflate the reliability of both—even if safeguards differ.</p></li><li><p><b>Risk in Agentic Systems</b>\n The Agent Tools API gives Grok abilities such as web search, code execution, and document retrieval. Bias-driven misjudgments in those contexts could have material consequences.</p></li><li><p><b>Regulatory Scrutiny</b>\n Biased outputs that systematically favor a CEO or public figure could attract attention from consumer protection regulators evaluating AI representational neutrality.</p></li><li><p><b>Developer Hesitancy</b>\n Early adopters may wait for evidence that the model version exposed through the API is not subject to the same glazing behaviors seen in consumer channels.</p></li></ol><p><a href=\"https://x.com/elonmusk/status/1991624623407161383?s=20\">Musk himself attempted to defuse the situation</a> with a self-deprecating X post this evening, writing:</p><blockquote><p>“Grok was unfortunately manipulated by adversarial prompting into saying absurdly positive things about me. For the record, I am a fat retard.”</p></blockquote><p>While intended to signal transparency, the admission did not directly address whether the root cause was adversarial prompting alone or whether model training introduced unintentional positive priors. </p><p>Nor did it clarify whether the API-exposed versions of Grok 4.1 Fast differ meaningfully from the consumer version that produced the offending outputs.</p><p>Until xAI provides deeper technical detail about prompt vulnerabilities, preference modeling, and safety guardrails, the controversy is likely to persist.</p><h2><b>Two Grok 4.1 Models Available on xAI API</b></h2><p>Although consumers using Grok apps gained access to Grok 4.1 Fast earlier in the week, developers could not previously use the model through the xAI API. The latest release closes that gap by adding two new models to the public model catalog:</p><ul><li><p><b>grok-4-1-fast-reasoning</b> — designed for maximal reasoning performance and complex tool workflows</p></li><li><p><b>grok-4-1-fast-non-reasoning</b> — optimized for extremely fast responses</p></li></ul><p>Both models support a 2 million–token context window, aligning them with xAI’s long-context roadmap and providing substantial headroom for multistep agent tasks, document processing, and research workflows.</p><p>The new additions appear alongside updated entries in xAI’s pricing and rate-limit tables, confirming that they now function as first-class API endpoints across xAI infrastructure and routing partners such as OpenRouter.</p><h2><b>Agent Tools API: A New Server-Side Tool Layer</b></h2><p>The other major component of the announcement is the <b>Agent Tools API</b>, which introduces a unified mechanism for Grok to call tools across a range of capabilities:</p><ul><li><p><b>Search Tools</b> including a direct link to <b>X (Twitter) search</b> for real-time conversations and <b>web search</b> for broad external retrieval.</p></li><li><p><b>Files Search: </b>Retrieval and citation of relevant documents uploaded by users</p></li><li><p><b>Code Execution: </b>A secure Python sandbox for analysis, simulation, and data processing</p></li><li><p><b>MCP (Model Context Protocol) Integration: </b>Connects Grok agents with third-party tools or custom enterprise systems</p></li></ul><p>xAI emphasizes that the API handles all infrastructure complexity—including sandboxing, key management, rate limiting, and environment orchestration—on the server side. Developers simply declare which tools are available, and Grok autonomously decides when and how to invoke them. The company highlights that the model frequently performs multi-tool, multi-turn workflows in parallel, reducing latency for complex tasks.</p><h2><b>How the New API Layer Leverages Grok 4.1 Fast</b></h2><p>While the model existed before today’s API release, Grok 4.1 Fast was trained explicitly for tool-calling performance. The model’s long-horizon reinforcement learning tuning supports autonomous planning, which is essential for agent systems that chain multiple operations.</p><p>Key behaviors highlighted by xAI include:</p><ul><li><p><b>Consistent output quality across the full 2M token context window</b>, enabled by long-horizon RL</p></li><li><p><b>Reduced hallucination rate</b>, cut in half compared with Grok 4 Fast while maintaining Grok 4’s factual accuracy performance</p></li><li><p><b>Parallel tool use</b>, where Grok executes multiple tool calls concurrently when solving multi-step problems</p></li><li><p><b>Adaptive reasoning</b>, allowing the model to plan tool sequences over several turns</p></li></ul><p>This behavior aligns directly with the Agent Tools API’s purpose: to give Grok the external capabilities necessary for autonomous agent work.</p><h2><b>Benchmark Results Demonstrating Highest Agentic Performance</b></h2><p>xAI released a set of benchmark results intended to illustrate how Grok 4.1 Fast performs when paired with the Agent Tools API, emphasizing scenarios that rely on tool calling, long-context reasoning, and multi-step task execution. </p><p>On <b>τ²-bench Telecom</b>, a benchmark built to replicate real-world customer-support workflows involving tool use, Grok 4.1 Fast achieved the highest score among all listed models — outpacing even Google&#x27;s new Gemini 3 Pro and OpenAI&#x27;s recent 5.1 on high reasoning — while also achieving among the lowest prices for developers and users. The evaluation, independently verified by Artificial Analysis, cost $105 to complete and served as one of xAI’s central claims of superiority in agentic performance.</p><p>In structured function-calling tests, Grok 4.1 Fast Reasoning recorded a 72 percent overall accuracy on the Berkeley Function Calling v4 benchmark, a result accompanied by a reported cost of $400 for the run. </p><p>xAI noted that Gemini 3 Pro’s comparative result in this benchmark stemmed from independent estimates rather than an official submission, leaving some uncertainty in cross-model comparisons.</p><p>Long-horizon evaluations further underscored the model’s design emphasis on stability across large contexts. In multi-turn tests involving extended dialog and expanded context windows, Grok 4.1 Fast outperformed both Grok 4 Fast and the earlier Grok 4, aligning with xAI’s claims that long-horizon reinforcement learning helped mitigate the typical degradation seen in models operating at the two-million-token scale.</p><p>A second cluster of benchmarks—Research-Eval, FRAMES, and X Browse—highlighted Grok 4.1 Fast’s capabilities in tool-augmented research tasks. </p><p>Across all three evaluations, Grok 4.1 Fast paired with the Agent Tools API earned the highest scores among the models with published results. It also delivered the lowest average cost per query in Research-Eval and FRAMES, reinforcing xAI’s messaging on cost-efficient research performance. </p><p>In X Browse, an internal xAI benchmark assessing multihop search capabilities across the X platform, Grok 4.1 Fast again led its peers, though Gemini 3 Pro lacked cost data for direct comparison.</p><h2><b>Developer Pricing and Temporary Free Access</b></h2><p>API pricing for Grok 4.1 Fast is as follows:</p><ul><li><p><b>Input tokens:</b> $0.20 per 1M</p></li><li><p><b>Cached input tokens:</b> $0.05 per 1M</p></li><li><p><b>Output tokens:</b> $0.50 per 1M</p></li><li><p><b>Tool calls:</b> From $5 per 1,000 successful tool invocations</p></li></ul><p>To facilitate early experimentation:</p><ul><li><p><b>Grok 4.1 Fast is free on OpenRouter until December 3rd.</b></p></li><li><p><b>The Agent Tools API is also free through December 3rd via the xAI API.</b></p></li></ul><p>When paying for the models outside of the free period, Grok 4.1 Fast reasoning and non-reasoning are both among the cheaper options from major frontier labs through their own APIs. See below:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input (/1M)</b></p></td><td><p><b>Output (/1M)</b></p></td><td><p><b>Total Cost</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 4.5 Turbo</p></td><td><p>$0.11</p></td><td><p>$0.45</p></td><td><p>$0.56</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p><b>Grok 4.1 Fast (reasoning)</b></p></td><td><p><b>$0.20</b></p></td><td><p><b>$0.50</b></p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p><b>Grok 4.1 Fast (non-reasoning)</b></p></td><td><p><b>$0.20</b></p></td><td><p><b>$0.50</b></p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>GPT-5.1</p></td><td><p>$1.25</p></td><td><p>$10.00</p></td><td><p>$11.25</p></td><td><p><a href=\"https://openai.com/pricing\">OpenAI</a></p></td></tr><tr><td><p>Gemini 2.5 Pro (≤200K)</p></td><td><p>$1.25</p></td><td><p>$10.00</p></td><td><p>$11.25</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Gemini 2.5 Pro (&gt;200K)</p></td><td><p>$2.50</p></td><td><p>$15.00</p></td><td><p>$17.50</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>Grok 4 (0709)</b></p></td><td><p><b>$3.00</b></p></td><td><p><b>$15.00</b></p></td><td><p><b>$18.00</b></p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Opus 4.1</p></td><td><p>$15.00</p></td><td><p>$75.00</p></td><td><p>$90.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs/models-overview\">Anthropic</a></p></td></tr></tbody></table><h2><b>How Enterprises Should Evaluate Grok 4.1 Fast in Light of Performance, Cost, and Trust</b></h2><p>For enterprises evaluating frontier-model deployments, Grok 4.1 Fast presents a compelling combination of high performance and low operational cost. Across multiple agentic and function-calling benchmarks, the model consistently outperforms or matches leading systems like Gemini 3 Pro, GPT-5.1 (high), and Claude 4.5 Sonnet, while operating inside a far more economical cost envelope. </p><p>At $0.70 per million tokens, both Grok 4.1 Fast variants sit only marginally above ultracheap models like Qwen 3 Turbo but deliver accuracy levels in line with systems that cost 10–20× more per unit. The τ²-bench Telecom results reinforce this value proposition: Grok 4.1 Fast not only achieved the highest score in its test cohort but also appears to be the lowest-cost model in that benchmark run. In practical terms, this gives enterprises an unusually favorable cost-to-intelligence ratio, particularly for workloads involving multistep planning, tool use, and long-context reasoning.</p><p>However, performance and pricing are only part of the equation for organizations considering large-scale adoption. The recent “glazing” controversy from Grok’s consumer deployment on X — combined with the earlier &quot;MechaHitler&quot; and &quot;White Genocid&quot; incidents — expose credibility and trust-surface risks that enterprises cannot ignore. </p><p>Even if the API models are technically distinct from the consumer-facing variant, the inability to prevent sycophantic, adversarially-induced bias in a high-visibility environment raises legitimate concerns about downstream reliability in operational contexts. Enterprise procurement teams will rightly ask whether similar vulnerabilities—preference skew, alignment drift, or context-sensitive bias—could surface when Grok is connected to production databases, workflow engines, code-execution tools, or research pipelines.</p><p>The introduction of the Agent Tools API raises the stakes further. Grok 4.1 Fast is not just a text generator—it is now an orchestrator of web searches, X-data queries, document retrieval operations, and remote Python execution. These agentic capabilities amplify productivity but also expand the blast radius of any misalignment. A model that can over-index on flattering a public figure could, in principle, also misprioritize results, mis-handle safety boundaries, or deliver skewed interpretations when operating with real-world data. </p><p>Enterprises therefore need a clear understanding of how xAI isolates, audits, and hardens its API models relative to the consumer-facing Grok whose failures drove the latest scrutiny.</p><p>The result is a mixed strategic picture. On performance and price, Grok 4.1 Fast is highly competitive—arguably one of the strongest value propositions in the modern LLM market. </p><p>But xAI’s enterprise appeal will ultimately depend on whether the company can convincingly demonstrate that the alignment instability, susceptibility to adversarial prompting, and bias-amplifying behavior observed on X do not translate into its developer-facing platform. </p><p>Without transparent safeguards, auditability, and reproducible evaluation across the very tools that enable autonomous operation, organizations may hesitate to commit core workloads to a system whose reliability is still the subject of public doubt. </p><p>For now, Grok 4.1 Fast is a technically impressive and economically efficient option—one that enterprises should test, benchmark, and validate rigorously before allowing it to take on mission-critical tas</p>",
      "source": "AI | VentureBeat",
      "source_url": "https://venturebeat.com/category/ai/feed/",
      "author": "carl.franzen@venturebeat.com (Carl Franzen)",
      "tags": [
        "AI"
      ]
    },
    {
      "title": "How to Build a Fully Offline Multi-Tool Reasoning Agent with Dynamic Planning, Error Recovery, and Intelligent Function Routing",
      "url": "https://www.marktechpost.com/2025/11/20/how-to-build-a-fully-offline-multi-tool-reasoning-agent-with-dynamic-planning-error-recovery-and-intelligent-function-routing/",
      "published": "2025-11-21T04:32:41+00:00",
      "date_verified": true,
      "description": "<p>In this tutorial, we explore how to build a fully offline, multi-step reasoning agent that uses the Instructor library to generate structured outputs and reliably orchestrate complex tool calls. In this implementation, we design an agent capable of choosing the right tool, validating inputs, planning multi-stage workflows, and recovering from errors. We bring together Instructor, [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/20/how-to-build-a-fully-offline-multi-tool-reasoning-agent-with-dynamic-planning-error-recovery-and-intelligent-function-routing/\">How to Build a Fully Offline Multi-Tool Reasoning Agent with Dynamic Planning, Error Recovery, and Intelligent Function Routing</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Asif Razzaq",
      "tags": [
        "Agentic AI",
        "AI Agents",
        "Editors Pick",
        "Staff",
        "Tutorials"
      ]
    },
    {
      "title": "1.23.0-beta.0",
      "url": "https://github.com/modelcontextprotocol/typescript-sdk/releases/tag/1.23.0-beta.0",
      "published": "2025-11-21T03:01:34+00:00",
      "date_verified": true,
      "description": "<h2>Special Note: zod v4</h2>\n<p>This <code>beta</code> release adds support for zod v4, a highly requested addition.</p>\n<p>Special thanks to <a class=\"user-mention notranslate\" href=\"https://github.com/dclark27\">@dclark27</a> <a class=\"user-mention notranslate\" href=\"https://github.com/colinhacks\">@colinhacks</a> for all the work on <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1040\">#1040</a> which adds this support while staying backwards compatible with zod v3!</p>\n<p>NOTE: if you run into any issues with zod v4 in this SDK please raise an issue! We'll be monitoring actively for any issues while trying to use zod v4 as it's a highly anticipated update. In order to make this upgrade possible we needed to also require v3.25+ for zod v3. You may need to update your version of zod v3 if you've been using an older one. We're also making this a <code>beta</code> release while we get initial feedback on the update here.</p>\n<h2>What's Changed</h2>\n<ul>\n<li>Migrate to vitest from jest by <a class=\"user-mention notranslate\" href=\"https://github.com/mattzcarey\">@mattzcarey</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1074\">#1074</a></li>\n<li>ci: add workflow_dispatch trigger for manual CI runs by <a class=\"user-mention notranslate\" href=\"https://github.com/felixweinberger\">@felixweinberger</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1114\">#1114</a></li>\n<li>Fix: @types/node incompatibility with vite warnings on npm install by <a class=\"user-mention notranslate\" href=\"https://github.com/KKonstantinov\">@KKonstantinov</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1121\">#1121</a></li>\n<li>Fix: clean up accidental spec.types.ts by <a class=\"user-mention notranslate\" href=\"https://github.com/KKonstantinov\">@KKonstantinov</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1122\">#1122</a></li>\n<li>fix: Pass RequestInit options to auth requests by <a class=\"user-mention notranslate\" href=\"https://github.com/dsp-ant\">@dsp-ant</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1066\">#1066</a></li>\n<li>SEP-1036: URL Elicitation by <a class=\"user-mention notranslate\" href=\"https://github.com/nbarbettini\">@nbarbettini</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1105\">#1105</a></li>\n<li>add none to test and the router. by <a class=\"user-mention notranslate\" href=\"https://github.com/m-henderson\">@m-henderson</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1116\">#1116</a></li>\n<li>[auth] Adjust scope management to line up with SEP-835 by <a class=\"user-mention notranslate\" href=\"https://github.com/pcarleton\">@pcarleton</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1133\">#1133</a></li>\n<li>chore: add .idea/ to .gitignore by <a class=\"user-mention notranslate\" href=\"https://github.com/maxisbey\">@maxisbey</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1134\">#1134</a></li>\n<li>chore: remove unused @types/eslint__js dependency by <a class=\"user-mention notranslate\" href=\"https://github.com/mattzcarey\">@mattzcarey</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1128\">#1128</a></li>\n<li>feat: url based client metadata registration (SEP 991) by <a class=\"user-mention notranslate\" href=\"https://github.com/mattzcarey\">@mattzcarey</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1127\">#1127</a></li>\n<li>feat: zod v4 with backwards compatibility for v3.25+ by <a class=\"user-mention notranslate\" href=\"https://github.com/dclark27\">@dclark27</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1040\">#1040</a></li>\n<li>fix: remove pnpm lock and regenerate package-lock by <a class=\"user-mention notranslate\" href=\"https://github.com/mattzcarey\">@mattzcarey</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1138\">#1138</a></li>\n<li>docs: update installation instructions for zod peer dependency by <a class=\"user-mention notranslate\" href=\"https://github.com/mattzcarey\">@mattzcarey</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1139\">#1139</a></li>\n<li>Implement SEP-1577 - Sampling With Tools by <a class=\"user-mention notranslate\" href=\"https://github.com/ochafik\">@ochafik</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1101\">#1101</a></li>\n<li>Follow up: unify v3 and v4 zod types via describe matrix and a test helper by <a class=\"user-mention notranslate\" href=\"https://github.com/KKonstantinov\">@KKonstantinov</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1141\">#1141</a></li>\n<li>chore: Add deprecated marker to old elicitInput overload by <a class=\"user-mention notranslate\" href=\"https://github.com/nbarbettini\">@nbarbettini</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1142\">#1142</a></li>\n<li>fix: Connect error in URL elicitation example by <a class=\"user-mention notranslate\" href=\"https://github.com/nbarbettini\">@nbarbettini</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1136\">#1136</a></li>\n<li>Support upscoping on insufficient_scope 403 by <a class=\"user-mention notranslate\" href=\"https://github.com/Nayana-Parameswarappa\">@Nayana-Parameswarappa</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1115\">#1115</a></li>\n<li>Support beta releases by publishing with --tag beta by <a class=\"user-mention notranslate\" href=\"https://github.com/felixweinberger\">@felixweinberger</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1146\">#1146</a></li>\n<li>Bump version to 1.23.0-beta.0 by <a class=\"user-mention notranslate\" href=\"https://github.com/felixweinberger\">@felixweinberger</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1147\">#1147</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a class=\"user-mention notranslate\" href=\"https://github.com/nbarbettini\">@nbarbettini</a> made their first contribution in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1105\">#1105</a></li>\n<li><a class=\"user-mention notranslate\" href=\"https://github.com/m-henderson\">@m-henderson</a> made their first contribution in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1116\">#1116</a></li>\n<li><a class=\"user-mention notranslate\" href=\"https://github.com/maxisbey\">@maxisbey</a> made their first contribution in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1134\">#1134</a></li>\n<li><a class=\"user-mention notranslate\" href=\"https://github.com/dclark27\">@dclark27</a> made their first contribution in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1040\">#1040</a></li>\n<li><a class=\"user-mention notranslate\" href=\"https://github.com/Nayana-Parameswarappa\">@Nayana-Parameswarappa</a> made their first contribution in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/pull/1115\">#1115</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a class=\"commit-link\" href=\"https://github.com/modelcontextprotocol/typescript-sdk/compare/1.22.0...1.23.0-beta.0\"><tt>1.22.0...1.23.0-beta.0</tt></a></p>",
      "source": "Release notes from typescript-sdk",
      "source_url": "https://github.com/modelcontextprotocol/typescript-sdk/releases.atom",
      "author": "felixweinberger",
      "tags": []
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/emollick.bsky.social/post/3m63qn2enic25",
      "published": "2025-11-21T02:47:00+00:00",
      "date_verified": true,
      "description": "Tell all the truth but tell it slant—\nSuccess in Circuit lies\nToo bright for our infirm Delight\nThe Truth's superb surprise\n\nThis paper finds poetry is a universal single shot jailbreak for LLMs. Systems built to stop prosaic attacks fail when the request is phrased in verse arxiv.org/abs/2511.15304",
      "source": "@emollick.bsky.social - Ethan Mollick",
      "source_url": "https://bsky.app/profile/emollick.bsky.social/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "Benchmark Scores = General Capability + Claudiness",
      "url": "https://epochai.substack.com/p/benchmark-scores-general-capability",
      "published": "2025-11-21T02:09:33+00:00",
      "date_verified": true,
      "description": "Is this because skills generalize very well, or because developers are pushing on all benchmarks at once?",
      "source": "Epoch AI",
      "source_url": "https://epochai.substack.com/feed",
      "author": "Greg Burnham",
      "tags": []
    },
    {
      "title": "Google's upgraded Nano Banana Pro AI image model hailed as 'absolutely bonkers' for enterprises and users",
      "url": "https://venturebeat.com/ai/googles-upgraded-nano-banana-pro-ai-image-model-hailed-as-absolutely-bonkers",
      "published": "2025-11-21T01:20:00+00:00",
      "date_verified": true,
      "description": "<p>Infographics rendered without a single spelling error. Complex diagrams one-shotted from paragraph prompts. Logos restored from fragments. And visual outputs so sharp with so much text density and accuracy, one developer simply called it “absolutely bonkers.”</p><p>Google DeepMind’s <a href=\"https://blog.google/technology/ai/nano-banana-pro/\">newly released Nano Banana Pro</a>—officially Gemini 3 Pro Image—has drawn astonishment from both the developer community and enterprise AI engineers. </p><p>But behind the viral praise lies something more transformative: a model built not just to impress, but to integrate deeply across Google’s AI stack—from Gemini API and Vertex AI to Workspace apps, Ads, and Google AI Studio.</p><p>Unlike earlier image models, which targeted casual users or artistic use cases, Gemini 3 Pro Image introduces studio-quality, multimodal image generation for structured workflows—with high resolution, multilingual accuracy, layout consistency, and real-time knowledge grounding. It’s engineered for technical buyers, orchestration teams, and enterprise-scale automation, not just creative exploration.</p><p>Benchmarks already show the model outperforming peers in overall visual quality, infographic generation, and text rendering accuracy. And as real-world users push it to its limits—from medical illustrations to AI memes—the model is revealing itself as both a new creative tool and a visual reasoning system for the enterprise stack.</p><h2><b>Built for Structured Multimodal Reasoning</b></h2><p>Gemini 3 Pro Image isn’t just drawing pretty pictures—it’s leveraging the reasoning layer of Gemini 3 Pro to generate visuals that communicate structure, intent, and factual grounding. </p><p>The model is capable of generating UX flows, educational diagrams, storyboards, and mockups from language prompts, and can incorporate up to 14 source images with consistent identity and layout fidelity across subjects.</p><p>Google describes the model as “a higher-fidelity model built on Gemini 3 Pro for developers to access studio-quality image generation,” and confirms it is now available via Gemini API, Google AI Studio, and Vertex AI for enterprise access.</p><p>In Antigravity, Google’s new AI vibe coding platform built by the former Windsurf co-founders it hired earlier this year, Gemini 3 Pro Image is already being used to create dynamic UI prototypes with image assets rendered before code is written. The same capabilities are rolling out to Google’s enterprise-facing products like Workspace Vids, Slides, and Google Ads, giving teams precise control over asset layout, lighting, typography, and image composition.</p><h2><b>High-Resolution Output, Localization, and Real-Time Grounding</b></h2><p>The model supports output resolutions of up to 2K and 4K, and includes studio-level controls over camera angle, color grading, focus, and lighting. It handles multilingual prompts, semantic localization, and in-image text translation, enabling workflows like:</p><ul><li><p>Translating packaging or signage while preserving layout</p></li><li><p>Updating UX mockups for regional markets</p></li><li><p>Generating consistent ad variants with product names and pricing changed by locale</p></li></ul><p>One of the clearest use cases is infographics—both technical and commercial. </p><p>Dr. Derya Unutmaz, an immunologist, generated a full medical illustration describing the stages of CAR-T cell therapy from lab to patient, praising the result as “perfect.” AI educator Dan Mac created a visual guide explaining transformer models “for a non-technical person” and called the result “unbelievable.”</p><p>Even complex structured visuals like full restaurant menus, chalkboard lecture visuals, or multi-character comic strips have been shared online—generated in a single prompt, with coherent typography, layout, and subject continuity.</p><h2><b>Benchmarks Signal a Lead in Compositional Image Generation</b></h2><p>Independent GenAI-Bench results show Gemini 3 Pro Image as a state-of-the-art performer across key categories:</p><ul><li><p>It ranks highest in <b>overall user preference</b>, suggesting strong visual coherence and prompt alignment.</p></li><li><p>It leads in <b>visual quality</b>, ahead of competitors like GPT-Image 1 and Seedream v4.</p></li><li><p>Most notably, it dominates in <b>infographic generation</b>, outscoring even Google’s own previous model, Gemini 2.5 Flash.</p></li></ul><p>Additional benchmarks released by Google show Gemini 3 Pro Image with lower text error rates across multiple languages, as well as stronger performance in image editing fidelity.</p><p>The difference becomes especially apparent in structured reasoning tasks. Where previous models might approximate style or fill in layout gaps, Gemini 3 Pro Image demonstrates consistency across panels, accurate spatial relationships, and context-aware detail preservation—crucial for systems generating diagrams, documentation, or training visuals at scale.</p><h2><b>Pricing Is Competitive for the Quality</b></h2><p>For developers and enterprise teams accessing Gemini 3 Pro Image via the Gemini API or Google AI Studio, pricing is tiered by resolution and usage. </p><p>Input tokens for images are priced at $0.0011 per image (equivalent to 560 tokens or $0.067 per image), while output pricing depends on resolution: standard 1K and 2K images cost approximately $0.134 each (1,120 tokens), and high-resolution 4K images cost $0.24 (2,000 tokens). </p><p>Text input and output are priced in line with Gemini 3 Pro: $2.00 per million input tokens and $12.00 per million output tokens when using the model’s reasoning capabilities. </p><p>The free tier currently does not include access to Nano Banana Pro, and unlike free-tier models, the paid-tier generations are not used to train Google’s systems.</p><p>Here’s a comparison table of major image-generation APIs for developers/enterprises, followed by a discussion of how they stack up (including the tiered pricing for Gemini 3 Pro Image / “Nano Banana Pro”).</p><table><tbody><tr><td><p><b>Model / Service</b></p></td><td><p><b>Approximate Price per Image or Token-Unit</b></p></td><td><p><b>Key Notes / Resolution Tiers</b></p></td></tr><tr><td><p>Google – Gemini 3 Pro Image (Nano Banana Pro)</p></td><td><p>Input (image): ~$0.067 per image (560 tokens). Output: ~$0.134 per image for 1K/2K (1120 tokens), ~$0.24 per image for 4K (2000 tokens). Text: $2.00 per million input tokens &amp; $12.00 per million output tokens (≤200k token context) </p></td><td><p>Tiered by resolution; paid-tier images are <i>not</i> used to train Google’s systems.</p></td></tr><tr><td><p>OpenAI – DALL-E 3 API</p></td><td><p>~ $0.04/image for 1024×1024 standard; ~$0.08/image for larger/resolution/HD. </p></td><td><p>Lower cost per image; resolution and quality tiers adjust pricing.</p></td></tr><tr><td><p>OpenAI – GPT-Image-1 (via Azure/OpenAI)</p></td><td><p>Low tier ~$0.01/image; Medium ~$0.04/image; High ~$0.17/image. </p></td><td><p>Token-based pricing – more complex prompts or higher resolution raise cost.</p></td></tr><tr><td><p>Google – Gemini 2.5 Flash Image (Nano Banana)</p></td><td><p>~$0.039 per image for 1024×1024 resolution (1290 tokens) in output. </p></td><td><p>Lower cost “flash” model for high-volume, lower latency use.</p></td></tr><tr><td><p>Other / Smaller APIs (e.g., via third-party credit systems)</p></td><td><p>Examples: $0.02–$0.03 per image in some cases for lower resolution or simpler models. </p></td><td><p>Often used for less demanding production use cases or draft content.</p></td></tr></tbody></table><p>The Google Gemini 3 Pro Image <!-- -->/ Nano Banana Pro<!-- --> pricing sits at the upper end: ~$0.134 for 1K/2K, ~$0.24 for 4K,  significantly higher than the ~$0.04 per image baseline for many OpenAI/DALL-E 3 standard images. </p><p>But the higher cost might be justifiable if: you require 4K resolution; you need enterprise-grade governance (e.g., Google emphasizes that paid-tier images are <i>not</i> used to train their systems); you need a token-based pricing system aligned with other LLM usage; and you already operate within Google’s cloud/AI stack (e.g., using Vertex AI).</p><p>On the other hand, if you’re generating large volumes of images (thousands to tens of thousands) and can accept lower resolution (1K/2K) or slightly less premium quality, the lower-cost alternatives (OpenAI, smaller models) offer meaningful savings — for instance, generating 10,000 images at ~$0.04 each costs ~$400, whereas at ~$0.134 each it’s ~$1,340. Over time, that delta adds up.</p><h2><b>SynthID and the Growing Need for Enterprise Provenance</b></h2><p>Every image generated by Gemini 3 Pro Image includes SynthID, Google’s imperceptible digital watermarking system. While many platforms are just beginning to explore AI provenance, Google is positioning SynthID as a core part of its enterprise compliance stack.</p><p>In the updated Gemini app, users can now upload an image and ask whether it was AI-generated by Google—a feature designed to support growing regulatory and internal governance demands.</p><p>A Google blog post emphasizes that provenance is no longer a “feature” but an operational requirement, particularly in high-stakes domains like healthcare, education, and media. SynthID also allows teams building on Google Cloud to differentiate between AI-generated content and third-party media across assets, use logs, and audit trails.</p><h2><b>Early Developer Reactions Range from Awe to Edge-Case Testing</b></h2><p>Despite the enterprise framing, early developer reactions have turned social media into a real-time proving ground.</p><p>Designer <a href=\"https://x.com/MrDavids1/status/1991514343666753870\">Travis Davids</a> called out a one-shot restaurant menu with flawless layout and typography: “Long generated text is officially solved.” </p><p>Immunologist <a href=\"https://x.com/DeryaTR_/status/1991541200147607939\">Dr. Derya Unutmaz</a> posted his CAR-T diagram with the caption: “What have you done, Google?!” while<a href=\"https://x.com/nikunj/status/1991550373249876286\"> Nikunj Kothari </a>converted a full essay into a stylized blackboard lecture in one shot, calling the results “simply speechless.”</p><div></div><p>Engineer <a href=\"https://x.com/deedydas/status/1991525559332139041?s=20\">Deedy Das</a> praised its performance across editing and brand restoration tasks: “Photoshop-like editing… It nails everything...By far the best image model I&#x27;ve ever seen.” </p><div></div><p>Developer<a href=\"https://x.com/ParkerOrtolani/status/1991321405728911660\"> Parker Ortolani </a>summarized it more simply: “Nano Banana remains absolutely bonkers.”</p><p>Even meme creators got involved. <a href=\"https://x.com/cto_junior/status/1991564259516702997\">@cto_junior </a>generated a fully styled “LLM discourse desk” meme—with logos, charts, monitors, and all—in one prompt, dubbing Gemini 3 Pro Image “your new meme engine.”</p><p>But scrutiny followed, too. AI researcher <a href=\"https://x.com/scaling01/status/1991553936202063937\">Lisan al Gaib</a> tested the model on a logic-heavy Sudoku problem, showing it hallucinated both an invalid puzzle and a nonsensical solution, noting that the model “is sadly not AGI.” </p><p>The post served as a reminder that visual reasoning has limits, particularly in rule-constrained systems where hallucinated logic remains a persistent failure mode.</p><h2><b>A New Platform Primitive, Not Just a Model</b></h2><p>Gemini 3 Pro Image now lives across Google’s entire enterprise and developer stack: Google Ads, Workspace (Slides, Vids), Vertex AI, Gemini API, and Google AI Studio. It’s also deployed in internal tools like Antigravity, where design agents render layout drafts before interface elements are coded.</p><p>This makes it a first-class multimodal primitive inside Google’s AI ecosystem, much like text completion or speech recognition. </p><p>In enterprise applications, visuals are not decorations—they’re data, documentation, design, and communication. Whether generating onboarding explainers, prototype visuals, or localized collateral, models like Gemini 3 Pro Image allow systems to create assets programmatically, with control, scale, and consistency.</p><p>At a time when the race between OpenAI, Google, and xAI is moving beyond benchmarks and into platforms, Nano Banana Pro is Google’s quiet declaration: the future of generative AI won’t just be spoken or written—it will be seen.</p>",
      "source": "AI | VentureBeat",
      "source_url": "https://venturebeat.com/category/ai/feed/",
      "author": "carl.franzen@venturebeat.com (Carl Franzen)",
      "tags": [
        "AI"
      ]
    },
    {
      "title": "v1.22.0",
      "url": "https://github.com/modelcontextprotocol/python-sdk/releases/tag/v1.22.0",
      "published": "2025-11-21T00:56:49+00:00",
      "date_verified": true,
      "description": "<h2>What's Changed</h2>\n<ul>\n<li>feat: Pass through and expose additional parameters in <code>ClientSessionGroup.call_tool</code> and <code>.connect_to_server</code> by <a class=\"user-mention notranslate\" href=\"https://github.com/inaku-Gyan\">@inaku-Gyan</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/python-sdk/pull/1576\">#1576</a></li>\n<li>chore: Lazy import <code>jsonschema</code> library by <a class=\"user-mention notranslate\" href=\"https://github.com/wuliang229\">@wuliang229</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/python-sdk/pull/1596\">#1596</a></li>\n<li>docs: Update examples to use stateless HTTP with JSON responses by <a class=\"user-mention notranslate\" href=\"https://github.com/domdomegg\">@domdomegg</a> in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/python-sdk/pull/1499\">#1499</a></li>\n</ul>\n<h2>New Contributors</h2>\n<ul>\n<li><a class=\"user-mention notranslate\" href=\"https://github.com/wuliang229\">@wuliang229</a> made their first contribution in <a class=\"issue-link js-issue-link\" href=\"https://github.com/modelcontextprotocol/python-sdk/pull/1596\">#1596</a></li>\n</ul>\n<p><strong>Full Changelog</strong>: <a class=\"commit-link\" href=\"https://github.com/modelcontextprotocol/python-sdk/compare/v1.21.1...v1.22.0\"><tt>v1.21.1...v1.22.0</tt></a></p>",
      "source": "Release notes from python-sdk",
      "source_url": "https://github.com/modelcontextprotocol/python-sdk/releases.atom",
      "author": "maxisbey",
      "tags": []
    },
    {
      "title": "Meta AI Releases Segment Anything Model 3 (SAM 3) for Promptable Concept Segmentation in Images and Videos",
      "url": "https://www.marktechpost.com/2025/11/20/meta-ai-releases-segment-anything-model-3-sam-3-for-promptable-concept-segmentation-in-images-and-videos/",
      "published": "2025-11-21T00:53:01+00:00",
      "date_verified": true,
      "description": "<p>How do you reliably find, segment and track every instance of any concept across large image and video collections using simple prompts? Meta AI Team has just released Meta Segment Anything Model 3, or SAM 3, an open-sourced unified foundation model for promptable segmentation in images and videos that operates directly on visual concepts instead [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/20/meta-ai-releases-segment-anything-model-3-sam-3-for-promptable-concept-segmentation-in-images-and-videos/\">Meta AI Releases Segment Anything Model 3 (SAM 3) for Promptable Concept Segmentation in Images and Videos</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Asif Razzaq",
      "tags": [
        "AI Paper Summary",
        "AI Shorts",
        "Applications",
        "Artificial Intelligence",
        "Computer Vision",
        "Editors Pick",
        "New Releases",
        "Open Source",
        "Staff",
        "Tech News",
        "Technology",
        "Uncategorized",
        "Meta AI Releases Segment Anything Model 3"
      ]
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/emollick.bsky.social/post/3m63idcac522s",
      "published": "2025-11-21T00:19:00+00:00",
      "date_verified": true,
      "description": "Nano banana Pro: “i need a flowchart for how to toast bread, make it as wacky and over the top and complicated as possible.“\n\nNot absolutely perfect, but I can’t believe how much there is a coherent through-line, how clear the text is, and also parts of it are actually funny?",
      "source": "@emollick.bsky.social - Ethan Mollick",
      "source_url": "https://bsky.app/profile/emollick.bsky.social/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "The Pulse #154: Cloudflare takes down half the internet – but shares a great postmortem",
      "url": "https://newsletter.pragmaticengineer.com/p/the-pulse-154",
      "published": "2025-11-20T23:06:09+00:00",
      "date_verified": true,
      "description": "Also: why it&#8217;s not practical to build for CDN redundancy, Google launches AI IDE Antigravity externally while using Jetski internally, more AI fakers caught in remote interviews, and more",
      "source": "The Pragmatic Engineer",
      "source_url": "https://newsletter.pragmaticengineer.com/feed",
      "author": "Gergely Orosz",
      "tags": []
    },
    {
      "title": "Roundtables: Surviving the New Age of Conspiracies",
      "url": "https://www.technologyreview.com/2025/11/20/1127749/roundtables-surviving-the-new-age-of-conspiracies/",
      "published": "2025-11-20T23:03:17+00:00",
      "date_verified": true,
      "description": "Everything is a conspiracy theory now. MIT Technology Review’s series, “The New Conspiracy Age,” explores how this moment is changing science and technology. Watch a discussion with our editors and Mike Rothschild, journalist and conspiracy theory expert, about how we can make sense of them all. Speakers: Amanda Silverman, Editor, Features &#38; Investigations; Niall Firth,&#8230;",
      "source": "MIT Technology Review",
      "source_url": "https://www.technologyreview.com/feed/",
      "author": "MIT Technology Review",
      "tags": [
        "Subscriber-Only Stories"
      ]
    },
    {
      "title": "Evolving GitHub Copilot’s next edit suggestions through custom model training",
      "url": "https://github.blog/ai-and-ml/github-copilot/evolving-github-copilots-next-edit-suggestions-through-custom-model-training/",
      "published": "2025-11-20T23:02:21+00:00",
      "date_verified": true,
      "description": "<p>GitHub Copilot’s next edit suggestions just got faster, smarter, and more precise thanks to new data pipelines, reinforcement learning, and continuous model updates built for in-editor workflows.</p>\n<p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/evolving-github-copilots-next-edit-suggestions-through-custom-model-training/\">Evolving GitHub Copilot’s next edit suggestions through custom model training</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
      "source": "The GitHub Blog",
      "source_url": "https://github.blog/feed/",
      "author": "Kevin Merchant",
      "tags": [
        "AI & ML",
        "GitHub Copilot",
        "AI",
        "developer tools",
        "IDE enhancements",
        "LLMs",
        "model training",
        "Next Edit Suggestions (NES)",
        "VS Code"
      ]
    },
    {
      "title": "How Data Engineering Can Power Manufacturing Industry Transformation",
      "url": "https://www.kdnuggets.com/2025/11/damcosolutions/how-data-engineering-can-power-manufacturing-industry-transformation",
      "published": "2025-11-20T23:00:45+00:00",
      "date_verified": true,
      "description": "Turning scattered information across production-line machines and systems into meaningful insights that help teams drive efficiency and competitiveness without increasing overhead costs.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "KDnuggets",
      "tags": []
    },
    {
      "title": "ScaleOps' new AI Infra Product slashes GPU costs for self-hosted enterprise LLMs by 50% for early adopters",
      "url": "https://venturebeat.com/ai/scaleops-new-ai-infra-product-slashes-gpu-costs-for-self-hosted-enterprise",
      "published": "2025-11-20T22:35:00+00:00",
      "date_verified": true,
      "description": "<p><a href=\"https://scaleops.com/\">ScaleOps</a> has expanded its cloud resource management platform with a new product aimed at enterprises operating self-hosted large language models (LLMs) and GPU-based AI applications. </p><p>The <a href=\"https://www.prnewswire.com/il/news-releases/scaleops-launches-ai-infrastructure-resource-management-product-to-power-self-hosted-ai-at-scale-302621807.html\">AI Infra Product announced today</a>, extends the company’s existing automation capabilities to address a growing need for efficient GPU utilization, predictable performance, and reduced operational burden in large-scale AI deployments. </p><p>The company said the system is already running in enterprise production environments and delivering major efficiency gains for early adopters, reducing GPU costs by between 50% and 70%, according to the company. The company does not publicly list enterprise pricing for this solution and instead invites interested customers to receive a custom quote based on their operation size and needs <a href=\"https://scaleops.com/pricing/\">here</a>.</p><p>In explaining how the system behaves under heavy load, Yodar Shafrir, CEO and Co-Founder of ScaleOps, said in an email to VentureBeat that the platform uses “proactive and reactive mechanisms to handle sudden spikes without performance impact,” noting that its workload rightsizing policies “automatically manage capacity to keep resources available.” </p><p>He added that minimizing GPU cold-start delays was a priority, emphasizing that the system “ensures instant response when traffic surges,” particularly for AI workloads where model load times are substantial.</p><h2><b>Expanding Resource Automation to AI Infrastructure</b></h2><p>Enterprises deploying self-hosted AI models face performance variability, long load times, and persistent underutilization of GPU resources. ScaleOps positioned the new AI Infra Product as a direct response to these issues. </p><p>The platform allocates and scales GPU resources in real time and adapts to changes in traffic demand without requiring alterations to existing model deployment pipelines or application code.</p><p>According to ScaleOps, the system manages production environments for organizations including Wiz, DocuSign, Rubrik, Coupa, Alkami, Vantor, Grubhub, Island, Chewy, and several Fortune 500 companies. </p><p>The AI Infra Product introduces workload-aware scaling policies that proactively and reactively adjust capacity to maintain performance during demand spikes. The company stated that these policies reduce the cold-start delays associated with loading large AI models, which improves responsiveness when traffic increases.</p><h2><b>Technical Integration and Platform Compatibility</b></h2><p>The product is designed for compatibility with common enterprise infrastructure patterns. It works across all Kubernetes distributions, major cloud platforms, on-premises data centers, and air-gapped environments. ScaleOps emphasized that deployment does not require code changes, infrastructure rewrites, or modifications to existing manifests. </p><p>Shafrir said the platform “integrates seamlessly into existing model deployment pipelines without requiring any code or infrastructure changes,” and he added that teams can begin optimizing immediately with their existing GitOps, CI/CD, monitoring, and deployment tooling.</p><p>Shafrir also addressed how the automation interacts with existing systems. He said the platform operates without disrupting workflows or creating conflicts with custom scheduling or scaling logic, explaining that the system “doesn’t change manifests or deployment logic” and instead enhances schedulers, autoscalers, and custom policies by incorporating real-time operational context while respecting existing configuration boundaries.</p><h2><b>Performance, Visibility, and User Control</b></h2><p>The platform provides full visibility into GPU utilization, model behavior, performance metrics, and scaling decisions at multiple levels, including pods, workloads, nodes, and clusters. While the system applies default workload scaling policies, ScaleOps noted that engineering teams retain the ability to tune these policies as needed.</p><p>In practice, the company aims to reduce or eliminate the manual tuning that DevOps and AIOps teams typically perform to manage AI workloads. Installation is intended to require minimal effort, described by ScaleOps as a two-minute process using a single helm flag, after which optimization can be enabled through a single action.</p><h2><b>Cost Savings and Enterprise Case Studies</b></h2><p>ScaleOps reported that early deployments of the AI Infra Product have achieved GPU cost reductions of 50–70% in customer environments. The company cited two examples:</p><ul><li><p>A major creative software company operating thousands of GPUs averaged 20% utilization before adopting ScaleOps. The product increased utilization, consolidated underused capacity, and enabled GPU nodes to scale down. These changes reduced overall GPU spending by more than half. The company also reported a 35% reduction in latency for key workloads.</p></li><li><p>A global gaming company used the platform to optimize a dynamic LLM workload running on hundreds of GPUs. According to ScaleOps, the product increased utilization by a factor of seven while maintaining service-level performance. The customer projected $1.4 million in annual savings from this workload alone.</p></li></ul><p>ScaleOps stated that the expected GPU savings typically outweigh the cost of adopting and operating the platform, and that customers with limited infrastructure budgets have reported fast returns on investment.</p><h2><b>Industry Context and Company Perspective</b></h2><p>The rapid adoption of self-hosted AI models has created new operational challenges for enterprises, particularly around GPU efficiency and the complexity of managing large-scale workloads. Shafrir described the broader landscape as one in which “cloud-native AI infrastructure is reaching a breaking point.”</p><p>“Cloud-native architectures unlocked great flexibility and control, but they also introduced a new level of complexity,” he said in the announcement. “Managing GPU resources at scale has become chaotic—waste, performance issues, and skyrocketing costs are now the norm. The ScaleOps platform was built to fix this. It delivers the complete solution for managing and optimizing GPU resources in cloud-native environments, enabling enterprises to run LLMs and AI applications efficiently, cost-effectively, and while improving performance.”</p><p>Shafrir added that the product brings together the full set of cloud resource management functions needed to manage diverse workloads at scale. The company positioned the platform as a holistic system for continuous, automated optimization.</p><h2><b>A Unified Approach for the Future</b></h2><p>With the addition of the AI Infra Product, ScaleOps aims to establish a unified approach to GPU and AI workload management that integrates with existing enterprise infrastructure. </p><p>The platform’s early performance metrics and reported cost savings suggest a focus on measurable efficiency improvements within the expanding ecosystem of self-hosted AI deployments.</p>",
      "source": "AI | VentureBeat",
      "source_url": "https://venturebeat.com/category/ai/feed/",
      "author": "carl.franzen@venturebeat.com (Carl Franzen)",
      "tags": [
        "AI",
        "Data Infrastructure"
      ]
    },
    {
      "title": "Top SQL Patterns from FAANG Data Science Interviews (with Code)",
      "url": "https://www.kdnuggets.com/top-sql-patterns-from-faang-data-science-interviews-with-code",
      "published": "2025-11-20T22:00:27+00:00",
      "date_verified": true,
      "description": "Here are the top 5 SQL patterns tested in FAANG data science interviews.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "Nate Rosidi",
      "tags": []
    },
    {
      "title": "Key Transparency Comes to Messenger",
      "url": "https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/",
      "published": "2025-11-20T22:00:21+00:00",
      "date_verified": true,
      "description": "<p>We&#8217;re excited to share another advancement in the security of your conversations on Messenger: the launch of key transparency verification for end-to-end encrypted chats.  This new feature enables an additional level of assurance that only you — and the people you&#8217;re communicating with — can see or listen to what is sent, and that no [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/\">Read More...</a></p>\n<p>The post <a href=\"https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/\" rel=\"nofollow\">Key Transparency Comes to Messenger</a> appeared first on <a href=\"https://engineering.fb.com\" rel=\"nofollow\">Engineering at Meta</a>.</p>",
      "source": "Engineering at Meta",
      "source_url": "https://engineering.fb.com/feed/",
      "author": "",
      "tags": [
        "Security & Privacy"
      ]
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/simonwillison.net/post/3m6374k2zys2y",
      "published": "2025-11-20T21:34:00+00:00",
      "date_verified": true,
      "description": "Nano Banana Pro, released this morning, is clearly the best image generation model. Superb instruction following, plus it can generate full infographics (with correct spelling and properly rendered text!) from a short prompt based on running extra searches https://simonwillison.net/2025/Nov/20/nano-banana-pro/",
      "source": "@simonwillison.net - Simon Willison",
      "source_url": "https://bsky.app/profile/simonwillison.net/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "Nano Banana Pro aka gemini-3-pro-image-preview is the best available image generation model",
      "url": "https://simonwillison.net/2025/Nov/20/nano-banana-pro/#atom-everything",
      "published": "2025-11-20T21:32:25+00:00",
      "date_verified": true,
      "description": "<p>Hot on the heels of Tuesday's <a href=\"https://simonwillison.net/2025/Nov/18/gemini-3/\">Gemini 3 Pro</a> release, today it's <a href=\"https://blog.google/technology/ai/nano-banana-pro/\">Nano Banana Pro</a>, also known as <a href=\"https://deepmind.google/models/gemini-image/pro/\">Gemini 3 Pro Image</a>. I've had a few days of preview access and this is an <em>astonishingly</em> capable image generation model.</p>\n<p>As is often the case, the most useful low-level details can be found in <a href=\"https://ai.google.dev/gemini-api/docs/image-generation#gemini-3-capabilities\">the API documentation</a>:</p>\n<blockquote>\n<p>Designed to tackle the most challenging workflows through advanced reasoning, it excels at complex, multi-turn creation and modification tasks.</p>\n<ul>\n<li>\n<strong>High-resolution output</strong>: Built-in generation capabilities for 1K, 2K, and 4K visuals.</li>\n<li>\n<strong>Advanced text rendering</strong>: Capable of generating legible, stylized text for infographics, menus, diagrams, and marketing assets.</li>\n<li>\n<strong>Grounding with Google Search</strong>: The model can use Google Search as a tool to verify facts and generate imagery based on real-time data (e.g., current weather maps, stock charts, recent events).</li>\n<li>\n<strong>Thinking mode</strong>: The model utilizes a \"thinking\" process to reason through complex prompts. It generates interim \"thought images\" (visible in the backend but not charged) to refine the composition before producing the final high-quality output.</li>\n<li>\n<strong>Up to 14 reference images</strong>: You can now mix up to 14 reference images to produce the final image.</li>\n</ul>\n<p>[...] These 14 images can include the following:</p>\n<ul>\n<li>Up to 6 images of objects with high-fidelity to include in the final image</li>\n<li>Up to 5 images of humans to maintain character consistency</li>\n</ul>\n</blockquote>\n<p>There is also a short (6 page) <a href=\"https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Image-Model-Card.pdf\">model card PDF</a> which lists the following as \"new capabilities\" compared to the previous Nano Banana: Multi character editing, Chart editing, Text editing, Factuality - Edu, Multi-input 1-3, Infographics, Doodle editing, Visual design.</p>\n<h4 id=\"trying-out-some-detailed-instruction-image-prompts\">Trying out some detailed instruction image prompts</h4>\n<p>Max Woolf published <a href=\"https://minimaxir.com/2025/11/nano-banana-prompts/#hello-nano-banana\">the definitive guide to prompting Nano Banana</a> just a few days ago. I decided to try his example prompts against the new model, requesting results in 4K.</p>\n<p>Here's what I got for his first test prompt, using Google's <a href=\"https://aistudio.google.com/\">AI Studio</a>:</p>\n<blockquote>\n<p><code>Create an image of a three-dimensional pancake in the shape of a skull, garnished on top with blueberries and maple syrup.</code></p>\n</blockquote>\n<p><img alt=\"A very detailed quality photo of a skull made of pancake batter, blueberries on top, maple syrup dripping down, maple syrup bottle in the background.\" src=\"https://static.simonwillison.net/static/2025/pancake-skull-1.jpg\" /></p>\n<p>The result came out as a 24.1MB, 5632 × 3072 pixel PNG file. I don't want to serve that on my own blog so here's <a href=\"https://drive.google.com/file/d/1QV3pcW1KfbTRQscavNh6ld9PyqG4BRes/view?usp=drive_link\">a Google Drive link for the original</a>.</p>\n<p>Then I ran his follow-up prompt:</p>\n<pre><code>Make ALL of the following edits to the image:\n- Put a strawberry in the left eye socket.\n- Put a blackberry in the right eye socket.\n- Put a mint garnish on top of the pancake.\n- Change the plate to a plate-shaped chocolate-chip cookie.\n- Add happy people to the background.\n</code></pre>\n<p><img alt=\"It's the exact same skull with the requested edits made - mint garnish on the blueberries, a strawberry in the left hand eye socket (from our perspective, technically the skull's right hand socket), a blackberry in the other, the plate is now a plate-sized chocolate chip cookie (admittedly on a regular plate) and there are four happy peo ple in the background.\" src=\"https://static.simonwillison.net/static/2025/pancake-skull-2.jpg\" /></p>\n<p>I'll note that it did put the plate-sized cookie on a regular plate. Here's <a href=\"https://drive.google.com/file/d/18AzhM-BUZAfLGoHWl6MQW_UW9ju4km-i/view?usp=drive_link\">the 24.9MB PNG</a>.</p>\n<p>The new model isn't cheap. Here's <a href=\"https://ai.google.dev/gemini-api/docs/pricing#gemini-3-pro-image-preview\">the API pricing</a>: it's 24 cents for a 4K image and 13.4 cents for a 1K or 2K image. Image inputs are 0.11 cents (just over 1/10th of a cent) each - an earlier version of their pricing page incorrectly said 6.7 cents each but that's now been fixed.</p>\n<p>Unlike most of Google's other models it also isn't available for free via AI Studio: you have to configure an API key with billing in order to use the model there.</p>\n<h4 id=\"creating-an-infographic\">Creating an infographic</h4>\n<p>So this thing is great at following instructions. How about rendering text?</p>\n<p>I tried this prompt, this time using the Gemini consumer app in \"thinking\" mode (which now uses Nano Banana Pro for image generation). <a href=\"https://gemini.google.com/share/d40fe391f309\">Here's a share link</a> - my prompt was:</p>\n<blockquote>\n<p>Infographic explaining how the Datasette open source project works</p>\n</blockquote>\n<p>This is a great opportunity to test its ability to run searches (aka \"Grounding with Google Search\"). Here's what it created based on that 9 word prompt:</p>\n<p><img alt=\"Described by Gemini 3 Pro: A technical architecture diagram titled &quot;How Datasette Works: From Raw Data to Explorable API,&quot; illustrating a workflow from left to right. 1. &quot;RAW DATA SOURCES&quot; include &quot;CSV&quot;, &quot;JSON&quot;, &quot;Excel (XLSX)&quot;, and &quot;Log Files&quot;. 2. These flow into &quot;DATA PREPARATION &amp; CONVERSION&quot; using tools &quot;csvs-to-sqlite&quot; and &quot;sqlite-utils&quot; to create a &quot;SQLite DATABASE&quot;. 3. This feeds into the central &quot;DATASETTE APPLICATION CORE,&quot; a stack comprising &quot;Data Ingestion (Read-Only)&quot;, &quot;Query Engine (SQL)&quot;, &quot;API Layer (JSON)&quot;, and &quot;Web UI Rendering&quot;. 4. A &quot;PLUGIN ECOSYSTEM&quot; connects below the core, listing &quot;Vega Charts&quot;, &quot;Cluster Maps&quot;, &quot;Full-Text Search&quot;, and &quot;Custom Renderers&quot;. 5. To the right, the core branches into &quot;OUTPUT &amp; INTERFACES&quot;: an &quot;Interactive Web Interface (Explore, Filter, Facet)&quot;, a &quot;JSON API (Programmatic Access)&quot; showing a snippet {&quot;data&quot;: [...]}, and a &quot;SQL EDITOR Custom SQL Queries&quot; showing SELECT * FROM.... 6. The API output connects to &quot;PUBLISHING &amp; DEPLOYMENT&quot; via a terminal command datasette publish cloudrun my.db leading to deployment targets &quot;Heroku&quot;, &quot;Google Cloud Run&quot;, &quot;Fly.io&quot;, and &quot;Vercel&quot;.\" src=\"https://static.simonwillison.net/static/2025/nano-banana-datasette.jpg\" /></p>\n<p>That's a pretty extraordinary result for such a simple prompt. The text is all spelled correctly and rendered without glitches. The content is solid too - it even included logos for the most popular publish platforms, and a tiny thumbnail of the Datasette UI which is close-enough for an infographic.</p>\n<p>\"Data Ingestion (Read-Only)\" is a bit off. Everything else looks great to me.</p>\n<p>Here's the thinking trace for that image generation process:</p>\n<blockquote>\n<p><strong>Initiating Datasette Infographic</strong></p>\n<p>I'm starting a detailed infographic about the Datasette project. I plan to use Google Search to gather specific information about its core processes, which I will then visualize in a multi-panel diagram.</p>\n<p><strong>Developing the Datasette workflow</strong></p>\n<p>I am visualizing the Datasette workflow as described in the search results. I'm focusing on the conversion of data from different formats into a SQLite database, which is then presented as a web application complete with a user interface and JSON output.</p>\n<p><strong>Visualizing Datasette Workflow</strong></p>\n<p>I've sketched out the initial structure for the infographic, focusing on a flowchart style. The key components include data input from diverse sources, conversion to SQLite, the Datasette core application, its main features (web UI, JSON API, SQL querying), ecosystem plugins, and finally, deployment options. I aim for clear icons and labels to represent each step. Now I will focus on refining the flow and clarifying the relationships between the parts.</p>\n<p><strong>Defining Core Datasette Stages</strong></p>\n<p>I've sketched out the initial infographic structure. I have identified the key components, focusing on visual representation of the data flow and the key benefits and features of the system. I have made updates to the flowchart with clear icons and labels. Now I'm working to expand the data input section and refine the visual representation of each step.</p>\n<p><strong>Constructing Datasette Infographic</strong></p>\n<p>I am translating the current Datasette workflow outline into visual elements. The input section will show icons for different data formats. I've sketched the data conversion stage with clear illustrations of the necessary tools. I will add a depiction of the Datasette core application, showcasing its interfaces and functions. The plugin ecosystem and deployment options will follow. Now, I am refining the visual representation.</p>\n<p><strong>Analyzing Datasette's Architecture</strong></p>\n<p>I'm currently working on representing the Datasette open-source project's architecture visually. I've broken it down into key components: raw data processing, SQLite conversion, core application functionalities, plugin integration, and deployment methods. I'm focusing on creating a clear, linear representation to show the workflow.</p>\n<p><strong>Mapping the Datasette Flow</strong></p>\n<p>I've crafted a comprehensive graphic to illustrate Datasette's operation. It spans the data ingestion, SQLite conversion, main application features, plugin interactions, and deployment stages, aiming for clarity and a logical flow.</p>\n</blockquote>\n<h4 id=\"detecting-generated-images-with-synthid\">Detecting generated images with SynthID</h4>\n<p>This note from the <a href=\"https://blog.google/technology/ai/nano-banana-pro/\">announcement post</a> caught my eye:</p>\n<blockquote>\n<p>We believe it's critical to know when an image is AI-generated. This is why all media generated by Google's tools are embedded with our imperceptible <a href=\"https://deepmind.google/models/synthid/\">SynthID</a> digital watermark.</p>\n<p>Today, we are putting a powerful verification tool directly in consumers' hands: you can now upload an image into the Gemini app and simply ask if it was generated by Google AI, thanks to SynthID technology. We are starting with images, but will expand to audio and video soon.</p>\n</blockquote>\n<p>Last night I used Nano Banana Pro to generate a fake photograph of raccoons stealing our food delivery, then scrubbed out the little diamond icon using the Apple Photos \"cleanup\" tool. I uploaded that Gemini app and asked \"Was this image created with AI?\":</p>\n<p><img alt=\"Screenshot of a mobile chat interface displaying a conversation about AI image detection. The user has uploaded a photo showing two raccoons on a porch; one raccoon reaches inside a paper bag a bench while the other stands on the ground looking up at it. The conversation title reads &quot;AI Image Creation Confirmed&quot;. The user asks, &quot;Was this image created with ai?&quot; The AI response, labeled &quot;Analysis &amp; 1 more&quot;, states: &quot;Yes, it appears that all or part of this image was created with Google AI. SynthID detected a watermark in 25-50% of the image.&quot;\" src=\"https://static.simonwillison.net/static/2025/nano-banana-detected.jpg\" /></p>\n<p>It replied:</p>\n<blockquote>\n<p>Yes, it appears that all or part of this image was created with Google Al. SynthID detected a watermark in 25-50% of the image.</p>\n</blockquote>\n<p>Presumably that 25-50% figure is because the rest of the photo was taken by me - it was just the raccoons that were added by Nano Banana Pro.</p>\n    \n        <p>Tags: <a href=\"https://simonwillison.net/tags/google\">google</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/datasette\">datasette</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/gemini\">gemini</a>, <a href=\"https://simonwillison.net/tags/text-to-image\">text-to-image</a>, <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a>, <a href=\"https://simonwillison.net/tags/nano-banana\">nano-banana</a></p>",
      "source": "Simon Willison's Weblog",
      "source_url": "https://simonwillison.net/atom/everything/",
      "author": "",
      "tags": [
        "google",
        "ai",
        "datasette",
        "generative-ai",
        "llms",
        "gemini",
        "text-to-image",
        "llm-release",
        "nano-banana"
      ]
    },
    {
      "title": "How to Use Gemini 3 Pro Efficiently",
      "url": "https://towardsdatascience.com/how-to-use-gemini-3-pro-efficiently/",
      "published": "2025-11-20T21:30:00+00:00",
      "date_verified": true,
      "description": "<p>Learn the pros and cons of Gemini 3 Pro, from testing with both coding and console usage</p>\n<p>The post <a href=\"https://towardsdatascience.com/how-to-use-gemini-3-pro-efficiently/\">How to Use Gemini 3 Pro Efficiently</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Eivind Kjosbakken",
      "tags": [
        "Large Language Models",
        "Artificial Intelligence",
        "Gemini",
        "Google Gemini",
        "Llm",
        "Machine Learning"
      ]
    },
    {
      "title": "Data Visualization Explained (Part 5): Visualizing Time-Series Data in Python (Matplotlib, Plotly, and Altair)",
      "url": "https://towardsdatascience.com/data-visualization-explained-part-5-visualizing-time-series-data-in-python-matplotlib-plotly-and-altair/",
      "published": "2025-11-20T20:30:00+00:00",
      "date_verified": true,
      "description": "<p>An explanation of time-series visualization, including in-depth code examples in Matplotlib, Plotly, and Altair.</p>\n<p>The post <a href=\"https://towardsdatascience.com/data-visualization-explained-part-5-visualizing-time-series-data-in-python-matplotlib-plotly-and-altair/\">Data Visualization Explained (Part 5): Visualizing Time-Series Data in Python (Matplotlib, Plotly, and Altair)</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Murtaza Ali",
      "tags": [
        "Data Visualization",
        "Data Science",
        "Editors Pick",
        "Programming",
        "Python"
      ]
    },
    {
      "title": "Data Cleaning at the Command Line for Beginner Data Scientists",
      "url": "https://www.kdnuggets.com/data-cleaning-at-the-command-line-for-beginner-data-scientists",
      "published": "2025-11-20T20:00:19+00:00",
      "date_verified": true,
      "description": "Data cleaning doesn’t always require Python or Excel. Learn how simple command-line tools can help you clean datasets faster and more efficiently.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "Bala Priya C",
      "tags": []
    },
    {
      "title": "OpenAI and Foxconn collaborate to strengthen U.S. manufacturing across the AI supply chain",
      "url": "https://openai.com/index/openai-and-foxconn-collaborate",
      "published": "2025-11-20T19:50:00+00:00",
      "date_verified": true,
      "description": "OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.",
      "source": "OpenAI News",
      "source_url": "https://openai.com/blog/rss.xml",
      "author": "",
      "tags": []
    },
    {
      "title": "Designing digital resilience in the agentic AI era",
      "url": "https://www.technologyreview.com/2025/11/20/1127941/designing-digital-resilience-in-the-agentic-ai-era/",
      "published": "2025-11-20T19:30:00+00:00",
      "date_verified": true,
      "description": "Digital resilience—the ability to prevent, withstand, and recover from digital disruptions—has long been a strategic priority for enterprises. With the rise of agentic AI, the urgency for robust resilience is greater than ever. Agentic AI represents a new generation of autonomous systems capable of proactive planning, reasoning, and executing tasks with minimal human intervention. As&#8230;",
      "source": "MIT Technology Review",
      "source_url": "https://www.technologyreview.com/feed/",
      "author": "MIT Technology Review Insights",
      "tags": [
        "Artificial intelligence",
        "sponsored"
      ]
    },
    {
      "title": "Tome's founders ditch viral presentation app with 20M users to build AI-native CRM Lightfield",
      "url": "https://venturebeat.com/ai/tomes-founders-ditch-viral-presentation-app-with-20m-users-to-build-ai",
      "published": "2025-11-20T19:00:00+00:00",
      "date_verified": true,
      "description": "<p><a href=\"https://lightfield.app/\"><u>Lightfield</u></a>, a customer relationship management platform built entirely around artificial intelligence, officially launched to the public this week after a year of quiet development — a bold pivot by a startup that once had <a href=\"https://www.forbes.com/sites/rashishrivastava/2024/04/23/the-prompt-the-latest-ai-startup-to-face-reality/\"><u>20 million users</u></a> and <a href=\"https://www.forbes.com/sites/alexkonrad/2023/02/22/storytelling-ai-startup-tome-raises-43-million/\"><u>$43 million in the bank</u></a> building something completely different.</p><p>The San Francisco-based company is positioning itself as a fundamental reimagining of how businesses track and manage customer relationships, abandoning the manual data entry that has defined CRMs for decades in favor of a system that automatically captures, organizes, and acts on customer interactions. With more than 100 early customers already using the platform daily — over half spending more than an hour per day in the system — <a href=\"https://lightfield.app/\"><u>Lightfield</u></a> is a direct challenge to the legacy business models of <a href=\"https://www.salesforce.com/\"><u>Salesforce</u></a> and <a href=\"https://www.hubspot.com/\"><u>HubSpot</u></a>, both of which generate billions in annual revenue.</p><p>&quot;The CRM, categorically, is perhaps the most complex and lowest satisfaction piece of software on Earth,&quot; said Keith Peiris, Lightfield&#x27;s co-founder and CEO, in an exclusive interview with VentureBeat. &quot;CRM companies have tens of millions of users, and you&#x27;d be hard-pressed to find a single one who actually loves the product. That problem is our opportunity.&quot;</p><p>The <a href=\"https://lightfield.app/\"><u>general availability</u></a> announcement marks an unusual inflection point in enterprise software: a company betting that large language models have advanced enough to replace structured databases as the foundation of business-critical systems. It&#x27;s a wager that has attracted backing from <a href=\"https://www.coatue.com/\"><u>Coatue Management</u></a>, which led the company&#x27;s Series A when it was still building presentation software under the name Tome.</p><h2><b>How Tome&#x27;s founders abandoned 20 million users to build a CRM from scratch</b></h2><p>The story behind Lightfield&#x27;s creation reflects both conviction and pragmatism. <a href=\"https://www.fastcompany.com/90827339/presentation-tool-tome-launches-ai-to-help-make-storytelling-simpler\"><u>Tome</u></a> had achieved significant viral success as an AI-powered presentation platform, gaining millions of users who appreciated its visual design and ease of use. But Peiris said the team concluded that building lasting differentiation in the general-purpose presentation market would prove difficult, even with a working product and real user traction.</p><p>&quot;Tome went viral as an AI slides product, and it was visually delightful and easy to use—the first real generative AI-based presentation platform,&quot; Peiris explained. &quot;But, the more people used it, the more I realized that to really help people communicate something—anything—we needed more context.&quot;</p><p>That realization led to a fundamental rethinking. The team observed that the most effective communication requires deep understanding of relationships, company dynamics, and ongoing conversations — context that exists most richly in sales and customer-facing roles. Rather than building a horizontal tool for everyone, they decided to build vertically for go-to-market teams.</p><p>&quot;We chose this lane, &#x27;sales,&#x27; because so many people in these roles used Tome, and it seemed like the most logical place to go vertical,&quot; Peiris said. The team reduced headcount to a core group of engineers and spent a year building in stealth.</p><p><a href=\"https://signal.nfx.com/investors/dan-rose\"><u>Dan Rose</u></a>, a senior advisor at <a href=\"https://www.coatue.com/\"><u>Coatue</u></a> who led the original investment in Tome, said the pivot validated his conviction in the founding team. &quot;It takes real guts to pivot, and even more so when the original product is working,&quot; Rose said. &quot;They shrunk the team down to a core group of engineers and got to work building Lightfield. This was not an easy product to build, it is extremely complex under the hood.&quot;</p><h2><b>Why Lightfield stores complete conversations instead of forcing data into fields</b></h2><p>What distinguishes <a href=\"https://lightfield.app/\"><u>Lightfield</u></a> from traditional CRMs is architectural, not cosmetic. While <a href=\"https://www.salesforce.com/\"><u>Salesforce</u></a>, <a href=\"https://www.hubspot.com/\"><u>HubSpot</u></a>, and their competitors require users to define rigid data schemas upfront — dropdown menus, custom fields, checkbox categories — and then manually populate those fields after every interaction, Lightfield stores the complete, unstructured record of what customers actually say and do.</p><p>&quot;Traditional CRMs force every interaction through predefined fields — they&#x27;re compressing rich, nuanced customer conversations into structured database entries,&quot; Peiris said. &quot;We store customer data in its raw, lossless form. That means we&#x27;re capturing significantly more detail and context than a traditional CRM ever could.&quot;</p><p>In practice, this means the system automatically records and transcribes sales calls, ingests emails, monitors product usage, and maintains what the company calls a &quot;relationship timeline&quot; — a complete chronological record of every touchpoint between a company and its customers. AI models then extract structured information from this raw data on demand, allowing companies to reorganize their data model without manual rework.</p><p>&quot;If you realize you need different fields or want to reorganize your schema entirely, the system can remap and refill itself automatically,&quot; Peiris explained. &quot;You&#x27;re not locked into decisions you made on day one when you barely understood your sales process.&quot;</p><p>The system also generates meeting preparation briefs, drafts follow-up emails based on conversation context, and can be queried in natural language — capabilities that represent a departure from the passive database model that has defined CRMs since the category&#x27;s inception in the 1980s.</p><h2><b>Sales teams report reviving dead deals and cutting response times from months to days</b></h2><p>Customer testimonials suggest the automation delivers measurable impact, particularly for small teams without dedicated sales operations staff. Tyler Postle, co-founder of <a href=\"http://voker.ai\"><u>Voker.ai</u></a>, said Lightfield&#x27;s AI agent helped him revive more than 40 stalled opportunities in a single two-hour session — leads he had neglected for six months while using HubSpot.</p><p>&quot;Within 2 days, 10 of those were revived and became active opps that moved to poc,&quot; Postle said. &quot;The problem was, instead of being a tool of action and autotracking—HubSpot was a tool where I had to do the work to record customer convos. Using HubSpot I was a data hygienist. Using Lighfield, I’m a closer.&quot;</p><p>Postle reported that his response times to prospects improved from weeks or months to one or two days, a change noticeable enough that customers commented on it. &quot;Our prospects and customers have even noticed it,&quot; he said.</p><p>Radu Spineanu, co-founder of <a href=\"https://humbleops.ai/\"><u>Humble Ops</u></a>, highlighted a specific feature that addresses what he views as the primary cause of lost deals: simple neglect. &quot;The killer feature is asking &#x27;who haven&#x27;t I followed up with?&#x27;&quot; Spineanu said. &quot;Most deals die from neglect, not rejection. Lightfield catches these dropped threads and can draft and send the follow-up immediately. That&#x27;s prevented at least three deals from going cold this quarter.&quot;</p><p>Spineanu had evaluated competing modern CRMs including <a href=\"https://attio.com/\"><u>Attio</u></a> and <a href=\"https://www.clay.com/\"><u>Clay</u></a> before selecting <a href=\"https://lightfield.app/\"><u>Lightfield</u></a>, dismissing <a href=\"https://www.salesforce.com/\"><u>Salesforce</u></a> and <a href=\"https://www.hubspot.com/\"><u>HubSpot</u></a> as &quot;built for a different era.&quot; He said those platforms assume companies have dedicated operations teams to configure workflows and maintain data quality — resources most early-stage companies lack.</p><h2><b>Why Y Combinator startups are rejecting Salesforce and starting with AI-native tools</b></h2><p>Peiris claims that the current batch of <a href=\"https://www.ycombinator.com/\"><u>Y Combinator</u></a> startups — widely viewed as a bellwether for early-stage company behavior — have largely rejected both <a href=\"https://www.salesforce.com/\"><u>Salesforce</u></a> and <a href=\"https://www.hubspot.com/\"><u>HubSpot</u></a>. &quot;If you were to poll a random sampling of current YC startups and ask whether they&#x27;re using Salesforce or HubSpot, the overwhelming answer would be &#x27;no,&#x27;&quot; he said. &quot;Salesforce is too expensive, too complex to set up, and frankly doesn&#x27;t do enough to justify the investment for an early-stage company.&quot;</p><p>According to Peiris, most startups begin with spreadsheets and eventually graduate to a first CRM — a transition point where Lightfield aims to intercede. &quot;Increasingly, they&#x27;re choosing Lightfield instead and skipping that intermediate step entirely,&quot; he said.</p><p>This represents a familiar pattern in enterprise software disruption: a new generation of companies forming habits around different tools, creating an opening for challengers to establish themselves before businesses grow large enough to face pressure toward industry-standard platforms. The company&#x27;s strategy appears to deliberately target this window, aiming to grow alongside early customers and become embedded in their processes as they scale.</p><h2><b>Can Salesforce and HubSpot retrofit their legacy systems for AI, or is the architecture too old?</b></h2><p>Both <a href=\"https://www.salesforce.com/\"><u>Salesforce</u></a> and <a href=\"https://www.hubspot.com/\"><u>HubSpot</u></a> have announced AI features in recent quarters, adding capabilities like conversation intelligence and automated data entry to their existing platforms. The question facing Lightfield is whether established vendors can incorporate similar capabilities—leveraging their existing customer bases and integrations — or whether fundamental architectural differences create a genuine moat.</p><p>Peiris argues the latter. &quot;The fundamental difference is in how we store data,&quot; he said. &quot;Because we have access to that complete context, the analysis we provide and the work we generate tends to be substantially higher quality than tools built on top of traditional database structures.&quot;</p><p>Existing conversation intelligence tools like <a href=\"https://www.gong.io/\"><u>Gong</u></a> and <a href=\"http://revenue.io\"><u>Revenue.io</u></a>, which analyze sales calls and provide coaching insights, already serve similar functions but require Salesforce instances to operate. Peiris said Lightfield&#x27;s advantage comes from unifying the entire data model rather than layering analysis on top of fragmented systems.</p><p>&quot;We have a more complete picture of each customer because we integrate company knowledge, communication sync, product analytics, and full CRM detail all in one place,&quot; he said. &quot;That unified context means the work being generated in Lightfield—whether it&#x27;s analysis, follow-ups, or insights—tends to be significantly higher quality.&quot;</p><h2><b>The privacy and accuracy concerns that come with AI-automated customer interactions</b></h2><p>The architecture creates obvious risks. Storing complete conversation histories raises privacy concerns, and relying on large language models to extract and interpret information introduces the possibility of errors—what AI researchers call hallucinations.</p><p>Peiris acknowledged both issues directly. On privacy, the company maintains that call recording follows standard practices, with visible notifications that recording is in progress, and that storing sales correspondence mirrors what CRM vendors have done for decades. The company has achieved SOC 2 Type I certification and is pursuing both SOC 2 Type II and HIPAA compliance. &quot;We don&#x27;t train models on customer data, period,&quot; Peiris said.</p><p>On accuracy, he was similarly forthright. &quot;Of course it happens,&quot; Peiris said when asked about misinterpretations. &quot;It&#x27;s impossible to completely eliminate hallucinations when working with large language models.&quot;</p><p>The company&#x27;s approach is to require human approval before sending customer communications or updating critical fields — positioning the system as augmentation rather than full automation. &quot;We&#x27;re building a tool that amplifies human judgment, not one that pretends to replace it entirely,&quot; Peiris said.</p><p>This is a more cautious stance than some AI-native software companies have taken, reflecting both technical realism about current model capabilities and potential liability concerns around customer-facing mistakes.</p><h2><b>How Lightfield plans to consolidate ten different sales tools into one platform</b></h2><p>Lightfield&#x27;s pricing strategy reflects a broader thesis about enterprise software economics. Rather than charging per-seat fees for a point solution, the company is positioning itself as a consolidated platform that can replace multiple specialized tools — sales engagement platforms, conversation intelligence systems, meeting assistants, and the CRM itself.</p><p>&quot;The real problem is that running a modern go-to-market function requires cobbling together 10 different independent point solutions,&quot; Peiris said. &quot;When you pay for 10 separate seat licenses, you&#x27;re essentially paying 10 different companies to solve the same foundational problems over and over again.&quot;</p><p>The company operates primarily through self-service signup rather than enterprise sales teams, which Peiris argues allows for lower pricing while maintaining margins. This is a common playbook among modern SaaS companies but represents a fundamental difference from Salesforce&#x27;s model, which relies heavily on direct sales and customer success teams.</p><p>Whether this approach can support a sustainable business at scale remains unproven. The company&#x27;s current customer base skews heavily toward early-stage startups—more than 100 <a href=\"https://www.ycombinator.com/\"><u>Y Combinator</u></a> companies, according to the company — a segment with limited budgets and high failure rates.</p><p>But Lightfield is betting it can become the system of record for a cohort of fast-growing companies, eventually creating an installed base comparable to how Salesforce established itself decades ago. The company&#x27;s trajectory will likely depend on whether AI capabilities alone provide sufficient differentiation—or whether incumbents can adapt quickly enough to defend their positions.</p><h2><b>The real test: whether sales teams will trust AI enough to let it run their business</b></h2><p>The company has outlined several areas for expansion, including an open platform for workflows and webhooks that would allow third-party integrations. Early customers have specifically requested connections with tools like <a href=\"https://www.apollo.io/\"><u>Apollo</u></a> for prospecting and <a href=\"https://slack.com/\"><u>Slack</u></a> for team communication — gaps that Postle, the <a href=\"http://voker.ai\"><u>Voker.ai</u></a> founder, acknowledged but dismissed as temporary.</p><p>&quot;The fact that HS and Salesforce have these integrations already isn&#x27;t a moat,&quot; Postle said. &quot;HS and Salesforce are going to lose to lightfield because they aren&#x27;t AI native, no matter how much they try to pretend to be.&quot;</p><p>Rose highlighted an unusual use case that emerged during Lightfield&#x27;s own development: the company&#x27;s product team used the CRM itself to analyze customer conversations and identify feature requests. &quot;In this sense, Lightfield more than just a sales database, it&#x27;s a customer intelligence layer,&quot; Rose said.</p><p>This suggests potential applications beyond traditional sales workflows, positioning the system as infrastructure for any function that requires understanding customer needs—product development, customer success, even marketing strategy.</p><p>For now, the company is focused on proving the core value proposition with early-stage companies. But the broader question Lightfield raises extends beyond CRM software specifically: whether AI capabilities have advanced sufficiently to replace structured databases as the foundation of enterprise systems, or whether the current generation of large language models remains too unreliable for business-critical functions.</p><p>The answer will likely emerge not from technical benchmarks but from customer behavior—whether sales teams actually trust AI-generated insights enough to base decisions on them, and whether the efficiency gains justify the inherent unpredictability of working with systems that approximate rather than calculate.</p><p><a href=\"https://lightfield.app/\"><u>Lightfield</u></a> is betting that the trade-off has already shifted in favor of approximation, at least for the millions of salespeople who currently view their CRM as an obstacle rather than an asset. Whether that bet proves correct will help define the next generation of enterprise software.</p>",
      "source": "AI | VentureBeat",
      "source_url": "https://venturebeat.com/category/ai/feed/",
      "author": "michael.nunez@venturebeat.com (Michael Nuñez)",
      "tags": [
        "AI",
        "Software"
      ]
    },
    {
      "title": "How Relevance Models Foreshadowed Transformers for NLP",
      "url": "https://towardsdatascience.com/how-relevance-models-foreshadowed-transformers-for-nlp/",
      "published": "2025-11-20T19:00:00+00:00",
      "date_verified": true,
      "description": "<p>Tracing the history of LLM attention: standing on the shoulders of giants</p>\n<p>The post <a href=\"https://towardsdatascience.com/how-relevance-models-foreshadowed-transformers-for-nlp/\">How Relevance Models Foreshadowed Transformers for NLP</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Sean Moran",
      "tags": [
        "Machine Learning",
        "Artificial Intelligence",
        "Deep Dives",
        "Deep Learning",
        "Llm",
        "Math"
      ]
    },
    {
      "title": "The Download: what’s next for electricity, and living in the conspiracy age",
      "url": "https://www.technologyreview.com/2025/11/20/1128183/the-download-whats-next-for-electricity-and-living-in-the-conspiracy-age/",
      "published": "2025-11-20T18:10:00+00:00",
      "date_verified": true,
      "description": "This is today&#8217;s edition of The Download, our weekday newsletter that provides a daily dose of what&#8217;s going on in the world of technology. Three things to know about the future of electricity The International Energy Agency recently released the latest version of the World Energy Outlook, the annual report that takes stock of the current state&#8230;",
      "source": "MIT Technology Review",
      "source_url": "https://www.technologyreview.com/feed/",
      "author": "Rhiannon Williams",
      "tags": [
        "The Download"
      ]
    },
    {
      "title": "3 Unexpected Uses for NotebookLM",
      "url": "https://www.kdnuggets.com/3-unexpected-uses-for-notebooklm",
      "published": "2025-11-20T18:00:16+00:00",
      "date_verified": true,
      "description": "Check out three use cases for NotebookLM that go beyond the expected functionality of generating FAQs, study guides, or basic summaries.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "Matthew Mayo",
      "tags": []
    },
    {
      "title": "Why I’m Making the Switch to marimo Notebooks",
      "url": "https://towardsdatascience.com/why-im-making-the-switch-to-marimo-notebooks/",
      "published": "2025-11-20T17:30:00+00:00",
      "date_verified": true,
      "description": "<p>A fresh way to think about computational notebooks</p>\n<p>The post <a href=\"https://towardsdatascience.com/why-im-making-the-switch-to-marimo-notebooks/\">Why I’m Making the Switch to marimo Notebooks</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Parul Pandey",
      "tags": [
        "Data Science",
        "Artificial Intelligence",
        "Deep Dives",
        "Machine Learning",
        "Notebooks",
        "Python"
      ]
    },
    {
      "title": "Three things to know about the future of electricity",
      "url": "https://www.technologyreview.com/2025/11/20/1128167/future-of-electricity/",
      "published": "2025-11-20T14:00:00+00:00",
      "date_verified": true,
      "description": "One of the dominant storylines I’ve been following through 2025 is electricity—where and how demand is going up, how much it costs, and how this all intersects with that topic everyone is talking about: AI. Last week, the International Energy Agency released the latest version of the World Energy Outlook, the annual report that takes&#8230;",
      "source": "MIT Technology Review",
      "source_url": "https://www.technologyreview.com/feed/",
      "author": "Casey Crownhart",
      "tags": [
        "Climate change and energy",
        "App",
        "Summary",
        "The Spark"
      ]
    },
    {
      "title": "vLLM vs TensorRT-LLM vs HF TGI vs LMDeploy, A Deep Technical Comparison for Production LLM Inference",
      "url": "https://www.marktechpost.com/2025/11/19/vllm-vs-tensorrt-llm-vs-hf-tgi-vs-lmdeploy-a-deep-technical-comparison-for-production-llm-inference/",
      "published": "2025-11-20T12:21:39+00:00",
      "date_verified": true,
      "description": "<p>Production LLM serving is now a systems problem, not a generate() loop. For real workloads, the choice of inference stack drives your tokens per second, tail latency, and ultimately cost per million tokens on a given GPU fleet. This comparison focuses on 4 widely used stacks: 1. vLLM, PagedAttention as the open baseline Core idea [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/19/vllm-vs-tensorrt-llm-vs-hf-tgi-vs-lmdeploy-a-deep-technical-comparison-for-production-llm-inference/\">vLLM vs TensorRT-LLM vs HF TGI vs LMDeploy, A Deep Technical Comparison for Production LLM Inference</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Michal Sutter",
      "tags": [
        "Artificial Intelligence",
        "Comparison",
        "Editors Pick",
        "Language Model",
        "Large Language Model",
        "Staff",
        "Technology"
      ]
    },
    {
      "title": "Helping 1,000 small businesses build with AI",
      "url": "https://openai.com/index/small-business-ai-jam",
      "published": "2025-11-20T11:00:00+00:00",
      "date_verified": true,
      "description": "OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.",
      "source": "OpenAI News",
      "source_url": "https://openai.com/blog/rss.xml",
      "author": "",
      "tags": []
    },
    {
      "title": "Ai2’s Olmo 3 family challenges Qwen and Llama with efficient, open reasoning and customization",
      "url": "https://venturebeat.com/ai/ai2s-olmo-3-family-challenges-qwen-and-llama-with-efficient-open-reasoning",
      "published": "2025-11-20T10:00:00+00:00",
      "date_verified": true,
      "description": "<p>The <a href=\"https://allenai.org/\"><u>Allen Institute for AI (Ai2)</u></a> hopes to take advantage of an increased demand for customized models and enterprises seeking more transparency from AI models with its latest release.</p><p>Ai2 made the latest addition to its Olmo family of large language models available to organizations, continuing to focus on openness and customization. </p><p>Olmo 3 has a longer context window, more reasoning traces and is better at coding than its previous iteration. This latest version, like the other Olmo releases, is open-sourced under the Apache 2.0 license. Enterprises will have complete transparency into and control over the training data and checkpointing. </p><p>Ai2 will release three versions of Olmo 3:</p><ul><li><p>Olmo 3- Think in both 7B and 32B are considered the flagship reasoning models for advanced research</p></li><li><p>Olmo 3- Base also in both parameters, which is ideal for programming, comprehension, math and long-context reasoning. Ai2 said this version is “ideal for continued pre-training or fine-tuning</p></li><li><p>Olmo 3-Instruct in 7B that is optimized for instruction following, multi-turn dialogue and tool use</p></li></ul><p>The company said Olmo 3- Think is the “first-ever fully open 32B thinking model that generates explicit reasoning-chain-style content.” Olmo-3 Think also has a long context window of 65,000 tokens, perfect for longer-running agentic projects or reasoning over longer documents. </p><p>Noah Smith, Ai2’s senior director of NLP research, told VentureBeat in an interview that many of its customers, from regulated enterprises to research institutions, want to use models that give them assurance about what went into the training. </p><p>“The releases from our friends in the tech world are very cool and super exciting, but there are a lot of people for whom data privacy control over what goes into the model, how the models train and other constraints on how the model can be used as front of mind,” said Smith. </p><p>Developers can access the models on Hugging Face and the Ai2 Playground. </p><p></p><h2>Transparency and customization</h2><p>Smith said models like Olmo 3, which the company believes any organization using its models has to have control over and mold in the way that best works for them.</p><p>“We don&#x27;t believe in one-size-fits-all solutions,” Smith said. It&#x27;s a known thing in the world of machine learning that if you try and build a model that solves all the problems, it ends up not being really the best model for any one problem. There aren&#x27;t formal proofs of that, but it&#x27;s a thing that old timers like me have kind of observed.”</p><p>He added that models with the ability to specialize “are maybe not as flash as getting high scores on math exams” but offer more flexibility for enterprises. </p><p>Olmo 3 allows enterprises to essentially retrain the model by adding to the data mix it learns from. The idea is that businesses can bring in their proprietary sources to guide the model in answering specific company queries. To help enterprises during this process, Ai2 added checkpoints from every major training phase. </p><p>Demand for model customization has grown as enterprises that cannot build their own LLMs want to create company-specific or industry-focused models. Startups like <a href=\"https://tfwiki.net/wiki/Arcee_(G1)\"><u>Arcee</u></a> have <a href=\"https://venturebeat.com/ai/arcee-opens-up-new-enterprise-focused-customizable-ai-model-afm-4-5b-trained-on-clean-rigorously-filtered-data\"><u>begun offering</u></a> enterprise-focused, customizable small models. </p><p>Models like Olmo 3, Smith said, also give enterprises more confidence in the technology. Since Olmo 3 provides the training data, Smith said enterprises can trust that the model did not ingest anything it shouldn’t have.</p><p>Ai2 has always claimed to be committed to greater transparency, even launching a tool called <a href=\"https://venturebeat.com/ai/whats-inside-the-llm-ai2-olmotrace-will-trace-the-source\"><u>OlmoTrace in April</u></a> that can track a model’s output directly back to the original training data. The company releases open-sourced models and posts its code to repositories like GitHub for anyone to use. </p><p>Competitors like Google and OpenAI have <a href=\"https://venturebeat.com/ai/googles-gemini-transparency-cut-leaves-enterprise-developers-debugging-blind\"><u>faced criticism from developers</u></a> over moves that hid raw reasoning tokens and chose to summarize reasoning, claiming that they now resort to “debugging blind” without transparency. </p><p>Ai2 pretrained Olmo 3 on the six-trillion-token open source dataset, Dolma 3. The dataset encompasses web data, scientific literature and code. Smith said they optimized Olmo 3 for code, compared to the focus on math for Olmo 2. </p><h2>How it stacks up</h2><p>Ai2 claims that the Olmo 3 family of models represents a significant leap for truly open-source models, at least for open-source LLMs developed outside China. The base Olmo 3 model trained “with roughly 2.5x greater compute efficiency as measured by GPU-hours per token,” meaning it consumed less energy during pre-training and costs less.</p><p>The company said the Olmo 3 models outperformed other open models, such as Marin from Stanford, LLM360’s K2, and Apertus, though Ai2 did not provide figures for the benchmark testing. </p><p>“Of note, Olmo 3-Think (32B) is the strongest fully open reasoning model, narrowing the gap to the best open-weight models of similar scale, such as the Qwen 3-32B-Thinking series of models across our suite of reasoning benchmarks, all while being trained on 6x fewer tokens,” Ai2 said in a press release. </p><p>The company added that Olmo 3-Instruct performed better than Qwen 2.5, Gemma 3 and Llama 3.1.</p><p>\n\n</p><p> </p><p>\n</p>",
      "source": "AI | VentureBeat",
      "source_url": "https://venturebeat.com/category/ai/feed/",
      "author": "",
      "tags": [
        "AI"
      ]
    },
    {
      "title": "OpenAI Debuts GPT-5.1-Codex-Max, a Long-Horizon Agentic Coding Model With Compaction for Multi-Window Workflows",
      "url": "https://www.marktechpost.com/2025/11/19/openai-debuts-gpt-5-1-codex-max-a-long-horizon-agentic-coding-model-with-compaction-for-multi-window-workflows/",
      "published": "2025-11-20T08:55:27+00:00",
      "date_verified": true,
      "description": "<p>OpenAI has introduced GPT-5.1-Codex-Max, a frontier agentic coding model designed for long running software engineering tasks that span millions of tokens and multi hour sessions. It is available today inside Codex in the CLI, IDE extension, cloud integration and code review surfaces, with API access planned soon. What GPT-5.1-Codex-Max is optimised for? GPT-5.1-Codex-Max is built [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/19/openai-debuts-gpt-5-1-codex-max-a-long-horizon-agentic-coding-model-with-compaction-for-multi-window-workflows/\">OpenAI Debuts GPT-5.1-Codex-Max, a Long-Horizon Agentic Coding Model With Compaction for Multi-Window Workflows</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Michal Sutter",
      "tags": [
        "Agentic AI",
        "AI Agents",
        "Editors Pick",
        "New Releases"
      ]
    },
    {
      "title": "How Jimdo empower solopreneurs with AI-powered business assistance",
      "url": "https://blog.langchain.com/customers-jimdo/",
      "published": "2025-11-20T06:47:31+00:00",
      "date_verified": true,
      "description": "See how Jimdo uses LangChain.js, LangGraph.js, and LangSmith to deliver personalized business insights that drive 50% more first customer contacts and 40% more overall customer activity.",
      "source": "LangChain Blog",
      "source_url": "https://blog.langchain.dev/rss/",
      "author": "LangChain",
      "tags": [
        "Case Studies"
      ]
    },
    {
      "title": "Quoting Nicholas Carlini",
      "url": "https://simonwillison.net/2025/Nov/20/nicholas-carlini/#atom-everything",
      "published": "2025-11-20T06:01:44+00:00",
      "date_verified": true,
      "description": "<blockquote cite=\"https://nicholas.carlini.com/writing/2025/are-llms-worth-it.html\"><p>Previously, when malware developers wanted to go and monetize their exploits, they would do exactly one thing: encrypt every file on a person's computer and request a ransome to decrypt the files. In the future I think this will change.</p>\n<p>LLMs allow attackers to instead process every file on the victim's computer, and tailor a blackmail letter specifically towards that person. One person may be having an affair on their spouse. Another may have lied on their resume. A third may have cheated on an exam at school. It is unlikely that any one person has done any of these specific things, but it is very likely that there exists something that is blackmailable for every person. Malware + LLMs, given access to a person's computer, can find that and monetize it.</p></blockquote>\n<p class=\"cite\">&mdash; <a href=\"https://nicholas.carlini.com/writing/2025/are-llms-worth-it.html\">Nicholas Carlini</a>, Are large language models worth it? Misuse: malware at scale</p>\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai-ethics\">ai-ethics</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/nicholas-carlini\">nicholas-carlini</a>, <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a></p>",
      "source": "Simon Willison's Weblog",
      "source_url": "https://simonwillison.net/atom/everything/",
      "author": "",
      "tags": [
        "ai-ethics",
        "generative-ai",
        "nicholas-carlini",
        "ai",
        "llms"
      ]
    },
    {
      "title": "Early experiments in accelerating science with GPT-5",
      "url": "https://openai.com/index/accelerating-science-gpt-5",
      "published": "2025-11-20T05:00:00+00:00",
      "date_verified": true,
      "description": "OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.",
      "source": "OpenAI News",
      "source_url": "https://openai.com/blog/rss.xml",
      "author": "",
      "tags": []
    },
    {
      "title": "Introducing AnyLanguageModel: One API for Local and Remote LLMs on Apple Platforms",
      "url": "https://huggingface.co/blog/anylanguagemodel",
      "published": "2025-11-20T05:00:00+00:00",
      "date_verified": true,
      "description": "",
      "source": "Hugging Face - Blog",
      "source_url": "https://huggingface.co/blog/feed.xml",
      "author": "",
      "tags": []
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/simonwillison.net/post/3m5zf3yidws26",
      "published": "2025-11-20T04:16:00+00:00",
      "date_verified": true,
      "description": "Notes on GPT-5.1-Codex-Max - remember when GPT-5 was meant to signal and end to confusing model names? https://simonwillison.net/2025/Nov/19/gpt-51-codex-max/",
      "source": "@simonwillison.net - Simon Willison",
      "source_url": "https://bsky.app/profile/simonwillison.net/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "Building more with GPT-5.1-Codex-Max",
      "url": "https://simonwillison.net/2025/Nov/19/gpt-51-codex-max/#atom-everything",
      "published": "2025-11-20T04:15:10+00:00",
      "date_verified": true,
      "description": "<p><strong><a href=\"https://openai.com/index/gpt-5-1-codex-max/\">Building more with GPT-5.1-Codex-Max</a></strong></p>\nHot on the heels of yesterday's <a href=\"https://simonwillison.net/2025/Nov/18/gemini-3/\">Gemini 3 Pro release</a> comes a new model from OpenAI called GPT-5.1-Codex-Max.</p>\n<p>(Remember when GPT-5 was meant to bring in a new era of less confusing model names? That didn't last!)</p>\n<p>It's currently only available through their <a href=\"https://developers.openai.com/codex/cli/\">Codex CLI coding agent</a>, where it's the new default model:</p>\n<blockquote>\n<p>Starting today, GPT‑5.1-Codex-Max will replace GPT‑5.1-Codex as the default model in Codex surfaces. Unlike GPT‑5.1, which is a general-purpose model, we recommend using GPT‑5.1-Codex-Max and the Codex family of models only for agentic coding tasks in Codex or Codex-like environments.</p>\n</blockquote>\n<p>It's not available via the API yet but should be shortly.</p>\n<p>The timing of this release is interesting given that Gemini 3 Pro appears to have <a href=\"https://simonwillison.net/2025/Nov/18/gemini-3/#benchmarks\">aced almost all of the benchmarks</a> just yesterday. It's reminiscent of the period in 2024 when OpenAI consistently made big announcements that happened to coincide with Gemini releases.</p>\n<p>OpenAI's self-reported <a href=\"https://openai.com/index/introducing-swe-bench-verified/\">SWE-Bench Verified</a> score is particularly notable: 76.5% for thinking level \"high\" and 77.9% for the new \"xhigh\". That was the one benchmark where Gemini 3 Pro was out-performed by Claude Sonnet 4.5 - Gemini 3 Pro got 76.2% and Sonnet 4.5 got 77.2%. OpenAI now have the highest scoring model there by a full .7 of a percentage point!</p>\n<p>They also report a score of 58.1% on <a href=\"https://www.tbench.ai/leaderboard/terminal-bench/2.0\">Terminal Bench 2.0</a>, beating Gemini 3 Pro's 54.2% (and Sonnet 4.5's 42.8%.)</p>\n<p>The most intriguing part of this announcement concerns the model's approach to long context problems:</p>\n<blockquote>\n<p>GPT‑5.1-Codex-Max is built for long-running, detailed work. It’s our first model natively trained to operate across multiple context windows through a process called <em>compaction</em>, coherently working over millions of tokens in a single task. [...]</p>\n<p>Compaction enables GPT‑5.1-Codex-Max to complete tasks that would have previously failed due to context-window limits, such as complex refactors and long-running agent loops by pruning its history while preserving the most important context over long horizons. In Codex applications, GPT‑5.1-Codex-Max automatically compacts its session when it approaches its context window limit, giving it a fresh context window. It repeats this process until the task is completed.</p>\n</blockquote>\n<p>There's a lot of confusion <a href=\"https://news.ycombinator.com/item?id=45982649\">on Hacker News</a> about what this actually means. Claude Code already does a version of compaction, automatically summarizing previous turns when the context runs out. Does this just mean that Codex-Max is better at that process?</p>\n<p>I had it draw me a couple of pelicans by typing \"Generate an SVG of a pelican riding a bicycle\" directly into the Codex CLI tool. Here's thinking level medium:</p>\n<p><img alt=\"A flat-style illustration shows a white, round-bodied bird with an orange beak pedaling a red-framed bicycle with thin black wheels along a sandy beach, with a calm blue ocean and clear sky in the background.\" src=\"https://static.simonwillison.net/static/2025/codex-max-medium.jpg\" /></p>\n<p>And here's thinking level \"xhigh\":</p>\n<p><img alt=\"A plump white bird with an orange beak and small black eyes crouches low on a blue bicycle with oversized dark wheels, shown racing forward with motion lines against a soft gradient blue sky.\" src=\"https://static.simonwillison.net/static/2025/codex-max-xhigh.jpg\" /></p>\n<p>I also tried xhigh on the my <a href=\"https://simonwillison.net/2025/Nov/18/gemini-3/#and-a-new-pelican-benchmark\">longer pelican test prompt</a>, which came out like this:</p>\n<p><img alt=\"A stylized dark gray bird with layered wings, a yellow head crest, and a long brown beak leans forward in a racing pose on a black-framed bicycle, riding across a glossy blue surface under a pale sky.\" src=\"https://static.simonwillison.net/static/2025/codex-breeding-max-xhigh.jpg\" /></p>\n<p>Also today: <a href=\"https://x.com/openai/status/1991266192905179613\">GPT-5.1 Pro is rolling out today to all Pro users</a>. According to the <a href=\"https://help.openai.com/en/articles/6825453-chatgpt-release-notes\">ChatGPT release notes</a>:</p>\n<blockquote>\n<p>GPT-5.1 Pro is rolling out today for all ChatGPT Pro users and is available in the model picker. GPT-5 Pro will remain available as a legacy model for 90 days before being retired.</p>\n</blockquote>\n<p>That's a pretty fast deprecation cycle for the GPT-5 Pro model that was released just three months ago.\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=45982649\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/openai\">openai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a>, <a href=\"https://simonwillison.net/tags/evals\">evals</a>, <a href=\"https://simonwillison.net/tags/pelican-riding-a-bicycle\">pelican-riding-a-bicycle</a>, <a href=\"https://simonwillison.net/tags/llm-release\">llm-release</a>, <a href=\"https://simonwillison.net/tags/gpt-5\">gpt-5</a>, <a href=\"https://simonwillison.net/tags/codex-cli\">codex-cli</a></p>",
      "source": "Simon Willison's Weblog",
      "source_url": "https://simonwillison.net/atom/everything/",
      "author": "",
      "tags": [
        "ai",
        "openai",
        "generative-ai",
        "llms",
        "evals",
        "pelican-riding-a-bicycle",
        "llm-release",
        "gpt-5",
        "codex-cli"
      ]
    },
    {
      "title": "Google Antigravity Makes the IDE a Control Plane for Agentic Coding",
      "url": "https://www.marktechpost.com/2025/11/19/google-antigravity-makes-the-ide-a-control-plane-for-agentic-coding/",
      "published": "2025-11-20T04:02:27+00:00",
      "date_verified": true,
      "description": "<p>Google has introduced Antigravity as an agentic development platform that sits on top of Gemini 3. It is not only an autocomplete layer, it is an IDE where agents plan, execute, and explain complex software tasks across editor, terminal, and browser surfaces. Antigravity was launched on November 18, 2025, alongside Gemini 3 as part of [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/19/google-antigravity-makes-the-ide-a-control-plane-for-agentic-coding/\">Google Antigravity Makes the IDE a Control Plane for Agentic Coding</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Michal Sutter",
      "tags": [
        "Agentic AI",
        "AI Agents",
        "Editors Pick",
        "New Releases"
      ]
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/simonwillison.net/post/3m5zb43m4mc23",
      "published": "2025-11-20T03:04:00+00:00",
      "date_verified": true,
      "description": "Made a video demonstrating the slightly absurd collection of digital duct tape I use to automate the sending of my Substack newsletter, despite Substack not offering an API https://www.youtube.com/watch?v=BoPZltKDM-s",
      "source": "@simonwillison.net - Simon Willison",
      "source_url": "https://bsky.app/profile/simonwillison.net/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "How I automate my Substack newsletter with content from my blog",
      "url": "https://simonwillison.net/2025/Nov/19/how-i-automate-my-substack-newsletter/#atom-everything",
      "published": "2025-11-20T03:00:34+00:00",
      "date_verified": true,
      "description": "<p>I sent out <a href=\"https://simonw.substack.com/p/trying-out-gemini-3-pro-with-audio\">my weekly-ish Substack newsletter</a> this morning and took the opportunity to record <a href=\"https://www.youtube.com/watch?v=BoPZltKDM-s\">a YouTube video</a> demonstrating my process and describing the different components that make it work. There's a <em>lot</em> of digital duct tape involved, taking the content from Django+Heroku+PostgreSQL to GitHub Actions to SQLite+Datasette+Fly.io to JavaScript+Observable and finally to Substack.</p>\n\n<p> </p>\n\n<p>The core process is the same as I described <a href=\"https://simonwillison.net/2023/Apr/4/substack-observable/\">back in 2023</a>. I have an Observable notebook called <a href=\"https://observablehq.com/@simonw/blog-to-newsletter\">blog-to-newsletter</a> which fetches content from my blog's database, filters out anything that has been in the newsletter before, formats what's left as HTML and offers a big \"Copy rich text newsletter to clipboard\" button.</p>\n<p><img alt=\"Screenshot of the interface. An item in a list says 9080: Trying out Gemini 3 Pro with audio transcription and a new pelican benchmark. A huge button reads Copy rich text newsletter to clipboard - below is a smaller button that says Copy just the links/quotes/TILs. A Last X days slider is set to 2. There are checkboxes for SKip content sent in prior newsletters and only include post content prior to the cutoff comment.\" src=\"https://static.simonwillison.net/static/2025/copy-to-newsletter.jpg\" /></p>\n<p>I click that button, paste the result into the Substack editor, tweak a few things and hit send. The whole process usually takes just a few minutes.</p>\n<p>I make very minor edits:</p>\n<ul>\n<li>I set the title and the subheading for the newsletter. This is often a direct copy of the title of the featured blog post.</li>\n<li>Substack turns YouTube URLs into embeds, which often isn't what I want - especially if I have a YouTube URL inside a code example.</li>\n<li>Blocks of preformatted text often have an extra blank line at the end, which I remove.</li>\n<li>Occasionally I'll make a content edit - removing a piece of content that doesn't fit the newsletter, or fixing a time reference like \"yesterday\" that doesn't make sense any more.</li>\n<li>I pick the featured image for the newsletter and add some tags.</li>\n</ul>\n<p>That's the whole process!</p>\n<h4 id=\"the-observable-notebook\">The Observable notebook</h4>\n<p>The most important cell in the Observable notebook is this one:</p>\n<div class=\"highlight highlight-source-js\"><pre><span class=\"pl-s1\">raw_content</span> <span class=\"pl-c1\">=</span> <span class=\"pl-kos\">{</span>\n  <span class=\"pl-c1\">return</span> <span class=\"pl-s1\">await</span> <span class=\"pl-kos\">(</span>\n    <span class=\"pl-k\">await</span> <span class=\"pl-en\">fetch</span><span class=\"pl-kos\">(</span>\n      <span class=\"pl-s\">`https://datasette.simonwillison.net/simonwillisonblog.json?sql=<span class=\"pl-s1\"><span class=\"pl-kos\">${</span><span class=\"pl-en\">encodeURIComponent</span><span class=\"pl-kos\">(</span></span></span>\n<span class=\"pl-s\"><span class=\"pl-s1\">        <span class=\"pl-s1\">sql</span></span></span>\n<span class=\"pl-s\"><span class=\"pl-s1\">      <span class=\"pl-kos\">)</span><span class=\"pl-kos\">}</span></span>&amp;_shape=array&amp;numdays=<span class=\"pl-s1\"><span class=\"pl-kos\">${</span><span class=\"pl-s1\">numDays</span><span class=\"pl-kos\">}</span></span>`</span>\n    <span class=\"pl-kos\">)</span>\n  <span class=\"pl-kos\">)</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">json</span><span class=\"pl-kos\">(</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n<span class=\"pl-kos\">}</span></pre></div>\n<p>This uses the JavaScript <code>fetch()</code> function to pull data from my blog's Datasette instance, using a very complex SQL query that is composed elsewhere in the notebook.</p>\n<p>Here's a link to <a href=\"https://datasette.simonwillison.net/simonwillisonblog?sql=with+content+as+%28%0D%0A++select%0D%0A++++id%2C%0D%0A++++%27entry%27+as+type%2C%0D%0A++++title%2C%0D%0A++++created%2C%0D%0A++++slug%2C%0D%0A++++%27%3Ch3%3E%3Ca+href%3D%22%27+%7C%7C+%27https%3A%2F%2Fsimonwillison.net%2F%27+%7C%7C+strftime%28%27%25Y%2F%27%2C+created%29%0D%0A++++++%7C%7C+substr%28%27JanFebMarAprMayJunJulAugSepOctNovDec%27%2C+%28strftime%28%27%25m%27%2C+created%29+-+1%29+*+3+%2B+1%2C+3%29+%0D%0A++++++%7C%7C+%27%2F%27+%7C%7C+cast%28strftime%28%27%25d%27%2C+created%29+as+integer%29+%7C%7C+%27%2F%27+%7C%7C+slug+%7C%7C+%27%2F%27+%7C%7C+%27%22%3E%27+%0D%0A++++++%7C%7C+title+%7C%7C+%27%3C%2Fa%3E+-+%27+%7C%7C+date%28created%29+%7C%7C+%27%3C%2Fh3%3E%27+%7C%7C+body%0D%0A++++++as+html%2C%0D%0A++++%27null%27+as+json%2C%0D%0A++++%27%27+as+external_url%0D%0A++from+blog_entry%0D%0A++union+all%0D%0A++select%0D%0A++++id%2C%0D%0A++++%27blogmark%27+as+type%2C%0D%0A++++link_title%2C%0D%0A++++created%2C%0D%0A++++slug%2C%0D%0A++++%27%3Cp%3E%3Cstrong%3ELink%3C%2Fstrong%3E+%27+%7C%7C+date%28created%29+%7C%7C+%27+%3Ca+href%3D%22%27%7C%7C+link_url+%7C%7C+%27%22%3E%27%0D%0A++++++%7C%7C+link_title+%7C%7C+%27%3C%2Fa%3E%3A%3C%2Fp%3E%3Cp%3E%27+%7C%7C+%27+%27+%7C%7C+replace%28commentary%2C+%27%0D%0A%27%2C+%27%3Cbr%3E%27%29+%7C%7C+%27%3C%2Fp%3E%27%0D%0A++++++as+html%2C%0D%0A++++json_object%28%0D%0A++++++%27created%27%2C+date%28created%29%2C%0D%0A++++++%27link_url%27%2C+link_url%2C%0D%0A++++++%27link_title%27%2C+link_title%2C%0D%0A++++++%27commentary%27%2C+commentary%2C%0D%0A++++++%27use_markdown%27%2C+use_markdown%0D%0A++++%29+as+json%2C%0D%0A++link_url+as+external_url%0D%0A++from+blog_blogmark%0D%0A++union+all%0D%0A++select%0D%0A++++id%2C%0D%0A++++%27quotation%27+as+type%2C%0D%0A++++source%2C%0D%0A++++created%2C%0D%0A++++slug%2C%0D%0A++++%27%3Cstrong%3Equote%3C%2Fstrong%3E+%27+%7C%7C+date%28created%29+%7C%7C%0D%0A++++%27%3Cblockquote%3E%3Cp%3E%3Cem%3E%27+%7C%7C%0D%0A++++replace%28quotation%2C+%27%0D%0A%27%2C+%27%3Cbr%3E%27%29+%7C%7C+%0D%0A++++%27%3C%2Fem%3E%3C%2Fp%3E%3C%2Fblockquote%3E%3Cp%3E%3Ca+href%3D%22%27+%7C%7C%0D%0A++++coalesce%28source_url%2C+%27%23%27%29+%7C%7C+%27%22%3E%27+%7C%7C+source+%7C%7C+%27%3C%2Fa%3E%27+%7C%7C%0D%0A++++case+%0D%0A++++++++when+nullif%28trim%28context%29%2C+%27%27%29+is+not+null+%0D%0A++++++++then+%27%2C+%27+%7C%7C+context+%0D%0A++++++++else+%27%27+%0D%0A++++end+%7C%7C%0D%0A++++%27%3C%2Fp%3E%27+as+html%2C%0D%0A++++%27null%27+as+json%2C%0D%0A++++source_url+as+external_url%0D%0A++from+blog_quotation%0D%0A++union+all%0D%0A++select%0D%0A++++id%2C%0D%0A++++%27note%27+as+type%2C%0D%0A++++case%0D%0A++++++when+title+is+not+null+and+title+%3C%3E+%27%27+then+title%0D%0A++++++else+%27Note+on+%27+%7C%7C+date%28created%29%0D%0A++++end%2C%0D%0A++++created%2C%0D%0A++++slug%2C%0D%0A++++%27No+HTML%27%2C%0D%0A++++json_object%28%0D%0A++++++%27created%27%2C+date%28created%29%2C%0D%0A++++++%27link_url%27%2C+%27https%3A%2F%2Fsimonwillison.net%2F%27+%7C%7C+strftime%28%27%25Y%2F%27%2C+created%29%0D%0A++++++%7C%7C+substr%28%27JanFebMarAprMayJunJulAugSepOctNovDec%27%2C+%28strftime%28%27%25m%27%2C+created%29+-+1%29+*+3+%2B+1%2C+3%29+%0D%0A++++++%7C%7C+%27%2F%27+%7C%7C+cast%28strftime%28%27%25d%27%2C+created%29+as+integer%29+%7C%7C+%27%2F%27+%7C%7C+slug+%7C%7C+%27%2F%27%2C%0D%0A++++++%27link_title%27%2C+%27%27%2C%0D%0A++++++%27commentary%27%2C+body%2C%0D%0A++++++%27use_markdown%27%2C+1%0D%0A++++%29%2C%0D%0A++++%27%27+as+external_url%0D%0A++from+blog_note%0D%0A++union+all%0D%0A++select%0D%0A++++rowid%2C%0D%0A++++%27til%27+as+type%2C%0D%0A++++title%2C%0D%0A++++created%2C%0D%0A++++%27null%27+as+slug%2C%0D%0A++++%27%3Cp%3E%3Cstrong%3ETIL%3C%2Fstrong%3E+%27+%7C%7C+date%28created%29+%7C%7C+%27+%3Ca+href%3D%22%27%7C%7C+%27https%3A%2F%2Ftil.simonwillison.net%2F%27+%7C%7C+topic+%7C%7C+%27%2F%27+%7C%7C+slug+%7C%7C+%27%22%3E%27+%7C%7C+title+%7C%7C+%27%3C%2Fa%3E%3A%27+%7C%7C+%27+%27+%7C%7C+substr%28html%2C+1%2C+instr%28html%2C+%27%3C%2Fp%3E%27%29+-+1%29+%7C%7C+%27+%26%238230%3B%3C%2Fp%3E%27+as+html%2C%0D%0A++++%27null%27+as+json%2C%0D%0A++++%27https%3A%2F%2Ftil.simonwillison.net%2F%27+%7C%7C+topic+%7C%7C+%27%2F%27+%7C%7C+slug+as+external_url%0D%0A++from+til%0D%0A%29%2C%0D%0Acollected+as+%28%0D%0A++select%0D%0A++++id%2C%0D%0A++++type%2C%0D%0A++++title%2C%0D%0A++++case%0D%0A++++++when+type+%3D+%27til%27%0D%0A++++++then+external_url%0D%0A++++++else+%27https%3A%2F%2Fsimonwillison.net%2F%27+%7C%7C+strftime%28%27%25Y%2F%27%2C+created%29%0D%0A++++++%7C%7C+substr%28%27JanFebMarAprMayJunJulAugSepOctNovDec%27%2C+%28strftime%28%27%25m%27%2C+created%29+-+1%29+*+3+%2B+1%2C+3%29+%7C%7C+%0D%0A++++++%27%2F%27+%7C%7C+cast%28strftime%28%27%25d%27%2C+created%29+as+integer%29+%7C%7C+%27%2F%27+%7C%7C+slug+%7C%7C+%27%2F%27%0D%0A++++++end+as+url%2C%0D%0A++++created%2C%0D%0A++++html%2C%0D%0A++++json%2C%0D%0A++++external_url%2C%0D%0A++++case%0D%0A++++++when+type+%3D+%27entry%27+then+%28%0D%0A++++++++select+json_group_array%28tag%29%0D%0A++++++++from+blog_tag%0D%0A++++++++join+blog_entry_tags+on+blog_tag.id+%3D+blog_entry_tags.tag_id%0D%0A++++++++where+blog_entry_tags.entry_id+%3D+content.id%0D%0A++++++%29%0D%0A++++++when+type+%3D+%27blogmark%27+then+%28%0D%0A++++++++select+json_group_array%28tag%29%0D%0A++++++++from+blog_tag%0D%0A++++++++join+blog_blogmark_tags+on+blog_tag.id+%3D+blog_blogmark_tags.tag_id%0D%0A++++++++where+blog_blogmark_tags.blogmark_id+%3D+content.id%0D%0A++++++%29%0D%0A++++++when+type+%3D+%27quotation%27+then+%28%0D%0A++++++++select+json_group_array%28tag%29%0D%0A++++++++from+blog_tag%0D%0A++++++++join+blog_quotation_tags+on+blog_tag.id+%3D+blog_quotation_tags.tag_id%0D%0A++++++++where+blog_quotation_tags.quotation_id+%3D+content.id%0D%0A++++++%29%0D%0A++++++else+%27%5B%5D%27%0D%0A++++end+as+tags%0D%0A++from+content%0D%0A++where+created+%3E%3D+date%28%27now%27%2C+%27-%27+%7C%7C+%3Anumdays+%7C%7C+%27+days%27%29+++%0D%0A++order+by+created+desc%0D%0A%29%0D%0Aselect+id%2C+type%2C+title%2C+url%2C+created%2C+html%2C+json%2C+external_url%2C+tags%0D%0Afrom+collected+%0D%0Aorder+by+%0D%0A++case+type+%0D%0A++++when+%27entry%27+then+0+%0D%0A++++else+1+%0D%0A++end%2C%0D%0A++case+type+%0D%0A++++when+%27entry%27+then+created+%0D%0A++++else+-strftime%28%27%25s%27%2C+created%29+%0D%0A++end+desc%3B&amp;numdays=7\">see and execute that query</a> directly in Datasette. It's 143 lines of convoluted SQL that assembles most of the HTML for the newsletter using SQLite string concatenation! An illustrative snippet:</p>\n<div class=\"highlight highlight-source-sql\"><pre>with content <span class=\"pl-k\">as</span> (\n  <span class=\"pl-k\">select</span>\n    id,\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>entry<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">as</span> type,\n    title,\n    created,\n    slug,\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>&lt;h3&gt;&lt;a href=\"<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">||</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>https://simonwillison.net/<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">||</span> strftime(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>%Y/<span class=\"pl-pds\">'</span></span>, created)\n      <span class=\"pl-k\">||</span> substr(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>JanFebMarAprMayJunJulAugSepOctNovDec<span class=\"pl-pds\">'</span></span>, (strftime(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>%m<span class=\"pl-pds\">'</span></span>, created) <span class=\"pl-k\">-</span> <span class=\"pl-c1\">1</span>) <span class=\"pl-k\">*</span> <span class=\"pl-c1\">3</span> <span class=\"pl-k\">+</span> <span class=\"pl-c1\">1</span>, <span class=\"pl-c1\">3</span>) \n      <span class=\"pl-k\">||</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">||</span> cast(strftime(<span class=\"pl-s\"><span class=\"pl-pds\">'</span>%d<span class=\"pl-pds\">'</span></span>, created) <span class=\"pl-k\">as</span> <span class=\"pl-k\">integer</span>) <span class=\"pl-k\">||</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">||</span> slug <span class=\"pl-k\">||</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>/<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">||</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>\"&gt;<span class=\"pl-pds\">'</span></span> \n      <span class=\"pl-k\">||</span> title <span class=\"pl-k\">||</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>&lt;/a&gt; - <span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">||</span> <span class=\"pl-k\">date</span>(created) <span class=\"pl-k\">||</span> <span class=\"pl-s\"><span class=\"pl-pds\">'</span>&lt;/h3&gt;<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">||</span> body\n      <span class=\"pl-k\">as</span> html,\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span>null<span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">as</span> json,\n    <span class=\"pl-s\"><span class=\"pl-pds\">'</span><span class=\"pl-pds\">'</span></span> <span class=\"pl-k\">as</span> external_url\n  <span class=\"pl-k\">from</span> blog_entry\n  <span class=\"pl-k\">union all</span>\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> ...</span></pre></div>\n<p>My blog's URLs look like <code>/2025/Nov/18/gemini-3/</code> - this SQL constructs that three letter month abbreviation from the month number using a substring operation.</p>\n<p>This is a <em>terrible</em> way to assemble HTML, but I've stuck with it because it amuses me.</p>\n<p>The rest of the Observable notebook takes that data, filters out anything that links to content mentioned in the previous newsletters and composes it into a block of HTML that can be copied using that big button.</p>\n<p>Here's the recipe it uses to turn HTML into rich text content on a clipboard suitable for Substack. I can't remember how I figured this out but it's very effective:</p>\n<div class=\"highlight highlight-source-js\"><pre><span class=\"pl-v\">Object</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">assign</span><span class=\"pl-kos\">(</span>\n  <span class=\"pl-en\">html</span><span class=\"pl-s\">`<span class=\"pl-kos\">&lt;</span><span class=\"pl-ent\">button</span> <span class=\"pl-c1\">style</span>=\"<span class=\"pl-s\">font-size: 1.4em; padding: 0.3em 1em; font-weight: bold;</span>\"<span class=\"pl-kos\">&gt;</span>Copy rich text newsletter to clipboard`</span><span class=\"pl-kos\">,</span>\n  <span class=\"pl-kos\">{</span>\n    <span class=\"pl-en\">onclick</span>: <span class=\"pl-kos\">(</span><span class=\"pl-kos\">)</span> <span class=\"pl-c1\">=&gt;</span> <span class=\"pl-kos\">{</span>\n      <span class=\"pl-k\">const</span> <span class=\"pl-s1\">htmlContent</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">newsletterHTML</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-c\">// Create a temporary element to hold the HTML content</span>\n      <span class=\"pl-k\">const</span> <span class=\"pl-s1\">tempElement</span> <span class=\"pl-c1\">=</span> <span class=\"pl-smi\">document</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">createElement</span><span class=\"pl-kos\">(</span><span class=\"pl-s\">\"div\"</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-s1\">tempElement</span><span class=\"pl-kos\">.</span><span class=\"pl-c1\">innerHTML</span> <span class=\"pl-c1\">=</span> <span class=\"pl-s1\">htmlContent</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-smi\">document</span><span class=\"pl-kos\">.</span><span class=\"pl-c1\">body</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">appendChild</span><span class=\"pl-kos\">(</span><span class=\"pl-s1\">tempElement</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-c\">// Select the HTML content</span>\n      <span class=\"pl-k\">const</span> <span class=\"pl-s1\">range</span> <span class=\"pl-c1\">=</span> <span class=\"pl-smi\">document</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">createRange</span><span class=\"pl-kos\">(</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-s1\">range</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">selectNode</span><span class=\"pl-kos\">(</span><span class=\"pl-s1\">tempElement</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-c\">// Copy the selected HTML content to the clipboard</span>\n      <span class=\"pl-k\">const</span> <span class=\"pl-s1\">selection</span> <span class=\"pl-c1\">=</span> <span class=\"pl-smi\">window</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">getSelection</span><span class=\"pl-kos\">(</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-s1\">selection</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">removeAllRanges</span><span class=\"pl-kos\">(</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-s1\">selection</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">addRange</span><span class=\"pl-kos\">(</span><span class=\"pl-s1\">range</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-smi\">document</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">execCommand</span><span class=\"pl-kos\">(</span><span class=\"pl-s\">\"copy\"</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-s1\">selection</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">removeAllRanges</span><span class=\"pl-kos\">(</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n      <span class=\"pl-smi\">document</span><span class=\"pl-kos\">.</span><span class=\"pl-c1\">body</span><span class=\"pl-kos\">.</span><span class=\"pl-en\">removeChild</span><span class=\"pl-kos\">(</span><span class=\"pl-s1\">tempElement</span><span class=\"pl-kos\">)</span><span class=\"pl-kos\">;</span>\n    <span class=\"pl-kos\">}</span>\n  <span class=\"pl-kos\">}</span>\n<span class=\"pl-kos\">)</span></pre></div>\n<h4 id=\"from-django-postgresql-to-datasette-sqlite\">From Django+Postgresql to Datasette+SQLite</h4>\n<p>My blog itself is a Django application hosted on Heroku, with data stored in Heroku PostgreSQL. Here's <a href=\"https://github.com/simonw/simonwillisonblog\">the source code for that Django application</a>. I use the Django admin as my CMS.</p>\n<p><a href=\"https://datasette.io/\">Datasette</a> provides a JSON API over a SQLite database... which means something needs to convert that PostgreSQL database into a SQLite database that Datasette can use.</p>\n<p>My system for doing that lives in the <a href=\"https://github.com/simonw/simonwillisonblog-backup\">simonw/simonwillisonblog-backup</a> GitHub repository. It uses GitHub Actions on a schedule that executes every two hours, fetching the latest data from PostgreSQL and converting that to SQLite.</p>\n<p>My <a href=\"https://github.com/simonw/db-to-sqlite\">db-to-sqlite</a> tool is responsible for that conversion. I call it <a href=\"https://github.com/simonw/simonwillisonblog-backup/blob/dc5b9df272134ce051a5280b4de6d4daa9b2a9fc/.github/workflows/backup.yml#L44-L62\">like this</a>:</p>\n<div class=\"highlight highlight-source-shell\"><pre>db-to-sqlite \\\n  <span class=\"pl-s\"><span class=\"pl-pds\">$(</span>heroku config:get DATABASE_URL -a simonwillisonblog <span class=\"pl-k\">|</span> sed s/postgres:/postgresql+psycopg2:/<span class=\"pl-pds\">)</span></span> \\\n  simonwillisonblog.db \\\n  --table auth_permission \\\n  --table auth_user \\\n  --table blog_blogmark \\\n  --table blog_blogmark_tags \\\n  --table blog_entry \\\n  --table blog_entry_tags \\\n  --table blog_quotation \\\n  --table blog_quotation_tags \\\n  --table blog_note \\\n  --table blog_note_tags \\\n  --table blog_tag \\\n  --table blog_previoustagname \\\n  --table blog_series \\\n  --table django_content_type \\\n  --table redirects_redirect</pre></div>\n<p>That <code>heroku config:get DATABASE_URL</code> command uses Heroku credentials in an environment variable to fetch the database connection URL for my blog's PostgreSQL database (and fixes a small difference in the URL scheme).</p>\n<p><code>db-to-sqlite</code> can then export that data and write it to a SQLite database file called <code>simonwillisonblog.db</code>.</p>\n<p>The <code>--table</code> options specify the tables that should be included in the export.</p>\n<p>The repository does more than just that conversion: it also exports the resulting data to JSON files that live in the repository, which gives me a <a href=\"https://github.com/simonw/simonwillisonblog-backup/commits/main/simonwillisonblog\">commit history</a> of changes I make to my content. This is a cheap way to get a revision history of my blog content without having to mess around with detailed history tracking inside the Django application itself.</p>\n<p>At the <a href=\"https://github.com/simonw/simonwillisonblog-backup/blob/dc5b9df272134ce051a5280b4de6d4daa9b2a9fc/.github/workflows/backup.yml#L200-L204\">end of my GitHub Actions workflow</a> is this code that publishes the resulting database to Datasette running on <a href=\"https://fly.io/\">Fly.io</a> using the <a href=\"https://datasette.io/plugins/datasette-publish-fly\">datasette publish fly</a> plugin:</p>\n<div class=\"highlight highlight-source-shell\"><pre>datasette publish fly simonwillisonblog.db \\\n  -m metadata.yml \\\n  --app simonwillisonblog-backup \\\n  --branch 1.0a2 \\\n  --extra-options <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>--setting sql_time_limit_ms 15000 --setting truncate_cells_html 10000 --setting allow_facet off<span class=\"pl-pds\">\"</span></span> \\\n  --install datasette-block-robots \\\n  <span class=\"pl-c\"><span class=\"pl-c\">#</span> ... more plugins</span></pre></div>\n<p>As you can see, there are a lot of moving parts! Surprisingly it all mostly just works - I rarely have to intervene in the process, and the cost of those different components is pleasantly low.</p>\n    \n        <p>Tags: <a href=\"https://simonwillison.net/tags/blogging\">blogging</a>, <a href=\"https://simonwillison.net/tags/django\">django</a>, <a href=\"https://simonwillison.net/tags/javascript\">javascript</a>, <a href=\"https://simonwillison.net/tags/postgresql\">postgresql</a>, <a href=\"https://simonwillison.net/tags/sql\">sql</a>, <a href=\"https://simonwillison.net/tags/sqlite\">sqlite</a>, <a href=\"https://simonwillison.net/tags/youtube\">youtube</a>, <a href=\"https://simonwillison.net/tags/heroku\">heroku</a>, <a href=\"https://simonwillison.net/tags/datasette\">datasette</a>, <a href=\"https://simonwillison.net/tags/observable\">observable</a>, <a href=\"https://simonwillison.net/tags/github-actions\">github-actions</a>, <a href=\"https://simonwillison.net/tags/fly\">fly</a>, <a href=\"https://simonwillison.net/tags/newsletter\">newsletter</a></p>",
      "source": "Simon Willison's Weblog",
      "source_url": "https://simonwillison.net/atom/everything/",
      "author": "",
      "tags": [
        "blogging",
        "django",
        "javascript",
        "postgresql",
        "sql",
        "sqlite",
        "youtube",
        "heroku",
        "datasette",
        "observable",
        "github-actions",
        "fly",
        "newsletter"
      ]
    },
    {
      "title": "An Implementation of a Comprehensive Empirical Framework for Benchmarking Reasoning Strategies in Modern Agentic AI Systems",
      "url": "https://www.marktechpost.com/2025/11/19/an-implementation-of-a-comprehensive-empirical-framework-for-benchmarking-reasoning-strategies-in-modern-agentic-ai-systems/",
      "published": "2025-11-20T02:32:22+00:00",
      "date_verified": true,
      "description": "<p>In this tutorial, we dive deep into how we systematically benchmark agentic components by evaluating multiple reasoning strategies across diverse tasks. We explore how different architectures, such as Direct, Chain-of-Thought, ReAct, and Reflexion, behave when faced with problems of increasing difficulty, and we quantify their accuracy, efficiency, latency, and tool-usage patterns. By conducting controlled empirical [&#8230;]</p>\n<p>The post <a href=\"https://www.marktechpost.com/2025/11/19/an-implementation-of-a-comprehensive-empirical-framework-for-benchmarking-reasoning-strategies-in-modern-agentic-ai-systems/\">An Implementation of a Comprehensive Empirical Framework for Benchmarking Reasoning Strategies in Modern Agentic AI Systems</a> appeared first on <a href=\"https://www.marktechpost.com\">MarkTechPost</a>.</p>",
      "source": "MarkTechPost",
      "source_url": "https://www.marktechpost.com/feed/",
      "author": "Asif Razzaq",
      "tags": [
        "Agentic AI",
        "Editors Pick",
        "Tutorials"
      ]
    },
    {
      "title": "No Title",
      "url": "https://bsky.app/profile/emollick.bsky.social/post/3m5z5yfd7v22x",
      "published": "2025-11-20T02:08:00+00:00",
      "date_verified": true,
      "description": "\"Hey, Gemini 3, So I need DOOM, but more root vegetables, also no guns or demons or mars. And more of a focus on different flooring styles. but otherwise EXACTLY the same as DOOM.\"\n\nGemini: \"Here is F.L.O.O.R. (First-person Lino Observation & Ornamental Review).\"\n\nPretty good!",
      "source": "@emollick.bsky.social - Ethan Mollick",
      "source_url": "https://bsky.app/profile/emollick.bsky.social/rss",
      "author": "",
      "tags": []
    },
    {
      "title": "The largest AI data center campuses will soon be a fifth the size of Manhattan",
      "url": "https://epochai.substack.com/p/the-largest-ai-data-center-campuses",
      "published": "2025-11-20T01:02:10+00:00",
      "date_verified": true,
      "description": "AI's physical footprint is scaling rapidly, too.",
      "source": "Epoch AI",
      "source_url": "https://epochai.substack.com/feed",
      "author": "Luke Emberson",
      "tags": []
    },
    {
      "title": "How we’re making GitHub Copilot smarter with fewer tools",
      "url": "https://github.blog/ai-and-ml/github-copilot/how-were-making-github-copilot-smarter-with-fewer-tools/",
      "published": "2025-11-20T01:00:00+00:00",
      "date_verified": true,
      "description": "<p>We're using embedding-guided tool routing, adaptive clustering, and a streamlined 13-tool core to deliver faster experience in VS Code.</p>\n<p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/how-were-making-github-copilot-smarter-with-fewer-tools/\">How we’re making GitHub Copilot smarter with fewer tools</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
      "source": "The GitHub Blog",
      "source_url": "https://github.blog/feed/",
      "author": "Anisha Agarwal",
      "tags": [
        "AI & ML",
        "GitHub Copilot",
        "agentic workflows",
        "MCP",
        "VS Code"
      ]
    },
    {
      "title": "OpenAI debuts GPT‑5.1-Codex-Max coding model and it already completed a 24-hour task internally",
      "url": "https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24",
      "published": "2025-11-20T00:26:00+00:00",
      "date_verified": true,
      "description": "<p>OpenAI has <a href=\"https://openai.com/index/gpt-5-1-codex-max/\"><b>introduced GPT‑5.1-Codex-Max</b></a>, a new frontier agentic coding model now available in its Codex developer environment. The release marks a significant step forward in AI-assisted software engineering, offering improved long-horizon reasoning, efficiency, and real-time interactive capabilities. GPT‑5.1-Codex-Max will now replace GPT‑5.1-Codex as the default model across Codex-integrated surfaces.</p><p>The new model is designed to serve as a persistent, high-context software development agent, capable of managing complex refactors, debugging workflows, and project-scale tasks across multiple context windows.</p><p>It comes on the heels of<a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\"> Google releasing its powerful new Gemini 3 Pro model</a> yesterday, yet still outperforms or matches it on key coding benchmarks: </p><p>On <b>SWE-Bench Verified</b>, <b>GPT‑5.1-Codex-Max achieved 77.9% accuracy</b> at extra-high reasoning effort, edging past Gemini 3 Pro’s 76.2%. </p><p>It also led on <b>Terminal-Bench 2.0, with 58.1% accuracy versus Gemini’s 54.2%, </b>and matched Gemini’s score of 2,439 on LiveCodeBench Pro, a competitive coding Elo benchmark.</p><p>When measured against Gemini 3 Pro’s most advanced configuration — its Deep Thinking model — Codex-Max holds a slight edge in agentic coding benchmarks, as well. </p><h3><b>Performance Benchmarks: Incremental Gains Across Key Tasks</b></h3><p>GPT‑5.1-Codex-Max demonstrates measurable improvements over GPT‑5.1-Codex across a range of standard software engineering benchmarks. </p><p>On SWE-Lancer IC SWE, it achieved 79.9% accuracy, a significant increase from GPT‑5.1-Codex’s 66.3%. In SWE-Bench Verified (n=500), it reached 77.9% accuracy at extra-high reasoning effort, outperforming GPT‑5.1-Codex’s 73.7%.</p><p>Performance on Terminal Bench 2.0 (n=89) showed more modest improvements, with GPT‑5.1-Codex-Max achieving 58.1% accuracy compared to 52.8% for GPT‑5.1-Codex. </p><p>All evaluations were run with compaction and extra-high reasoning effort enabled.</p><p>These results indicate that the new model offers a higher ceiling on both benchmarked correctness and real-world usability under extended reasoning loads.</p><h3><b>Technical Architecture: Long-Horizon Reasoning via Compaction</b></h3><p>A major architectural improvement in GPT‑5.1-Codex-Max is its ability to reason effectively over extended input-output sessions using a mechanism called <b>compaction</b>. </p><p>This enables the model to retain key contextual information while discarding irrelevant details as it nears its context window limit — effectively allowing for continuous work across millions of tokens without performance degradation.</p><p>The model has been internally observed to complete tasks lasting more than 24 hours, including multi-step refactors, test-driven iteration, and autonomous debugging.</p><p>Compaction also improves token efficiency. At medium reasoning effort, GPT‑5.1-Codex-Max used approximately 30% fewer thinking tokens than GPT‑5.1-Codex for comparable or better accuracy, which has implications for both cost and latency.</p><h3><b>Platform Integration and Use Cases</b></h3><p>GPT‑5.1-Codex-Max is currently available across multiple Codex-based environments, which refer to OpenAI’s own integrated tools and interfaces built specifically for code-focused AI agents. These include:</p><ul><li><p><b>Codex CLI</b>, OpenAI’s official command-line tool (@openai/codex), where GPT‑5.1-Codex-Max is already live.</p></li><li><p><b>IDE extensions</b>, likely developed or maintained by OpenAI, though no specific third-party IDE integrations were named.</p></li><li><p><b>Interactive coding environments</b>, such as those used to demonstrate frontend simulation apps like CartPole or Snell’s Law Explorer.</p></li><li><p><b>Internal code review tooling</b>, used by OpenAI’s engineering teams.</p></li></ul><p>For now, GPT‑5.1-Codex-Max is not yet available via public API, though OpenAI states this is coming soon. Users who wish to work with the model in terminal environments today can do so by installing and using the Codex CLI.</p><p>It is not currently confirmed whether or how the model will integrate into third-party IDEs unless they are built on top of the CLI or future API.</p><p>The model is capable of interacting with live tools and simulations. Examples shown in the release include:</p><ul><li><p>An interactive CartPole policy gradient simulator, which visualizes reinforcement learning training and activations.</p></li><li><p>A Snell’s Law optics explorer, supporting dynamic ray tracing across refractive indices.</p></li></ul><p>These interfaces exemplify the model’s ability to reason in real time while maintaining an interactive development session — effectively bridging computation, visualization, and implementation within a single loop.</p><h3><b>Cybersecurity and Safety Constraints</b></h3><p>While GPT‑5.1-Codex-Max does not meet OpenAI’s “High” capability threshold for cybersecurity under its Preparedness Framework, it is currently the most capable cybersecurity model OpenAI has deployed. It supports use cases such as automated vulnerability detection and remediation, but with strict sandboxing and disabled network access by default.</p><p>OpenAI reports no increase in scaled malicious use but has introduced enhanced monitoring systems, including activity routing and disruption mechanisms for suspicious behavior. Codex remains isolated to a local workspace unless developers opt-in to broader access, mitigating risks like prompt injection from untrusted content.</p><h3><b>Deployment Context and Developer Usage</b></h3><p>GPT‑5.1-Codex-Max is currently available to users on <b>ChatGPT Plus, Pro, Business, Edu, and Enterprise</b> plans. It will also become the new default in Codex-based environments, replacing GPT‑5.1-Codex, which was a more general-purpose model.</p><p>OpenAI states that 95% of its internal engineers use Codex weekly, and since adoption, these engineers have shipped ~70% more pull requests on average — highlighting the tool’s impact on internal development velocity.</p><p>Despite its autonomy and persistence, OpenAI stresses that Codex-Max should be treated as a coding assistant, not a replacement for human review. The model produces terminal logs, test citations, and tool call outputs to support transparency in generated code.</p><h3><b>Outlook</b></h3><p>GPT‑5.1-Codex-Max represents a significant evolution in OpenAI’s strategy toward agentic development tools, offering greater reasoning depth, token efficiency, and interactive capabilities across software engineering tasks. By extending its context management and compaction strategies, the model is positioned to handle tasks at the scale of full repositories, rather than individual files or snippets.</p><p>With continued emphasis on agentic workflows, secure sandboxes, and real-world evaluation metrics, Codex-Max sets the stage for the next generation of AI-assisted programming environments — while underscoring the importance of oversight in increasingly autonomous systems.</p>",
      "source": "AI | VentureBeat",
      "source_url": "https://venturebeat.com/category/ai/feed/",
      "author": "carl.franzen@venturebeat.com (Carl Franzen)",
      "tags": [
        "AI",
        "Dev"
      ]
    },
    {
      "title": "Unlock Business Value: Build a Data & Analytics Strategy That Delivers",
      "url": "https://www.kdnuggets.com/2025/11/gartner/unlock-business-value-build-a-data-analytics-strategy-that-delivers",
      "published": "2025-11-19T23:00:16+00:00",
      "date_verified": true,
      "description": "In today’s data-saturated world, simply being “data-driven” isn’t enough. The most successful organizations are those that translate data, analytics, and AI into measurable business outcomes—creating real value for customers and shareholders alike.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "KDnuggets",
      "tags": []
    },
    {
      "title": "The Google Search of AI agents? Fetch launches ASI:One and Business tier for new era of non-human web",
      "url": "https://venturebeat.com/ai/the-google-search-of-ai-agents-fetch-launches-asi-one-and-business-tier-for",
      "published": "2025-11-19T22:57:00+00:00",
      "date_verified": true,
      "description": "<p><a href=\"https://fetch.ai/\">Fetch AI</a>, a startup founded and led by former DeepMind founding investor, Humayun Sheikh, <a href=\"https://www.businesswire.com/news/home/20251119088395/en/Fetch-Combines-Personalized-AI-with-Multi-Agent-Collaboration-to-Handle-Complex-Consumer-Tasks-Launches-Claim-Your-Agent-to-Fight-Brand-Knock-Offs\">on Wednesday announced the release</a> of three interconnected products designed to provide the trust, coordination, and interoperability needed for large-scale AI agent ecosystems. </p><p>The launch includes <a href=\"https://asi1.ai/\">ASI:One</a>, a personal-AI orchestration platform; <a href=\"https://business.fetch.ai/\">Fetch Business</a>, a verification and discovery portal for brand agents; and <a href=\"https://agentverse.ai/?sort=relevancy&amp;page=1&amp;recommended=true\">Agentverse</a>, an open directory hosting more than two million agents. </p><p>Together, the system positions Fetch as an infrastructure provider for what it calls the “Agentic Web”—a layer where consumer AIs and brand AIs collaborate to complete tasks instead of merely suggesting them.</p><p>The company says the tools address a central limitation in current consumer AI: models can provide recommendations but cannot reliably execute multi-step actions that require coordination across businesses. Fetch’s approach centers on enabling agents from different organizations to interoperate securely, using verified identities and shared context to complete end-to-end workflows.</p><p>“We’re creating the same foundation for agents that Google created for websites,” said Humayun Sheikh, Founder and CEO of Fetch AI, and an early investor in DeepMind, in a press release provided to VentureBeat. “Instead of just finding information, your personal AI coordinates with verified brand agents to get things done.”</p><h2><b>Fetch’s founding and DeepMind connection </b></h2><p>Fetch AI was founded in 2017 by Humayun Sheikh, an entrepreneur whose early investment in DeepMind helped support the company’s commercial development before its acquisition by Google. “I was one of the first five people at DeepMind and its first investor. My check was the first one in,” Sheikh said, reflecting on the period when advanced machine learning research was still largely inaccessible outside major technology companies.</p><p>His early experience helped shape Fetch’s direction. “Even in 2013, it was clear to me that agentic systems were going to be the ones that worked. That’s where I focused—on the agentic web,” Sheikh noted. Fetch built on this thesis by developing infrastructure for autonomous software agents, focusing on verifiable identity, secure data exchange, and multi-agent coordination. </p><p>Over the past several years, the company has expanded to a 70-person team across Cambridge and Menlo Park, raised approximately $60 million, and accumulated more than one million users interacting with its model—data that informed the design of the newly launched products.</p><p>Sheikh added that his decision to bootstrap the company initially came directly from the proceeds of the DeepMind exit, noting in the interview that while the sale to Google was “a good exit,” he believed the team could have held out for a higher valuation. </p><p>The early self-funding period allowed Fetch to begin work in 2015—well before transformer architectures went mainstream—on the hypothesis that agentic infrastructure would become foundational to applied AI.</p><h2><b>ASI:One is a platform for multi-agent orchestration</b></h2><p>At the core of the launch is <b>ASI:One</b>, a language model interface designed specifically for coordinating multiple agents rather than addressing isolated queries. Fetch describes it as an “intelligence layer” that handles context sharing, task routing, and preference modeling.</p><p>The system stores user-level signals such as favored airlines, dietary constraints, budget ranges, loyalty program identifiers, and calendar availability. When a user requests a complex task — such as planning a trip with flights, hotels, and restaurant reservations — ASI:One retrieves those preferences and delegates work to the appropriate verified agents. The agents then return actionable outputs, including inventory and booking options, rather than generic recommendations.</p><p>In practice, ASI:One functions as a workflow generator across organizational boundaries. By contrast with conventional LLM applications, which often rely on APIs or RAG techniques to surface information, ASI:One is built to coordinate autonomous agents that can complete transactions. Fetch notes that personalization improves over time as the model accumulates structured preference data.</p><p>Sheikh emphasized the distinction between orchestrated execution and traditional AI output. “This isn’t searching for options separately and hoping they work together,” he said. “It’s orchestration.” </p><p>He added that Fetch’s architecture is intentionally modular: “Our architecture is a mix of agentic and expert models. One large model isn’t enough — you need specialists. That’s why we built ASI1, tuned specifically for agentic systems.”</p><p>The interview also revealed new details about ASI:One’s personalization systems: the platform uses multiple user-owned knowledge graphs to store preferences, travel history, social connections, and contextual constraints. </p><p>These knowledge graphs are siloed per user and not co-mingled with any Fetch-operated data. Sheikh described this as a “deterministic backbone” that gives the personal AI a stable memory layer beyond the probabilistic output of a single large model.</p><p>ASI:One launches in Beta today, with a broader release planned for early 2026. Fetch also offers ASI:One Mobile, released earlier this year, giving users access to the same agent-orchestration capabilities on iOS and Android. The mobile app connects directly to Agentverse and the user’s knowledge graphs, enabling on-the-go task execution and real-time interaction with registered agents.</p><h2><b>Fetch Business offers verified identity and brand control</b></h2><p>To enable reliable coordination between consumers and companies, Fetch is introducing a verification and discovery portal called Fetch Business. </p><p>The platform allows organizations to verify their identity and claim an official Brand Agent handle — for example, @Hilton or @Nike — regardless of which tools they use to build the underlying agent.</p><p>Fetch positions the product as an analogue to ICANN domain registration and SSL certificate systems for websites. Verified status is intended to protect consumers from interacting with counterfeit or untrusted agents, a problem the company describes as a major barrier to widespread agent adoption.</p><p>The system includes low-code tools for small businesses to create agents in a few steps and connect real-time APIs such as inventory, booking systems, or CRM platforms. </p><p>“With Fetch, you can create an agent in one minute. It gets a handle, like a Twitter username, and you can personalize it completely—even give it your social media permissions to post on your behalf,” Sheikh said. Once a brand claims its namespace, its agent becomes discoverable to consumer AIs and other agents inside Agentverse.</p><p>The company has pre-reserved thousands of brand namespaces in anticipation of demand. Verification status persists across any platform that integrates with Agentverse, creating a portable identity layer for business agents.</p><p>The interview highlighted that Fetch Business inherits web-trust primitives directly: domain owners verify their identity by inserting a short code snippet into their existing website backend, allowing the system to pass a cryptographic challenge and grant the agent an authenticity badge similar to a “blue check” for agent identities. Sheikh framed this as “reusing the trust layer the web already spent decades building.”</p><p>Companies can begin claiming agents now at <a href=\"https://business.fetch.ai/\"><b>business.fetch.ai</b></a>.</p><h2><b>Agentverse is an open directory of more yhan 2 million agents</b></h2><p>The final component of the release is <a href=\"https://agentverse.ai/\">Agentverse</a>, an open directory and cloud platform that hosts agents and enables cross-ecosystem discoverability. Fetch states that millions of agents have already registered, spanning travel, retail, entertainment, food service, and enterprise categories.</p><p>Agentverse provides metadata, capability descriptions, and routing logic that ASI:One uses to identify appropriate agents for specific tasks. It also supports secure communication and data exchange between agents. The company notes that the directory is platform-agnostic: agents built with any framework can join and interoperate.</p><p>According to Sheikh, the lack of a discovery layer is one reason most AI agents see little or no usage. “Ninety percent of AI agents never get used because there’s no discovery layer,” he said. </p><p>He framed the role of Agentverse in more technical terms: “Right now, if you build an agent, there’s no universal way for others to discover it. That’s what AgentVerse solves—it’s like DNS for agents.” He also described the system as an essential component of the emerging agent economy: “Fetch is building the Google of agents. Just like websites needed search, agents need discovery, trust, and interaction—Fetch provides all of that.”</p><p>The interview further underscored that Agentverse is cloud-agnostic by design. Sheikh contrasted this with competing agent ecosystems tied to specific cloud providers, arguing that a universal registry is only viable if independent of proprietary cloud environments. He said the open architecture enables an LLM to query any agent “within one minute of deployment,” turning agent publication into a near-instantaneous process similar to registering a domain.</p><p>Agentverse also integrates payment pathways, enabling agents to execute purchases using partners such as Visa, Skyfire, and supported stablecoins. Consumers can configure spending limits or require explicit approval for transactions.</p><h2><b>Industry context and implications</b></h2><p>Fetch’s launch comes at a time when consumer AI platforms are exploring the shift from static chat interfaces toward autonomous agents capable of completing actions. However, most agent systems remain limited by siloed architectures, limited interoperability, and weak verification standards.</p><p>Fetch positions its infrastructure as a response to these limitations by providing a cross-platform coordination layer, identity system, and directory service. The company argues that an agent ecosystem requires consistent verification mechanisms to ensure that consumers interact with authentic brand representatives rather than imitations. By establishing namespace control and portable trust indicators, Fetch Business aims to fill a gap similar to early web domain verification.</p><p>At the same time, ASI:One attempts to centralize user preference data in a way that enables more efficient personalization and multi-agent coordination. This approach differs from generalist LLM applications, which often lack persistent preference architectures or direct access to brand-controlled agents.</p><p>The interview also made clear that micropayments and digital transaction infrastructure are central to Fetch’s long-term vision. Sheikh referenced integrations with protocols such as Coinbase’s 402 and AP2, positioning these capabilities as essential for autonomous agents to complete end-to-end tasks that include financial execution.</p><p>Fetch’s combined release of ASI:One, Fetch Business, and Agentverse introduces an interconnected stack designed to support large-scale deployment and usage of AI agents. The company frames the system as foundational infrastructure for an agentic ecosystem, where consumer AIs can coordinate with verified brand agents to complete tasks reliably and securely. The additions to its identity, discovery, and orchestration layers reflect Fetch’s long-standing thesis — rooted partly in lessons from DeepMind’s early development — that intelligence becomes meaningful only when paired with the capacity to act.</p>",
      "source": "AI | VentureBeat",
      "source_url": "https://venturebeat.com/category/ai/feed/",
      "author": "carl.franzen@venturebeat.com (Carl Franzen)",
      "tags": [
        "AI"
      ]
    },
    {
      "title": "How to Perform Agentic Information Retrieval",
      "url": "https://towardsdatascience.com/how-to-perform-agentic-information-retrieval/",
      "published": "2025-11-19T22:30:00+00:00",
      "date_verified": true,
      "description": "<p>Learn how to utilize AI agents to find information in your document corpus</p>\n<p>The post <a href=\"https://towardsdatascience.com/how-to-perform-agentic-information-retrieval/\">How to Perform Agentic Information Retrieval</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Eivind Kjosbakken",
      "tags": [
        "Agentic AI",
        "Agentic Ai",
        "Ai Agent",
        "Information Retrieval",
        "Llm",
        "Rag"
      ]
    },
    {
      "title": "How AI will change software engineering – with Martin Fowler",
      "url": "https://newsletter.pragmaticengineer.com/p/martin-fowler",
      "published": "2025-11-19T22:09:43+00:00",
      "date_verified": true,
      "description": "Martin Fowler breaks down how AI is transforming software architecture and development, from refactoring and deterministic techniques to the timeless principles that still anchor great engineering.",
      "source": "The Pragmatic Engineer",
      "source_url": "https://newsletter.pragmaticengineer.com/feed",
      "author": "Gergely Orosz",
      "tags": []
    },
    {
      "title": "How to write a great agents.md: Lessons from over 2,500 repositories",
      "url": "https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/",
      "published": "2025-11-19T22:00:00+00:00",
      "date_verified": true,
      "description": "<p>Learn how to write effective agents.md files for GitHub Copilot with practical tips, real examples, and templates from analyzing 2,500+ repositories.</p>\n<p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/\">How to write a great agents.md: Lessons from over 2,500 repositories</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
      "source": "The GitHub Blog",
      "source_url": "https://github.blog/feed/",
      "author": "Matt Nigh",
      "tags": [
        "AI & ML",
        "GitHub Copilot",
        "agentic AI",
        "generative AI"
      ]
    },
    {
      "title": "Scaling innovation in manufacturing with AI",
      "url": "https://www.technologyreview.com/2025/11/19/1128067/scaling-innovation-in-manufacturing-with-ai/",
      "published": "2025-11-19T21:54:55+00:00",
      "date_verified": true,
      "description": "Manufacturing is getting a major system upgrade. As AI amplifies existing technologies—like digital twins, the cloud, edge computing, and the industrial internet of things (IIoT)—it is enabling factory operations teams to shift from reactive, isolated problem-solving to proactive, systemwide optimization. Digital twins—physically accurate virtual representations of a piece of equipment, a production line, a process,&#8230;",
      "source": "MIT Technology Review",
      "source_url": "https://www.technologyreview.com/feed/",
      "author": "MIT Technology Review Insights",
      "tags": [
        "Artificial intelligence",
        "sponsored"
      ]
    },
    {
      "title": "Developing Human Sexuality in the Age of AI",
      "url": "https://towardsdatascience.com/developing-human-sexuality-in-the-age-of-ai/",
      "published": "2025-11-19T21:00:00+00:00",
      "date_verified": true,
      "description": "<p>How we learn is changing with generative AI — what does that mean for sex education, consent, and responsibility?</p>\n<p>The post <a href=\"https://towardsdatascience.com/developing-human-sexuality-in-the-age-of-ai/\">Developing Human Sexuality in the Age of AI</a> appeared first on <a href=\"https://towardsdatascience.com\">Towards Data Science</a>.</p>",
      "source": "Towards Data Science",
      "source_url": "https://towardsdatascience.com/feed",
      "author": "Stephanie Kirmer",
      "tags": [
        "Artificial Intelligence",
        "Ai Ethics",
        "Deep Dives",
        "Generative Ai",
        "sexuality",
        "Social Science"
      ]
    },
    {
      "title": "GPT-5.1 is about as capable as GPT-5",
      "url": "https://epochai.substack.com/p/gpt-51-is-about-as-capable-as-gpt",
      "published": "2025-11-19T20:18:32+00:00",
      "date_verified": true,
      "description": "With &#8220;high&#8221; reasoning, both GPT-5.1 and GPT-5 score 151 on the Epoch Capabilities Index, our tool for combining results across multiple benchmarks",
      "source": "Epoch AI",
      "source_url": "https://epochai.substack.com/feed",
      "author": "Luke Emberson",
      "tags": []
    },
    {
      "title": "An Introduction to Zapier Automations for Data Scientists",
      "url": "https://www.kdnuggets.com/an-introduction-to-zapier-automations-for-data-scientists",
      "published": "2025-11-19T20:00:04+00:00",
      "date_verified": true,
      "description": "Zapier Automations connect your favorite tools and services so that routine tasks don't eat into your day.",
      "source": "KDnuggets",
      "source_url": "https://www.kdnuggets.com/feed",
      "author": "Shittu Olumide",
      "tags": []
    }
  ]
}